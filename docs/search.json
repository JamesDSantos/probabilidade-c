[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Probabilidade C",
    "section": "",
    "text": "Prefácio",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introdução",
    "section": "",
    "text": "1.1 Vetores aleatórios\nNeste curso vamos utilizar o negrito para designar um vetor. Por exemplo,\n\\[\\textbf{x}=(x_1,…,x_n)\\], é um vetor de comprimento \\(n\\).\nAgora, sejam \\(X_1,…,X_n\\) variáveis aleatórias. Então, dizemos que\n\\[\\textbf{X}=(X_1,…,X_n)\\] é um vetor aleatório (também é usual o termo variável aleatória \\(n\\) -dimensional).\nUtilizamos a vírgula para denotar a interseção de eventos relacionados aos vetores aleatórios. Por exemplo,\n\\[P(X_1\\in A,X_2\\in B)=P(\\{X_1\\in A\\}\\cap\\{X_2\\in B\\})\\],\nAssim como as variáveis aleatórias, os vetores aleatórios possuem funções de densidade/probabilidade e funções de distribuição. Para frisar que mais de uma variável está sendo considerada, utilizamos o adjetivo conjunta. Deste modo, existem para os vetores aleatórias a função de distribuição conjunta e a função de densidade/probabilidade conjunta. Por sua vez, a distribuição de um subvetor de \\(\\textbf{X}\\) é denominada marginal.\nTambém é possível encontrar funções de distribuição ou densidade/probabilidade para o vetor aleatório \\(\\textbf{X}\\) condicionado com o vetor aleatório \\(\\textbf{Y}\\).\nUma vez que essas funções, já conhecidas para o caso univariado, possuem seu equivalente para vetores, é natural expandir conceitos como espança e variância para vetores, assim como a esperança e variância para distribuições condicionais. Nesse momento, novas medidas que medem o relacionamento entre variáveis aleatórias, como covariância e correlação, serão apresentadas.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "intro.html#vetores-aleatórios",
    "href": "intro.html#vetores-aleatórios",
    "title": "1  Introdução",
    "section": "",
    "text": "Dois dados de seis faces são lançados. Sejam \\(X_1\\) e \\(X_2\\) os resultados do dado 1 e 2, respectivamente. Então, \\(\\textbf{X}=(X_1,X_2)\\) é um vetor aleatório.\n\n\n\n\nDois dados de seis faces são lançados. Sejam \\(X_1\\) e \\(X_2\\) os resultados do dado 1 e 2, respectivamente. Então, \\(P(X_1=3,X_2=5)\\) é o mesmo que \\(P(\\{X_1=3\\}\\cap\\{X_2=5\\})\\). Em palavras, este número representa a probabilidade de sair 3 no primeiro dado e 5 no segundo.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "intro.html#teoremas-limites",
    "href": "intro.html#teoremas-limites",
    "title": "1  Introdução",
    "section": "1.2 Teoremas limites",
    "text": "1.2 Teoremas limites",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "intro.html#cadeias-de-markov",
    "href": "intro.html#cadeias-de-markov",
    "title": "1  Introdução",
    "section": "1.3 Cadeias de Markov",
    "text": "1.3 Cadeias de Markov",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_discretos.html",
    "href": "vetores_aleatorios_discretos.html",
    "title": "2  Distribuição de vetores aleatórios discretos",
    "section": "",
    "text": "2.1 Função de probabilidade conjunta\nOs objetivos deste capítulo são:\nObserve que a função de probabilidade conjunta é a interseção dos eventos \\(\\{X_1=x_1\\},\\ldots,\\{X_n=x_n\\}\\). Portanto, se \\(X_1,\\ldots,X_n\\) são mutuamente independentes, teremos\n\\[P(\\textbf{X}=\\textbf{x})=\\prod_{i=1}^n P(X_i=x_i).\\] Também é possível que subconjuntos de variáveis do vetor sejam independentes. Por exemplo, \\(\\tilde{\\textbf{X}}_1=\\{X_1,\\ldots,X_m\\}\\) podem ser independentes de \\(\\tilde{\\textbf{X}}_2=\\{X_{m+1},\\ldots,X_n\\}\\), o que resulta em\n\\[P(\\textbf{X}=\\textbf{x})=P(\\tilde{\\textbf{X}}_1=\\tilde{\\textbf{x}}_1)P(\\tilde{\\textbf{X}}_2=\\tilde{\\textbf{x}}_2).\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Distribuição de vetores aleatórios discretos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_discretos.html#função-de-probabilidade-conjunta",
    "href": "vetores_aleatorios_discretos.html#função-de-probabilidade-conjunta",
    "title": "2  Distribuição de vetores aleatórios discretos",
    "section": "",
    "text": "Definition 2.1 Sejam \\(X_1,\\ldots,X_n\\) variáveis aleatórias discretas. Então, a função\n\\[P(\\textbf{X}=\\textbf{x})=P(X_1=x_1,\\ldots,X_n=x_n),\\] é denominada função de probabilidade conjunta.\n\n\nProposition 2.1 Seja \\(\\textbf{X}\\) um vetor de variáveis aleatórias discretas. Teremos que \\[P(\\textbf{X}=\\textbf{x})=P(X_1=x_1,\\ldots,X_n=x_n)\\] é uma função de probabilidade se:\n\\[\n\\sum_{\\textbf{x}\\in\\mathbb{Z}^n}P(\\textbf{X}=\\textbf{x})=1\\] e se \\[P(\\textbf{X}=\\textbf{x})\\geq 0,\\;\\;\\forall\\;\\textbf{x}\\in\\mathbb{Z}^n.\\]\n\n\nExample 2.1 Seja \\(\\textbf{X}=(X_1,X_2)\\) um vetor aleatório discreto e considere a função\n\\[P(X_1=x_1,X_2=x_2)=\\left\\{\\begin{array}{ll}\\frac{1}{20},& x_1=1,x_2=1\\\\\n\\frac{4}{20},&x_1=1,x_2=2\\\\\n\\frac{5}{20},&x_1=2,x_2=1\\\\\n\\frac{7}{20},&x_1=2,x_2=2\\\\\n\\frac{2}{20},&x_1=3,x_2=1\\\\\n\\frac{1}{20},&x_1=3,x_2=2\\\\ 0,&\\hbox{caso contrário}\\end{array}\\right.\\]\nObserve que todas as probabilidades são não negativas a soma para todos os pares \\((x_1,x_2)\\in\\mathbb{Z}^2\\) é igual a 1, logo a função dada é de fato uma função de probabilidade conjunta para o vetor \\(\\textbf{X}\\).\n\n\nExercise 2.1 Seja\n\\[P(\\textbf{X}=\\textbf{x})=P(X_1=x_1,X_2=x_2)=cq^{x_1+x_2},\\] onde \\((x_1,x_2)\\in\\{0,1\\}^2\\) e \\(q&gt;0\\). Encontre o valor de \\(c\\) para que \\(P(\\textbf{X}=\\textbf{x})\\) seja uma função de probabilidade.\n\n\n\n\n\nExample 2.2 Considere uma moeda com os números 0 e 1 em cada lado. Considere ainda que os dois resultados são equiprováveis. A moeda é lançada duas vezes. Seja \\(X_i\\) o resultado do \\(i\\)-ésimo lançamento. Considerando que \\(X_1\\) e \\(X_2\\) são independentes, encontre a função de probabilidade conjunta de \\(\\textbf{X}=(X_1,X_2)\\).\nSolução. Para \\(i=1,2\\), teremos que\n\\[P(X_i=0)=P(X_i=1)=\\frac{1}{2}.\\]\nComo \\(X_1\\) e \\(X_2\\) são lançamentos independentes, teremos\n\\[P(\\textbf{X}=(0,0))=P(X_1=0,X_2=0)=P(X_1=0)P(X_2=0)=\\frac{1}{4}.\\] Todos os resultados possíveis são \\(\\{(0,0),(0,1),(1,0),(1,1)\\}\\) e podemos mostrar, de modo análogo ao que foi exposto acima, todos esses eventos têm probabilidade 1/4.\n\n\nExercise 2.2 Lança-se um dado de 6 faces. Seja \\(\\textbf{X}=(X_1,X_2)\\) onde\n\\[X_1=\\left\\{\\begin{array}{ll}1,& \\hbox{ se o resultado é par}\\\\0,&\\hbox{ caso contrário}\\end{array}\\right.\\] e\n\\[X_2=\\left\\{\\begin{array}{ll}1,& \\hbox{ se o resultado é maior que 3}\\\\ 0,&\\hbox{ caso contrário}\\end{array}\\right.\\]\nEncontre a função de probabilidade conjunta de \\(\\textbf{X}\\).\n\n\nExercise 2.3 Considere o vetor aleatório \\(\\mathbf{X} = (X_1, X_2, X_3)\\) e os subconjuntos \\(\\tilde{\\mathbf{X}}_1 = \\{X_1\\}\\) e \\(\\tilde{\\mathbf{X}}_2 = \\{X_2, X_3\\}\\). A função de probabilidade conjunta de \\(\\tilde{\\mathbf{X}}_2\\) é dada pela tabela abaixo:\n\n\n\n\\(x_2 \\setminus x_3\\)\n0\n1\n\\(P(X_2 = x_2)\\)\n\n\n\n\n0\n0,2\n0,3\n0,5\n\n\n1\n0,1\n0,4\n0,5\n\n\n\\(P(X_3 = x_3)\\)\n0,3\n0,7\n1,0\n\n\n\nSabendo que \\(X_1\\) assume valores no conjunto \\(\\{0, 1\\}\\) com probabilidades \\(P(X_1=0)=0,6\\) e \\(P(X_1=1)=0,4\\), e que o bloco \\(\\tilde{\\mathbf{X}}_1\\) é independente do bloco \\(\\tilde{\\mathbf{X}}_2\\):\nCalcule a probabilidade conjunta do vetor completo para o ponto \\((X_1=0, X_2=1, X_3=0)\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Distribuição de vetores aleatórios discretos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_discretos.html#função-de-distribuição-conjunta",
    "href": "vetores_aleatorios_discretos.html#função-de-distribuição-conjunta",
    "title": "2  Distribuição de vetores aleatórios discretos",
    "section": "2.2 Função de distribuição conjunta",
    "text": "2.2 Função de distribuição conjunta\n\nDefinition 2.2 A função de distribuição conjunta é definida por\n\\[F(\\textbf{x})=P(X_1\\leq x_1,\\ldots,X_n\\leq x_n)=\\sum_{u_1=-\\infty}^{x_1}\\cdots\\sum_{u_n=-\\infty}^{x_n}P(X_1=u_1,\\ldots,X_n=u_n).\\]\n\n\nExample 2.3 Considere novamente a função de probabilidade conjunta dada por\n\\[P(X=x,Y=y)=\\left\\{\\begin{array}{ll}\\frac{1}{10},& x=1,y=1\\\\\n\\frac{4}{10},&x=1,y=2\\\\\n\\frac{3}{10},&x=2,y=1\\\\\n\\frac{2}{10},&x=2,y=2\\\\\n\\\\ 0,&\\hbox{caso contrário}\\end{array}\\right.\\]\nA função de distribuição conjunta é dada por\n\\[F(x,y)=\\left\\{\\begin{array}{ll}0,& x&lt;1,y&lt;1\\\\\nP(X=1,Y=1)=\\frac{1}{10},& x=1,y=1\\\\\nP(X=1,Y=1)+P(X=1,Y=2)=\\frac{5}{10},&x=1,y=2\\\\\nP(X=1,Y=1)+P(X=2,Y=1)=\\frac{4}{10},&x=2,y=1\\\\\n1,&x\\geq 2,y\\geq 2\\end{array}\\right.\\]\n\n\nExercise 2.4 Considere o vetor \\((X,Y)\\) de variáveis aleatórias com função de probabilidade conjunta dada por\n\\[P(X=x,Y=y)=\\frac{2^{x+y}}{9},\\] com \\((x,y)\\in\\{0,1\\}^2\\). Encontre a função de distribuição conjunta deste vetor aleatório.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Distribuição de vetores aleatórios discretos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_discretos.html#distribuição-marginal",
    "href": "vetores_aleatorios_discretos.html#distribuição-marginal",
    "title": "2  Distribuição de vetores aleatórios discretos",
    "section": "2.3 Distribuição marginal",
    "text": "2.3 Distribuição marginal\n\nDefinition 2.3 Seja \\(\\textbf{X} = (X_1, \\ldots, X_n)\\) um vetor aleatório discreto. Considere um subvetor \\(\\textbf{X}_a\\) com índices \\(a \\subset \\{1, \\ldots, n\\}\\). A função de probabilidade marginal de \\(\\textbf{X}_a\\) é obtida somando-se a função conjunta sobre todos os valores possíveis das variáveis cujos índices não estão em \\(a\\) (denotados por \\(a^c\\)):\\[P(\\textbf{X}_a = \\textbf{x}_a) = \\sum_{\\textbf{x}_{a^c}} P(X_1=x_1, \\ldots, X_n=x_n)\\]onde o somatório é estendido a todos os valores possíveis de cada \\(x_j\\) tal que \\(j \\notin a\\).\n\nNota: No caso de um vetor bidimensional \\(\\textbf{X} = (X, Y)\\), se quisermos a marginal de \\(X\\), marginalizamos \\(Y\\) somando sobre todos os seus valores:\\[P(X=x) = \\sum_{y=-\\infty}^\\infty P(X=x, Y=y)\\]\n\nExample 2.4 Considere a tabela abaixo, cujo corpo contém a função distribuição de probabilidade conjunta das variáveis \\(X\\) e \\(Y\\).\n\\[\\begin{array}{c|cccc}\\hline\n&y\\\\\nx&  1&  2&  3&  4\\\\ \\hline\n1&  0,1&    0,05&   0,02&   0,07\\\\\n2&  0,08&   0,05&   0,1&    0,19\\\\\n3&  0,1&    0,2&    0,04&   0\\\\ \\hline\\end{array}\\]\nVamos encontrar as distribuições marginais de \\(X\\) e \\(Y\\):\n\\[\\begin{align}\nP(X=1)&=\\sum_{y=1}^4P(X=1,Y=y)=0,24\\\\\nP(X=2)&=\\sum_{y=1}^4P(X=2,Y=y)=0,42\\\\\nP(X=3)&=\\sum_{y=1}^4P(X=3,Y=y)=0,34\\end{align}\\] e \\[\\begin{align}\nP(Y=1)&=\\sum_{x=1}^3P(X=x,Y=1)=0,28\\\\\nP(Y=2)&=\\sum_{x=1}^3P(X=x,Y=1)=0,3\\\\\nP(Y=3)&=\\sum_{x=1}^3P(X=x,Y=1)=0,16\\\\\nP(Y=4)&=\\sum_{x=1}^3P(X=x,Y=1)=0,26.\n\\end{align}\\]\nObserve que a função de probabilidade marginal de \\(X\\) é obtida a partir da soma das linhas da tabela, enquanto que a função de probabilidade marginal de \\(Y\\) é obtida a partir da soma das colunas. Nessas funções podem ser colocadas nas margens da tabela:\n\\[\\begin{array}{c|cccc|c}\\hline\n&y\\\\\nx&  1&  2&  3&  4& P(X=x)\\\\ \\hline\n1&  0,10&   0,05&   0,02&   0,07&0,24\\\\\n2&  0,08&   0,05&   0,10&   0,19&0,42\\\\\n3&  0,10&   0,20&   0,04&   0,00&0,34\\\\ \\hline\nP(Y=y)&0,28&0,30&0,16&0,26&\\end{array}\\]\n\n\nExercise 2.5 Considere a tabela de probabilidade conjunta das variáveis aleatórias discretas \\(X\\) (linhas) e \\(Y\\) (colunas) apresentada abaixo, onde um dos valores foi substituído pela constante \\(k\\).\n\\[\\begin{array}{c|ccc}\\hline\n&y\\\\\nx&  1&  2&  3\\\\ \\hline\n1&  0,15&   0,10&   k\\\\\n2&  0,05&   0,20&   0,15\\\\\n3&  0,05&   0,10&   0,10\\\\ \\hline\\end{array}\\]\n\nEncontre o valor de \\(k\\) para que a tabela represente uma distribuição de probabilidade conjunta válida.\nDetermine as funções de probabilidade marginais de \\(X\\) e \\(Y\\).\n\n\n\nExercise 2.6 Sejam \\(X\\) e \\(Y\\) variáveis aleatórias discretas com a seguinte função de probabilidade conjunta:\n\\[P(X=x,Y=y)=\\frac{e^{−x}x^y}{2^xy!},\\] onde \\(x=1,2,\\ldots\\) e \\(y=0,1,\\ldots\\). Encontre a função de probabilidade marginal de \\(X\\).\n\n\nExercise 2.7 Considere novamente o vetor aleatório \\(\\mathbf{X} = (X_1, X_2, X_3)\\) e os subconjuntos \\(\\tilde{\\mathbf{X}}_1 = \\{X_1\\}\\) e \\(\\tilde{\\mathbf{X}}_2 = \\{X_2, X_3\\}\\). A função de probabilidade conjunta de \\(\\tilde{\\mathbf{X}}_2\\) é dada pela tabela abaixo:\n\n\n\n\\(x_2 \\setminus x_3\\)\n0\n1\n\\(P(X_2 = x_2)\\)\n\n\n\n\n0\n0,2\n0,3\n0,5\n\n\n1\n0,1\n0,4\n0,5\n\n\n\\(P(X_3 = x_3)\\)\n0,3\n0,7\n1,0\n\n\n\nSabendo que \\(X_1\\) assume valores no conjunto \\(\\{0, 1\\}\\) com probabilidades \\(P(X_1=0)=0,6\\) e \\(P(X_1=1)=0,4\\), e que o bloco \\(\\tilde{\\mathbf{X}}_1\\) é independente do bloco \\(\\tilde{\\mathbf{X}}_2\\):\n\nMostre que \\(X_1\\) é independente de \\(X_2\\) e que \\(X_1\\) é independente de \\(X_3\\)\nMostre que \\(X_2\\) e \\(X_3\\) não são independentes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Distribuição de vetores aleatórios discretos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_discretos.html#distribuição-condicional",
    "href": "vetores_aleatorios_discretos.html#distribuição-condicional",
    "title": "2  Distribuição de vetores aleatórios discretos",
    "section": "2.4 Distribuição condicional",
    "text": "2.4 Distribuição condicional\n\nDefinition 2.4 Sejam \\(\\textbf{X}\\) e \\(\\textbf{Y}\\) vetores aleatórios discretos. Então, a distribuição de probabilidade condicional de \\(\\textbf{X}\\) dado \\(\\textbf{Y=y}\\) é definida por\n\\[P(\\textbf{X}=\\textbf{x}|\\textbf{Y}=\\textbf{y})=\\frac{P(\\textbf{X}=\\textbf{x},\\textbf{Y}=\\textbf{y})}{P(\\textbf{Y}=\\textbf{y})},\\] e a respectiva função distribuição é dada por\n\\[F(\\textbf{x}|\\textbf{y})=P(\\textbf{X}\\leq \\textbf{x}|\\textbf{Y}=\\textbf{y}).\\]\n\n\nExample 2.5 Considere a seguinte distribuição conjunta:\n\\[P(X=x,Y=y)=\\left\\{\\begin{array}{ll}0,1,&x=0,y=0\\\\\n0,2,&x=0,y=1\\\\\n0,3,&x=1,y=0\\\\\n0,4,&x=1,y=1\\\\\n0,&\\hbox{caso contrário}\\end{array}\\right.\\]\nQual é a distribuição de \\(Y\\) dado \\(X=1\\)?\nSolução: Primeiro, temos que \\[P(X=1)=P(X=1,Y=0)+P(X=1,Y=1)=0,7\\] logo, \\[P(Y=y|X=1)=\\left\\{\\begin{array}{ll}\n\\frac{3}{7},&y=0\\\\\n\\frac{4}{7},&y=1\\\\\n0,&\\hbox{caso contrário}\\end{array}\\right.\\]\n\n\nExercise 2.8 Considere a variável aleatória bidimensional \\((X, Y)\\) com a seguinte função de probabilidade conjunta:\n\\[P(X=x, Y=y) = \\begin{cases}\nk, & x=1, y=1 \\\\\n2k, & x=1, y=2 \\\\\n3k, & x=2, y=1 \\\\\n4k, & x=2, y=2 \\\\\n0, & \\text{caso contrário}\n\\end{cases}\\]\n\nDetermine o valor da constante \\(k\\).\nCalcule a probabilidade marginal de \\(X\\), ou seja, \\(P(X=x)\\).\nEncontre a distribuição de probabilidade condicional de \\(X\\) dado que \\(Y=2\\).\n\n\n\nExercise 2.9 Considere a função de probabilidade abaixo: \\[P(X=x,Y=y)={y \\choose x}\\frac{1}{2^{2y}}\\] onde \\(x=0,\\ldots,y\\) e \\(y=1,2,\\ldots\\). Encontre a função de probabilidade de \\(X\\) dado \\(Y=y\\).\n\n\nExercise 2.10 Sejam\n\\[P(X=x|Y=y)={y\\choose x}\\frac{1}{2^y}\\] onde \\(x=0,\\ldots,y\\) e \\[P(Y=y)=\\frac{e^{−1}}{y!},\\] onde \\(y=0,1,\\ldots\\). Encontre a função de probabilidade de \\(Y\\) dado \\(X=x\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Distribuição de vetores aleatórios discretos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_discretos.html#funções-de-vetores-aleatórios-discretos",
    "href": "vetores_aleatorios_discretos.html#funções-de-vetores-aleatórios-discretos",
    "title": "2  Distribuição de vetores aleatórios discretos",
    "section": "2.5 Funções de vetores aleatórios discretos",
    "text": "2.5 Funções de vetores aleatórios discretos\nSeja \\(X\\) uma variável aleatória e seja \\(g(.)\\) uma função real. Considere a variável \\(Y=g(X)\\), com \\(g:\\mathbb{R}\\rightarrow \\mathbb{Z}\\). É sempre verdade que\n\\[P(Y\\in A)=P(g(X)\\in A)\\].\nSe \\(X\\) é uma variável discreta, então\n\\[P(Y\\in A)=\\sum_{x:g(x)\\in A}P(X=x).\\]\n\nExample 2.6 Seja \\(X\\) uma variável discreta com\n\\[P(X=x)=\\begin{cases}0,1,& x=-1\\\\ 0,2,& x=0,\\\\ 0,3,&x=1\\\\ 0,4,& x=2 \\end{cases}.\\] Vamos encontrar a função de probabilidade de \\(Y=X^2\\).\n\\[\\begin{array}{c|cccc}\\hline\nx&  -1 &    0&  1&  2& \\\\ \\hline\ny=x^2   &1  &0& 1&  4\\\\ \\hline\nP(X=x)  &0,1    &0,2    &0,3&   0,4\\\\\n\\hline \\end{array}\\]\nDeste modo,\n\\[\\begin{align}\nP(Y=0)&=P(X=0)=0,2\\\\\nP(Y=1)&=P(X=-1)+P(X=1)=0,4\\\\\nP(Y=4)&=P(X=2)=0,4\n\\end{align}\\]\n\n\nExercise 2.11 Seja \\(X\\) uma variável discreta com\\[P(X=x)=\\begin{cases}0,2,& x=-1\\\\ 0,1,& x=0,\\\\ 0,4,&x=1\\\\ 0,3,& x=2 \\end{cases}.\\] Encontre a função de probabilidade de \\(Y=|X|\\).\n\nObserve que a extensão é natural para vetores aleatórios. Seja \\(\\textbf{X}\\) um vetor aleatório discreto de comprimento \\(n\\) e seja \\(g:\\mathbb{R}^n\\rightarrow \\mathbb{Z}^m\\). Então a função de probabilidade de \\(\\textbf{Y}=g(\\textbf{X})\\) é dada por\n\\[P(\\textbf{Y}=\\textbf{y})=P(g(\\textbf{X})=\\textbf{y})=\\sum_{\\textbf{x}\\in\\mathbb{Z}^n:g(\\textbf{x})=\\textbf{y}}P(\\textbf{X}=\\textbf{x}).\\]\n\nExample 2.7 Seja \\(\\textbf{X}=(X_1,X_2)\\) um vetor aleatório com função de probabilidade conjunta dada por\n\\[P(\\textbf{X}=\\textbf{x})=\\frac{x_1+x_2}{12},\\] onde \\((x_1,x_2)\\in\\{1,2\\}^2\\). Vamos encontrar a função de probabilidade de \\(\\textbf{Y}=g(\\textbf{X})=(x_1,x_1+x_2).\\) Observe que\n\\[\\begin{array}{cc|cc}\nx_1 &x_2    &y_1 & y_2 \\\\ \\hline\n1   &1    & 1 & 2\\\\\n1   &2   & 1 & 3\\\\\n2   &1   & 2 & 3\\\\\n2   &2   & 2 & 4\\\\ \\hline\n\\end{array}\n\\] Então,\n\\[\\begin{align}\nP(\\textbf{Y}=(1,2))=P(\\textbf{X}=(1,1))=\\frac{2}{12}\\\\\nP(\\textbf{Y}=(1,3))=P(\\textbf{X}=(1,2))=\\frac{3}{12}\\\\\nP(\\textbf{Y}=(2,3))=P(\\textbf{X}=(2,1))=\\frac{3}{12}\\\\\nP(\\textbf{Y}=(2,4))=P(\\textbf{X}=(2,2))=\\frac{4}{12}\\\\\n\\end{align}\\]\n\n\nExercise 2.12 Seja \\(\\textbf{X}=(X_1,X_2)\\) um vetor aleatório com função de probabilidade conjunta dada por\\[P(\\textbf{X}=\\textbf{x})=\\frac{x_1+x_2}{12},\\] onde\\((x_1,x_2)\\in\\{1,2\\}^2\\). Encontre a função de probabilidade de\\(\\textbf{Y}=g(\\textbf{X})=(X_1-X_2, X_1+X_2).\\)\n\nAté o momento, utilizamos um vetor aleatório discreto de comprimento \\(n\\) para encontrar a distribuição de \\(\\textbf{Y}=g(\\textbf{X})\\), também de comprimento \\(n\\). Contudo, é comum ter \\(g:\\mathbb{R}^n\\rightarrow \\mathbb{Z}^m\\), onde \\(m&lt;n\\). Para o caso no qual \\(n=2\\) e \\(m=1\\), teremos\n\\[P(Y=y)=P(g(\\textbf{X})=y)=\\sum_{\\textbf{x}\\in\\mathbb{Z}^2:g(\\textbf{x})=y}P(X_1=x_1,X_2=x_2).\\] Sem perda de generalidade, assuma que para um dado \\(y\\), existe uma função \\(h\\) tal que a condição \\(g(x_1, x_2) = y\\) é equivalente a \\(x_1 = h(x_2, y)\\). Então \\[\\begin{align}P(Y=y)&=\\sum_{\\textbf{x}\\in\\mathbb{Z}^2:g(\\textbf{x})=y}P(X_1=h(x_2,y),X_2=x_2)\\\\&=\\sum_{x_2=-\\infty}^\\infty P(X_1=h(x_2,y),X_2=x_2).\\end{align}\\]\n\nProposition 2.2 Soma de variáveis aleatórias Seja \\(\\textbf{X}=(X_1,X_2)\\) um vetor aleatório discreto e considere da variável \\(Y=g(X_1,X_2)=X_1+X_2\\). Observe que é possível escrever \\[x_1=y-x_2=h(y,x_2),\\] logo \\[P(Y=y)=\\sum_{x_2=-\\infty}^\\infty P(X_1=y-x_2,X_2=x_2).\\]\n\n\nExample 2.8 A função de probabilidade de \\(\\textbf{X}=(X_1,X_2)\\) é dada na tabela abaixo:\n\\[\\begin{array}{c|cc}\\hline & x_1 \\\\  \nx_2 & -1 & 1 \\\\ \\hline\n0 & 0,10 & 0,05\\\\\n1 & 0,15 & 0,20\\\\\n2 & 0,25 & 0,25 \\\\ \\hline\\end{array}\\]\nA função de probabilidade de \\(Y=X_1+X_2\\) é dada por \\[\\begin{align}P(Y=y)&=\\sum_{x_2=0}^2 P(X_1=y-x_2,X_2=x_2)\\\\&=P(X_1=y,X_2=0)+P(X_1=y-1,X_2=1)+P(X_1=y-2,X_2=2)\\end{align}\\] Por exemplo, para \\(y=-1\\) teremos\n\\[\\begin{align}P(Y=-1)&=P(X_1=-1,X_2=0)+P(X_1=-2,X_2=1)+P(X_1=-3,X_2=2)\\\\&=P(X_1=-1,X_2=0)=0,1\\end{align}\\]\n\n\nExercise 2.13 Com base no exemplo anterior, determine os valores restantes da função de probabilidade de \\(Y\\).\n\n\n2.5.1 Alguns resultados importantes\n\n2.5.1.1 Funções indicadoras\nVamos discutir alguns resultados importantes sobre funções de vetores discretos. Contudo, é relevante a discussão de alguns resultados relacionados a funções indicadoras.\n\nFunção indicadora.Seja \\(A \\subset \\Omega\\). A função \\(I_A: \\Omega \\rightarrow \\{0,1\\}\\), definida por\\[I_A(x)=\\begin{cases} 1, & \\text{se } x \\in A \\\\ 0, & \\text{se } x \\notin A \\end{cases}\\]é denominada função indicadora do conjunto \\(A\\)\n\n\nIndicadora da interseção \\[I_{A\\cap B}(x)=I_A(x)I_B(x)\\]\n\n\nExample 2.9 Seja \\(A=\\{x\\in \\mathbb{N}:x \\leq 5 \\}\\) e \\(B=\\{x\\in\\mathbb{N}:x\\hbox{ é ímpar}\\}\\). É simples notar que os valores que satisfazem simultaneamente as restrições de \\(A\\) e \\(B\\) são 1, 3 e 5. Vamos chegar a essa conclusão utilizando indicadoras:\n\\[\\begin{array}{c|cccccc|ccc}\\hline\nx & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & \\cdots \\\\ \\hline\nI_A(x)& 1 & 1 & 1& 1 & 1 & 1 & 0 & 0 & \\cdots & \\\\\\hline\nI_B(x)& 0 & 1 & 0& 1 & 0 & 1 & 0 & 1 & \\cdots & \\\\\\hline\nI_{A\\cap B}(x)& 0 & 1 & 0& 1 & 0 & 1 & 0 & 0 & 0 & \\\\\\hline\\end{array}\\]\n\n\nExercise 2.14 Considere o conjunto universo \\(\\Omega = \\{0, 1, 2, 3, 4, 5, 6, 7\\}\\). Definimos dois subconjuntos de \\(\\Omega\\) através das seguintes propriedades:\\(A = \\{x \\in \\Omega : x \\text{ é múltiplo de 3}\\}\\)\\(B = \\{x \\in \\Omega : x^2 - 7x + 10 \\leq 0\\}\\)A) Liste os elementos de \\(A\\) e \\(B\\) e determine seus respectivos vetores indicadores \\(I_A(x)\\) e \\(I_B(x)\\) para todo \\(x \\in \\Omega\\).B) Utilizando a proposição \\(I_{A \\cap B}(x) = I_A(x)I_B(x)\\), complete a tabela abaixo para identificar os elementos da interseção:\n\\[\\begin{array}{c|cccccccc}\n\\hline\nx & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\\\ \\hline\nI_A(x) & & & & & & & & \\\\ \\hline\nI_B(x) & & & & & & & & \\\\ \\hline\nI_A(x)I_B(x) & & & & & & & & \\\\ \\hline\n\\end{array}\\]C) Com base no resultado da última linha da tabela, escreva o conjunto \\(A \\cap B\\) por extensão.\n\nAs funções indicadoras são úteis para definir para quais valores as probabilidades são positivas. Por exemplo, em vez que escrever\n\\[P(X=x)=p^x(1-p)^{1-x}\\] para \\(x\\in\\{0,1\\}\\), podemos escrever\n\\[P(X=x)=p^x(1-p)^{1-x}I_{\\{0,1\\}}(x).\\]\n\n\n2.5.1.2 O Método da Indução Matemática\nA demonstração por indução é uma ferramentada matemática para provar que uma afirmação é verdadeira para todos os números inteiros a partir de um valor inicial. O método divide-se em dois passos fundamentais:\n\nBase da Indução: Verificamos se a afirmação vale para o primeiro caso (geralmente \\(n=1\\)).\nPasso Indutivo: Assumimos que a afirmação vale para um número \\(k\\) (nossa Hipótese de Indução) e provamos que, a partir disso, ela obrigatoriamente vale para \\(k+1\\).\n\n\nExample 2.10 A Soma dos Primeiros Inteiros. Prove que, para todo \\(n \\geq 1\\):\\[1 + 2 + 3 + \\ldots + n = \\frac{n(n+1)}{2}\\]\nDemonstração:\n\nBase: Para \\(n=1\\):O lado esquerdo é \\(1\\). O lado direito é \\(\\frac{1(1+1)}{2} = 1\\). A base está verificada.\nHipótese de Indução (H.I.): Supomos que para um \\(k\\) qualquer a fórmula é válida:\\[S_k = 1 + 2 + \\ldots + k = \\frac{k(k+1)}{2}\\]\nPasso Indutivo: Queremos mostrar que a soma até \\(k+1\\) segue a mesma lógica. Note que a soma até \\(k+1\\) é a soma até \\(k\\) mais o próximo termo:\\[S_{k+1} = \\underbrace{1 + 2 + \\ldots + k}_{S_k} + (k+1)\\]Substituindo pela nossa H.I.:\\[S_{k+1} = \\frac{k(k+1)}{2} + (k+1)\\]Colocando em um denominador comum:\\[S_{k+1} = \\frac{k(k+1) + 2(k+1)}{2} = \\frac{(k+1)(k+2)}{2}\\]Como chegamos na fórmula original com \\(n\\) substituído por \\(k+1\\), a prova está concluída.\n\n\n\nExercise 2.15 Utilize o método da indução matemática para provar que a soma das primeiras \\(n\\) potências de 2 (começando em \\(2^1\\)) é dada por:\\[2^1 + 2^2 + 2^3 + \\ldots + 2^n = 2^{n+1} - 2\\]\n\n\n\n\n2.5.2 Distribuição Binomial como soma de Bernoullis independentes\n\nRecordando Dizemos que \\(X\\sim\\hbox{Bernoulli(p)}\\) se sua função de probabilidade é dada por\n\\[P(X=x)=p^{x}(1-p)^{1-x}I_{\\{0,1\\}}(x).\\]\nDizemos que \\(Y\\sim\\hbox{Binomial}(n,p)\\) se sua função de probabilidade é dada por\n\\[P(Y=y)={n\\choose y}p^{y}(1-p)^{n-y}I_{\\{0,\\ldots,n\\}}(y).\\]\n\n\nResultado chave: Para \\(0&lt;y&lt;n\\) natural, \\[{n-1\\choose y}+{n-1\\choose y-1}={n\\choose y}.\\]\n\nSejam \\(X_1\\) e \\(X_2\\) variáveis aleatórias independentes com distribuição Bernoulli(\\(p\\)). Vamos encontrar a função de probabilidade de \\(Y=X_1+X_2\\). Primeiro, já sabemos que\n\\[P(Y=y)=\\sum_{x_2=0}^1 P(X_1=y-x_2,X_2=x_2),\\] e, como \\(X_1\\) é independente de \\(X_2\\),\n\\[P(Y=y)=\\sum_{x_2=0}^1 P(X_1=y-x_2)P(X_2=x_2).\\] como \\(X_1\\) e \\(X_2\\) tem distribuição Bernoulli(\\(p\\)), teremos\n\\[\\begin{align}P(Y=y)&=\\sum_{x_2=0}^1 \\left[p^{y-x_2}(1-p)^{1-y+x_2} I_{\\{0,1\\}}(y-x_2)\\right]\\left[p^{x_2}(1-p)^{1-x_2}I_{\\{0,1\\}}(x_2)\\right]\\\\&=p^{y}(1-p)^{2-y}\\sum_{x_2=0}^1 I_{\\{0,1\\}}(x_2)I_{\\{0,1\\}}(y-x_2)\\end{align},\\]\nSabemos que \\(y\\in\\{0,1,2\\}\\). Vamos obter o valor de \\(\\sum_{x_2=0}^1 I_{\\{0,1\\}}(x_2)I_{\\{0,1\\}}(y-x_2)\\) para cada \\(y\\).\n\nse \\(y=0\\),\n\n\\[\\begin{array}{l|cc|c}\n\\hline\nx_2 & 0 & 1 &\\hbox{soma}\\\\ \\hline\nI_{\\{0,1\\}}(x_2) & 1& 1\\\\ \\hline\nI_{\\{0,1\\}}(y-x_2)& 1& 0 \\\\ \\hline\nI_{\\{0,1\\}}(x_2)I_{\\{0,1\\}}(y-x_2) & 1& 0 & 1\\\\ \\hline\n\\end{array}\\] logo, \\(\\sum_{x_2=0}^1 I_{\\{0,1\\}}(x_2)I_{\\{0,1\\}}(0-x_2)=1\\)\n\nse \\(y=1\\),\n\n\\[\\begin{array}{l|cc|c}\n\\hline\nx_2 & 0 & 1 &\\hbox{soma}\\\\ \\hline\nI_{\\{0,1\\}}(x_2) & 1& 1\\\\ \\hline\nI_{\\{0,1\\}}(y-x_2)& 1& 1 \\\\ \\hline\nI_{\\{0,1\\}}(x_2)I_{\\{0,1\\}}(y-x_2) & 1& 1 & 2\\\\ \\hline\n\\end{array}\\] logo, \\(\\sum_{x_2=0}^1 I_{\\{0,1\\}}(x_2)I_{\\{0,1\\}}(1-x_2)=2\\)\n\nse \\(y=2\\),\n\n\\[\\begin{array}{l|cc|c}\n\\hline\nx_2 & 0 & 1 & \\hbox{soma}\\\\ \\hline\nI_{\\{0,1\\}}(x_2) & 1& 1\\\\ \\hline\nI_{\\{0,1\\}}(y-x_2)& 0& 1 \\\\ \\hline\nI_{\\{0,1\\}}(x_2)I_{\\{0,1\\}}(y-x_2) & 0& 1 & 1\\\\ \\hline\n\\end{array}\\] logo, \\(\\sum_{x_2=0}^1 I_{\\{0,1\\}}(x_2)I_{\\{0,1\\}}(2-x_2)=1\\)\nAgora, note que\n\\[\\begin{array}{c|ccc}\\hline\ny & 0 & 1 & 2 \\\\ \\hline\n\\sum_{x_2=0}^1 I_{\\{0,1\\}}(x_2)I_{\\{0,1\\}}(y-x_2) & 1 & 2 & 1 \\\\ \\hline\n{2 \\choose y} &  1 & 2 & 1 \\\\ \\hline\n\\end{array}\\]\nlogo,\n\\[P(Y=y)={2\\choose y}p^y(1-p)^{2-y}I_{\\{0,1,2\\}}(y).\\]\n\nExercise 2.16 Sejam \\(X_1,X_2,X_3\\) variáveis aleatórias independentes com distribuição Bernoulli\\((p)\\). Mostre que a distribuição de \\(Y=X_1+X_2+X_3\\) é\n\\[P(Y=y)={3 \\choose y}p^{y}(1-p)^{3-y}I_{\\{0,1,2,3\\}}(y)\\] Dica: Você já sabe que \\(Z=X_1+X_2\\) é \\[P(Z=z)={2\\choose z}p^z (1-p)^{2-z}I_{\\{0,1,2\\}}(z),\\] e, como \\(Y=X_1+X_2+X_3=Z+X_3\\), basta encontrar \\[P(Y=y)=\\sum_{x_3=0}^1 P(Z=y-x_3,X_3=x_3).\\]\n\nObserve que \\(X_1+X_2\\sim\\hbox{Binomial}(2,p)\\) e \\(X_1+X_2+X_3\\sim\\hbox{Binomial}(3,p)\\). De fato, sejam \\(X_1,\\ldots,X_n\\) variáveis aleatórias independentes com distribuição Bernoulli(\\(p\\)). Suponha, por indução, que\n\\[Z=\\sum_{i=1}^{n-1} X_i\\sim\\hbox{Binomial}(n-1,p).\\] Então \\[Y=\\sum_{i=1}^n X_i=X_n+Z\\] e\n\\[\\begin{align}\nP(Y=y)&=\\sum_{x=0}^1 P(X_n=x, Z=y-x)=\\sum_{x=0}^1 P(X_n=x)P(Z=y-x)\\\\\n&=\\sum_{x=0}^1 P(X_n=x)P(Z=y-x)\\\\&=\\sum_{x=0}^1 \\left[p^x(1-p)^{1-x}I_{\\{0,1\\}}(x)\\right]\\left[{n-1\\choose y-x}p^{y-x}(1-p)^{n-1-y+x}I_{\\{0,\\ldots,n-1\\}}(y-x)\\right]\\\\\n&=p^y(1-p)^{n-y}\\sum_{x=0}^1\\left[{n-1\\choose y-x}I_{\\{0,1\\}}(x)I_{\\{0,\\ldots,n-1\\}}(y-x)\\right].\n\\end{align}\\]\nVamos analizar o somatório acima:\n\nse \\(y=0\\), teremos que \\(I_{\\{0,\\ldots,n-1\\}}(0-x)=1\\) somente quando \\(x=0\\). Logo,\n\n\\[\\sum_{x=0}^1\\left[{n-1\\choose y-x}I_{\\{0,1\\}}(x)I_{\\{0,\\ldots,n-1\\}}(0-x)\\right]={n-1\\choose 0}=1={n\\choose 0}\\]\n\nse \\(y=n\\), teremos que \\(I_{\\{0,\\ldots,n-1\\}}(n-x)=1\\) somente quando \\(x=1\\). Logo,\n\n\\[\\sum_{x=0}^1\\left[{n-1\\choose y-x}I_{\\{0,1\\}}(x)I_{\\{0,\\ldots,n-1\\}}(n-x)\\right]={n-1\\choose n-1}=1={n\\choose n}\\] * para \\(y=1,\\ldots,n-1\\), teremos que \\(I_{\\{0,\\ldots,n-1\\}}(y-x)=1\\) para \\(x=0,1\\). Logo,\n\\[\\sum_{x=0}^1\\left[{n-1\\choose y-x}I_{\\{0,1\\}}(x)I_{\\{0,\\ldots,n-1\\}}(y-x)\\right]={n-1\\choose y}+{n-1\\choose y-1}={n\\choose y}\\]\nportanto,\n\\[\\begin{align}\nP(Y=y)&=p^y(1-p)^{n-y}\\sum_{x=0}^1\\left[{n-1\\choose y-x}I_{\\{0,1\\}}(x)I_{\\{0,\\ldots,n-1\\}}(y-x)\\right]\\\\&={n\\choose y}p^y(1-p)^{n-y}I_{\\{0,\\ldots,n\\}}(y).\n\\end{align}\\]\n\nExercise 2.17 Sejam \\(X_1,X_2\\) variáveis aleatórias independentes, onde \\(X_i\\sim\\hbox{Binomial}(m_i,p),\\) com \\(i=1,2\\).\n\nMostre que \\(Y=X_1+X_2\\sim\\hbox{Binomial}(m_1+m_2,p)\\). Sugestão: escreva \\(X_i\\) como soma de Bernoullis independentes.\nE qual a distribuição de \\(Z=X_1+\\cdots+X_n\\), onde \\(X_i\\sim\\hbox{Binomial}(m_i,p)\\) e \\(X_1,\\ldots,X_n\\) são independentes?\n\n\n\n\n2.5.3 Soma de Poissons independentes\n\nRecordando Dizemos que \\(X\\sim\\hbox{Poisson}(\\lambda)\\) se sua função de probabilidade é dada por\n\\[P(X=x)=\\frac{e^{-\\lambda}\\lambda^x}{x!}I_{\\mathbb{N}}(x)\\] e \\(\\lambda&gt;0\\).\nResultado chave (Teorema binomial): Para quaisquer \\(a,b\\), \\[\\sum_{x=0}^n{ n\\choose x}a^x b^{n-x}=(a+b)^n.\\]\n\nSejam \\(X_1,X_2\\) variáveis aleatórias independentes com distribuição \\(\\hbox{Poisson}(\\lambda)\\). Seja \\(Y=X_1+X_2\\). Note que\n\\[\\begin{align}P(Y=y)&=\\sum_{x_2=0}^\\infty P(X_1=y-x_2,X_2=x_2)\n\\\\&=\\sum_{x_2=0}^\\infty \\frac{e^{-\\lambda}\\lambda^{y-x_2}}{(y-x_2)!}I_{\\mathbb{N}}(y-x_2)\\frac{e^{-\\lambda}\\lambda^{x_2}}{x_2!}I_{\\mathbb{N}}(x_2)\\\\\n&=e^{-2\\lambda}\\lambda^{y}\\sum_{x_2=0}^\\infty \\frac{1}{x_2!(y-x_2)!}I_{\\mathbb{N}}(y-x_2)I_\\mathbb{N}(x_2).\n\\end{align}\\] Para que \\(I_\\mathbb{N}(y-x_2)=1\\), é necessário que \\(x_2\\leq y\\). Logo, \\[\\begin{align}P(Y=y)&=e^{-2\\lambda}\\lambda^{y}\\sum_{x_2=0}^{y} \\frac{1}{x_2!(y-x_2)!}\\\\\n&=\\frac{e^{-2\\lambda}\\lambda^{y}}{y!}\\sum_{x_2=0}^{y} \\frac{y!}{x_2!(y-x_2)!}=\\frac{e^{-2\\lambda}\\lambda^{y}}{y!}\\sum_{x_2=0}^y{ y\\choose x_2}.\n\\end{align}\\]\nAgora, observe que\n\\[\\sum_{x_2=0}^y{ y\\choose x_2}=\\sum_{x_2=0}^y{ y\\choose x_2}1^{x_2}1^{y-x_2}=(1+1)^y=2^y,\\] portanto, \\[\\begin{align}P(Y=y)&=\\frac{e^{-2\\lambda}\\lambda^y}{y!}2^y=\\frac{e^{-2\\lambda}(2\\lambda)^y}{y!}.\n\\end{align}\\]\nIsso implica que \\(X_1+X_2\\sim\\hbox{Poisson}(2\\lambda)\\).\n\nExercise 2.18 Sejam \\(X_1\\) e \\(X_2\\) variáveis aleatórias independentes com \\(X_1\\sim\\hbox{Poisson}(\\lambda_1)\\) e \\(x_2\\sim\\hbox{Poisson}(\\lambda_2)\\).\n\nMostre que \\(X_1+X_2\\sim\\hbox{Poisson}(\\lambda_1+\\lambda_2)\\)\nCom base nesse resultado, qual é a distribuição de \\(\\sum_{i=1}^n X_i\\) quando as variáveis são independentes com \\(X_i\\sim\\hbox{Poisson}(\\lambda_i)\\)?\n\n\n\nExercise 2.19 Sejam \\(X_1\\) e \\(X_2\\) variáveis aleatórias independentes com \\(X_1\\sim\\hbox{Poisson}(\\lambda_1)\\) e \\(x_2\\sim\\hbox{Poisson}(\\lambda_2)\\). Encontre\n\\[P(X_1=x|X_1+X_2=n).\\]\n\n\n\n2.5.4 Distribuição binomial negativa como soma de distribuições geométricas independentes\n\nRecordando Dizemos que \\(X\\sim\\hbox{Geométrica}(p)\\) se sua função de probabilidade é dada por \\[P(X=x)=p(1-p)^x I_{\\mathbb{N}}(x)\\] e dizemos que \\(Y\\sim\\hbox{Binomial Negativa}(n,p)\\) se sua função de probabilidade é dada por \\[P(Y=y)={y+n-1\\choose y}p^n(1-p)^y I_{\\mathbb{N}}(y).\\]\n\n\nResultado relevante: para \\(t&gt;0\\),\n\\[\\sum_{j=0}^m{m+t-j\\choose m-j}={m+t+1\\choose m}\\]\n\n\nExercise 2.20 Sejam \\(X_1,X_2\\) variáveis aleatórias independentes com distribuição Geométrica\\((p)\\). Mostre que \\(Y=X_1+X_2\\sim\\hbox{Binomial Negativa}(2,p)\\)\n\n\nExercise 2.21 Sejam \\(X_1,X_2,X_3\\) variáveis aleatórias independentes com distribuição Geométrica\\((p)\\). Mostre que \\(Y=X_1+X_2+X_3\\sim\\hbox{Binomial Negativa}(3,p)\\)\n\n\nExercise 2.22 Sejam \\(X_1,X_2,\\ldots,X_n\\) variáveis aleatórias independentes com distribuição Geométrica\\((p)\\). Mostre que \\(Y=\\sum_{i=1}^nX_i\\sim\\hbox{Binomial Negativa}(n,p)\\). Especificamente, suponha por indução que\n\\[Z=\\sum_{i=1}^{n-1}X_i\\sim\\hbox{Binomial Negativa}(n-1,p).\\] Então, conclua o exercício encontrando a distribuição de \\(Y=Z+X_n\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Distribuição de vetores aleatórios discretos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_continuos.html",
    "href": "vetores_aleatorios_continuos.html",
    "title": "3  Distribuição de vetores aleatórios contínuos",
    "section": "",
    "text": "3.1 Função de densidade conjunta\nOs objetivos deste capítulo são:\nSeja \\(\\textbf{X}=(X_1,…,X_n)\\) um vetor de variáveis aleatórias absolutamente contínuas. Dizemos que a função contínua\n\\[f(\\textbf{x})=f(x_1,…,x_n)\\] é a função de densidade conjunta de \\(\\textbf{X}\\) se\n\\[P(X_1\\in A_1,\\ldots,X_n\\in A_n)=\\int_{A_1}\\cdots\\int_{A_n}f(\\textbf{x})d\\textbf{x}.\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distribuição de vetores aleatórios contínuos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_continuos.html#função-de-densidade-conjunta",
    "href": "vetores_aleatorios_continuos.html#função-de-densidade-conjunta",
    "title": "3  Distribuição de vetores aleatórios contínuos",
    "section": "",
    "text": "Proposition 3.1 Dizemos que \\(f(\\textbf{x})\\) (contínua) é a função de densidade conjunta para um vetor aleatório \\(\\textbf{X}\\) se\n\\[f(\\textbf{x})\\geq 0,\\;\\;\\forall\\;\\textbf{x}\\in\\mathbb{R}^n\\] e \\[\\int_{\\mathbb{R}^n}f(\\textbf{x})d\\textbf{x}=1.\\]\n\n\nNota importante Observe que \\[P(\\textbf{X}\\in A)=\\int_{A}f(\\textbf{x})d\\textbf{x}=\\int_{\\mathbb{R}^n}f(\\textbf{x})I_{A}(\\textbf{x})d\\textbf{x}.\\]\nEm palavras, o conjunto da função indicadora é sempre o conjunto de integração.\n\n\nExample 3.1 Mostre que \\[f(x,y)=xe^{−(1+y)x},\\] com \\(x,y&gt;0\\) é uma função de densidade conjunta.\nSolução. Note que \\(x&gt;0\\), logo \\(f(x,y)&gt;0\\) para todo \\((x,y)&gt;0\\). Portanto, basta mostrar que\n\\[\\int_{\\mathbb{R}^2} f(x,y)dxdy=\\int_{\\mathbb{R}^2}xe^{-(1+y)x}I_{\\mathbb{R}^+}(x)I_{\\mathbb{R}^+}(y)dxdy=\\int_0^\\infty\\int_0^\\infty xe^{-(1+y)x}dxdy=1\\]\nRecorde que, para \\(a,b&gt;0\\), \\[\\int_0^\\infty u^{a-1}e^{-bu}du=\\frac{\\Gamma(a)}{b^a}.\\]\nPortanto, considerando apenas a integral em \\(x\\), teremos\n\\[\\int_0^\\infty xe^{-x(1+y)}dx=\\frac{\\Gamma(2)}{(1+y)^2}=\\frac{1!}{(1+y)^2}=\\frac{1}{(1+y)^2}.\\] Então, \\[\\int_0^\\infty\\int_0^\\infty xe^{-(1+y)x}dxdy=\\int_0^\\infty \\frac{1}{(1+y)^2}dy\\]\nA integral da direita pode ser resolvida por integração por substituição. Fazendo \\(u=1+y\\), teremos e \\(du=dy\\) e\n\\[\\begin{align}\\int_0^\\infty \\frac{1}{(1+y)^2}I_{\\mathbb{R}^+}(y)dy&=\\int_0^\\infty \\frac{1}{u^2}I_{\\mathbb{R}^+ }(u-1)du\\\\&=\\int_1^\\infty \\frac{1}{u^2}du=\\left.-\\frac{1}{u}\\right|_1^\\infty=1.\\end{align}\\] Portanto, a função dada é uma densidade conjunta.\n\n\nExercise 3.1 Mostre que \\[f(x,y)=x^2e^{−(1+y)x},\\] com \\(x,y&gt;0\\) é uma função de densidade conjunta.\n\n\nExample 3.2 Seja \\[f(x,y)=kx^2,\\] onde \\(x\\in(0,1)\\) e \\(y\\in(0,x)\\). Encontre o valor de \\(k\\) para que \\(f(x,y)\\) seja uma função densidade.\nSolução. Como \\(x&gt;0\\), temos que \\(f(x,y)&gt;0\\) sempre que \\(k&gt;0\\). Portanto, basta encontrar o valor \\(k&gt;0\\) tal que\n\\[\\int_{\\mathbb{R}^2}f(x,y)dxdy=\\int_{\\mathbb{R}^2}kx^2 I_{(0,1)}(x)I_{(0,x)}(y)dxdy=\\int_0^1\\int_0^x kx^2 dydx=1\\]\nA integral em \\(y\\) é\n\\[\\int_0^x kx^2 dy=\\left.kx^2y\\right|_0^x=kx^3\\] logo, \\[\\int_0^1\\int_0^x kx^2 dydx=\\int_0^1 kx^3dx=\\left.\\frac{k}{4}x^4\\right|_0^1=\\frac{k}{4}.\\] Portanto, \\(f(x,y)\\) será função densidade conjunta quando \\(k=4\\).\n\n\nExercise 3.2 Seja \\[f(x,y)=k yx^2,\\] onde \\(x\\in(0,1)\\) e \\(y\\in(0,x)\\). Encontre o valor de \\(k\\) para que \\(f(x,y)\\) seja uma função densidade.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distribuição de vetores aleatórios contínuos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_continuos.html#função-de-distribuição-conjunta",
    "href": "vetores_aleatorios_continuos.html#função-de-distribuição-conjunta",
    "title": "3  Distribuição de vetores aleatórios contínuos",
    "section": "3.2 Função de distribuição conjunta",
    "text": "3.2 Função de distribuição conjunta\n\nNota importante Recorde que \\[I_{A\\cap B}(\\textbf{x})=I_{A}(\\textbf{x})I_{B}(\\textbf{x}).\\] Em particular, sejam \\(A\\) e \\(B\\) os intervalos \\((a_1,a_2)\\) e \\((b_1,b_2)\\). Então\n\\[I_{A\\cap B}(x)=I_{(a_1,a_2)}(x)I_{(b_1,b_2)}(x)=I_{(\\max\\{a_1,b_1\\},\\min\\{a_2,b_2\\})}(x).\\]\n\n\nExample 3.3 Simplificação de Indicadoras Simplifique o produto das seguintes funções indicadoras em uma única função indicadora:\\[g(x) = I_{(2, 10)}(x)I_{(5, 15)}(x)I_{(-\\infty, 8)}(x)\\]\nSolução:\nAplicamos a propriedade da interseção passo a passo, utilizando \\(I_{A \\cap B}(x) = I_{(\\max\\{a_1,b_1\\}, \\min\\{a_2,b_2\\})}(x)\\).\n\nPrimeiro par: \\(I_{(2, 10)}(x)I_{(5, 15)}(x)\\)\nLimite inferior: \\(\\max\\{2, 5\\} = 5\\)\nLimite superior: \\(\\min\\{10, 15\\} = 10\\)\nIndicadora resultante: \\(I_{(5,10)}(x)\\)\n\nMultiplicando pelo terceiro termo: \\(I_{(5, 10)}(x)I_{(-\\infty, 8)}(x)\\)\nLimite inferior: \\(\\max\\{5, -\\infty\\} = 5\\) Limite superior: \\(\\min\\{10, 8\\} = 8\\) *Resultado final: \\(I_{(5, 8)}(x)\\)\n\n\nExercise 3.3 Seja a função \\(h(x)\\) definida pelo produto de três restrições de intervalos:\\[h(x) = I_{(-3, 4)}(x)I_{(0, 7)}(x) \\cdot I_{(x, \\infty)}(2)\\]Dica: Note que \\(I_{(x, \\infty)}(2)\\) é o mesmo que dizer que \\(x &lt; 2\\).\n\nReescreva \\(h(x)\\) como uma única função indicadora.\nDetermine o valor da integral \\(\\int_{-\\infty}^{\\infty} h(x) dx\\).\n\n\n\nExercise 3.4 Simplifique a expressão abaixo e determine o valor da função para qualquer \\(x \\in \\mathbb{R}\\):\\[g(x) = I_{(0, 5)}(x)I_{(10, 20)}(x)\\]\n\n\nExercise 3.5 Expresse o produto das indicadoras abaixo como uma única indicadora de \\(x\\), mantendo \\(y\\) como um parâmetro fixo:\\[k(x) = I_{(0, \\infty)}(x) I_{(-\\infty, y)}(x)\\]\n\nDetermine a indicadora resultante.\nPara quais valores de \\(y\\) a função \\(k(x)\\) é identicamente nula (igual a zero para todo \\(x\\))?\n\n\nComo vimos no capítulo anterior, \\[F(\\textbf{x})=P(\\textbf{x}\\leq \\textbf{x})=P(X_1\\leq x_1,\\ldots,X_n\\leq x_n),\\] é denominada função de distribuição conjunta (ou ainda função de distribuição multivariada).\n\nProposition 3.2 A função de distribuição de um vetor de variáveis aleatórias contínuas é dada por \\[F(\\textbf{x})=\\int_{-\\infty}^{x_1}\\cdots\\int_{-\\infty}^{x_n}f(y_1,\\ldots,y_n)d\\textbf{y}.\\]\n\n\nExample 3.4 Encontre a função distribuição do vetor \\((X,Y)\\) cuja função de densidade conjunta é\n\\[f(x,y)=2xI_{(0,1)}(x)I_{(0,1)}(y).\\] Solução.\n\\[\\begin{align}F(u,v)&=\\int_{-\\infty}^u\\int_{-\\infty}^v f(x,y)dydx=\\int_{-\\infty}^u\\int_{-\\infty}^v 2xI_{(0,1)}(x)I_{(0,1)}(y)dydx\\end{align}\\] Considerando que \\(u,v\\in(0,1)\\), teremos\n\\[\\begin{align}F(u,v)&=\\int_{0}^u\\int_{0}^v 2xI_{(0,1)}(x)I_{(0,1)}(y)dydx.\\end{align}\\] A integral em \\(y\\) é \\[\\int_0^{v}2xdy=2x\\left.y\\right|_{0}^{v}=v\\] logo, \\[F(u,v)=2v\\int_0^{u}xdx=2v\\left.\\frac{x^2}{2}\\right|_0^u=vu^2\\] para \\(u,v\\in(0,1)\\).\n\n\nExercise 3.6 Encontre a função de distribuição conjunta a partir da densidade conjunta abaixo:\n\\[f(x,y)=\\frac{3}{80}(x^2+xy)\\], com \\(0&lt;x&lt;2\\) e \\(0&lt;y&lt;4\\).\n\n\nExample 3.5 Considere o vetor aleatório com função densidade conjunta dada por \\[f(x,y)=e^{-y}I_{(0,\\infty)}(x)I_{(x,\\infty)}(y).\\] Encontre a função de distribuição conjunta.\n\\[\\begin{align}F(u,v)&=\\int_{-\\infty}^u\\int_{-\\infty}^v f(x,y)dydx=\\int_{-\\infty}^u\\int_{-\\infty}^v e^{-y}I_{(0,\\infty)}(x)I_{(x,\\infty)}(y)dydx\\\\&=\\int_{-\\infty}^uI_{(0,\\infty)}(x)\\left[\\int_{-\\infty}^v e^{-y}I_{(x,\\infty)}(y)dy\\right]dx\\end{align}\\] Observe que podemos fazer \\[\\int_{-\\infty}^v e^{-y}I_{(x,\\infty)}dy=\\int_\\mathbb{R}e^{-y}I_{(x,\\infty)}(y)I_{\\mathbb{R}^+}(y)dy\\] Note que \\(I_{(-\\infty,v)}(y)I_{(x,\\infty)}(y)=1\\) somente se \\(x&lt;v\\). Isso é o mesmo que escrever\n\\[1=I_{(-\\infty,v)}(y)I_{(x,\\infty)}(y)I_{(-\\infty,v)}(x)=I_{(x,v)}(y)I_{(-\\infty,v)}(x).\\] Então,\n\\[\\begin{align}\\int_{-\\infty}^v e^{-y}I_{(x,\\infty)}dy&=I_{(-\\infty),v}(x)\\int_x^ve^{-y}dy=I_{(-\\infty,v)}\\left[\\left.-e^{-y}\\right|_{x}^v\\right]\\\\&=\\left(e^{-x}-e^{-v}\\right)I_{(-\\infty,v)}(x)\\end{align}\\]\nEntão \\[\\begin{align}F(u,v)&=\\int_{-\\infty}^{u}I_{(0,\\infty)}(x)I_{(-\\infty,v)}(x)\\left(e^{-x}-e^{-v}\\right)dx\\\\&=\\int_{-\\infty}^{u}I_{(0,v)}(x)\\left(e^{-x}-e^{-v}\\right)dx\\\\&=\\int_0^{\\min\\{u,v\\}}(e^{-x}-e^{-v})dx\\\\&=\\int_0^{\\min\\{u,v\\}}e^{-x}dx-\\int_0^{\\min\\{u,v\\}}e^{-v}dx\\\\&=\\left[\\left.-e^{-x}\\right|_0^{\\min\\{u,v\\}}\\right]- \\min\\{u,v\\}e^{-v}\\\\&=1-e^{-\\min\\{u,v\\}}-\\min\\{u,v\\}e^{-v}\\end{align}\\] para \\(u,v&gt;0\\).\n\n\nExercise 3.7 Considere o vetor aleatório \\((X, Y)\\) com função densidade conjunta dada por:\\[f(x, y) = 2e^{-(x+y)} I_{(0, y)}(x) I_{(0, \\infty)}(y)\\]\nEncontre a função de distribuição conjunta.\n\n\nExercise 3.8 Seja a função densidade conjunta:\\[f(x, y) =\\frac{3}{2}I_{(-1,1)}(x)I_{(x^2,1)}(y).\\] Encontre a função de distribuição.\n\n::: ::: {#prp-} Se \\(\\textbf{X}\\) é um vetor aleatório comprimento \\(n\\), então\n\\[f(\\textbf{x})=\\frac{\\partial}{\\partial x_1}\\cdots \\frac{\\partial}{\\partial x_n} F(\\textbf{x}).\\]\n:::\n\nExercise 3.9 Seja\n\\[F(x,y)=1−e^{−x}−e^{−y}+e^{-(x+y)},\\] com \\((x,y)\\in\\mathbb{R}^2_+\\). Encontre a densidade conjunta correspondente.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distribuição de vetores aleatórios contínuos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_continuos.html#distribuições-marginais",
    "href": "vetores_aleatorios_continuos.html#distribuições-marginais",
    "title": "3  Distribuição de vetores aleatórios contínuos",
    "section": "3.3 Distribuições Marginais",
    "text": "3.3 Distribuições Marginais\nSeja \\(\\textbf{X}\\) um vetor aleatório de dimensão \\(n\\). A distribuição de uma coordenada qualquer de \\(\\textbf{X}\\) é denominada distribuição marginal.\nComo em geral utilizamos as letras \\(F\\), \\(P\\) e \\(f\\) para designar as funções de distribuição, probabilidade e densidade, é importante acrescentar uma notação que identifique explicitamente a variável. Quando isto for necessário, adicionaremos a letra que designa a variável subscrita na função. Por exemplo, \\(F_{X_1}(x)\\) é a função de distribuição marginal de \\(X_1\\).\n\nProposition 3.3 Seja \\(\\textbf{X}=(\\textbf{X}_a,\\textbf{X}_b)\\) um vetor de variáveis aleatórias contínuas. A função de densidade marginal do subvetor \\(\\textbf{X}_a\\) é dada por \\[f_{\\textbf{X}_a}(\\textbf{x}_a)=\\int f(\\textbf{x})d\\textbf{x}_{b}.\\]\n\n\nExample 3.6 Seja \\((X,Y)\\) um par de variáveis aleatórias com densidade conjunta dada por \\[f(x,y)=8xyI_{(0,y)}(x)I_{(0,1)}(y),\\] Determine as densidades marginais de \\(X\\) e \\(Y\\).\nSolução A densidade marginal de \\(Y\\) é\n\\[\\begin{align}f_Y(y)&=\\int_{\\mathbb{R}}f(x,y)dx=8yI_{(0,1)}(y)\\int_\\mathbb{R} I_{(0,y)}(x)xdx\\\\&=8yI_{(0,1)}(y)\\int_0^y xdx=8yI_{(0,1)}(y)\\left.\\frac{x^2}{2}\\right|_0^y=4y^3I_{(0,1)}(y).\\end{align}\\]\nPara determinar a marginal de \\(X\\), observe que\n\\[I_{(0,y)}(x)I_{(0,1)}(y)=1\\Rightarrow 0&lt;x&lt;y\\hbox{ e } 0&lt;y&lt;1\\] note que é possível inferir que: \\(0&lt;x&lt;1\\) e \\(x&lt;y&lt;1\\). Portanto,\n\\[I_{(0,y)}(x)I_{(0,1)}(y)=I_{(x,1)}(y)I_{(0,1)}(x),\\] logo \\[f_X(x)=\\int_x^1 f(x,y)dx=8xI_{(0,1)}(x)\\left.\\frac{y^2}{2}\\right|_{x}^1=4x(1-x^2)I_{(0,1)}(x).\\]\n\n\nExercise 3.10 Seja a função densidade conjunta:\\[f(x, y) =\\frac{3}{2}I_{(-1,1)}(x)I_{(x^2,1)}(y).\\] Encontre as densidades marginais de \\(X\\) e \\(Y\\).\n\n\nExercise 3.11 Considere a seguinte função de densidade conjunta, \\[f(x,y)=xy^2e^{−y(x+1)}.\\] onde \\(x,y&gt;0\\). Encontre a função densidade marginal de \\(X\\) e \\(Y\\).\n\n\nExercise 3.12 Considere a densidade conjunta \\[f(x,y)=\\frac{6}{7}\\left(x^2+\\frac{xy}{2}\\right)\\] para \\(0&lt;x&lt;1\\) e \\(0&lt;y&lt;2\\)\n\nverifique que \\(f(x,y)\\) é de fato uma função densidade conjunta .\nencontre a função densidade marginal de \\(X\\).\nCalcule \\(P(X&gt;Y)\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distribuição de vetores aleatórios contínuos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_continuos.html#distribuição-condicional",
    "href": "vetores_aleatorios_continuos.html#distribuição-condicional",
    "title": "3  Distribuição de vetores aleatórios contínuos",
    "section": "3.4 Distribuição condicional",
    "text": "3.4 Distribuição condicional\nSejam \\(\\textbf{X}\\) e \\(\\textbf{Y}\\) vetores aleatórios contínuos. Sabemos que\n\\[P(\\textbf{X}\\leq \\textbf{x}|\\textbf{Y}\\in B)=\\frac{P(\\textbf{X}\\leq\\textbf{x},\\textbf{Y}\\in B)}{P(\\textbf{Y}\\in B)}.\\]\nComo \\(\\textbf{Y}\\) é um vetor de variáveis aleatórias contínuas, sabemos que \\(P(\\textbf{Y}=\\textbf{y})=0\\). Entretanto, a probabilidade \\(P(\\textbf{X}\\leq \\textbf{x}|\\textbf{Y}=\\textbf{y})\\) faz todo o sentido. Para mostrar este fato, seja \\(B(\\varepsilon)\\) uma bola fechada de raio \\(\\varepsilon\\) e centro \\(\\textbf{y}\\). Pelo Teorema do Valor Médio, existe \\(\\tilde{y}\\in B(\\varepsilon)\\) tal que\n\\[P(\\textbf{Y}\\in B(\\varepsilon) )=\\int_{B(\\varepsilon)} f_{\\textbf{Y}}(\\textbf{u})d\\textbf{u}=\\hbox{Vol}(B(\\varepsilon))f_{\\textbf{Y}}(\\tilde{\\textbf{y}})\\] e\n\\[P(\\textbf{X}\\leq \\textbf{x},\\textbf{Y}\\in B(\\varepsilon) )=\\int_{\\textbf{v}\\leq \\textbf{x}}\\int_{B(\\varepsilon)} f_{\\textbf{X},\\textbf{Y}}(\\textbf{v},\\textbf{u})d\\textbf{u}d\\textbf{v}=\\hbox{Vol}(B(\\varepsilon))\\int_{\\textbf{v}\\leq \\textbf{x}}f_{\\textbf{X},\\textbf{Y}}(\\textbf{v},\\tilde{\\textbf{y}}_{\\textbf{v}})d\\textbf{v}.\\] Portanto,\n\\[P(\\textbf{X}\\leq \\textbf{x}|\\textbf{Y}\\in B(\\varepsilon) )=\\frac{\\hbox{Vol}(B(\\varepsilon))\\int_{\\textbf{v}\\leq \\textbf{x}}f_{\\textbf{X},\\textbf{Y}}(\\textbf{v},\\tilde{\\textbf{y}})d\\textbf{v}}{\\hbox{Vol}(B(\\varepsilon))f_{\\textbf{Y}}(\\tilde{\\textbf{y}})}=\\int_{\\textbf{v}\\leq \\textbf{x}}\\frac{f_{\\textbf{X},\\textbf{Y}}(\\textbf{v},\\tilde{\\textbf{y}}_{\\textbf{v}})}{f_{\\textbf{Y}}(\\tilde{\\textbf{y}})}d\\textbf{v}.\\] Agora, note que \\(B(\\varepsilon)\\rightarrow\\textbf{y}\\) quando \\(\\varepsilon\\rightarrow0\\), logo \\(\\tilde{\\textbf{y}}\\rightarrow\\textbf{y}\\) e \\(\\tilde{\\textbf{y}}_{\\textbf{v}}\\rightarrow\\textbf{y}\\) para todo \\(\\textbf{v}\\), o que implica em\n\\[\\lim_{\\varepsilon\\rightarrow 0}P(\\textbf{X}\\leq \\textbf{x}|\\textbf{Y}\\in B(\\varepsilon) )=P(\\textbf{X}\\leq \\textbf{x}|\\textbf{Y}= \\textbf{y})=F(\\textbf{x}|\\textbf{y})=\\int_{\\textbf{v}\\leq \\textbf{x}}\\frac{f_{\\textbf{X},\\textbf{Y}}(\\textbf{v},{\\textbf{y}})}{f_{\\textbf{Y}}({\\textbf{y}})}d\\textbf{v}.\\] o que implica em\n\\[f(\\textbf{x}|\\textbf{y})=\\frac{f_{\\textbf{X},\\textbf{Y}}(\\textbf{x},\\textbf{y})}{f_{\\textbf{Y}}(\\textbf{y})}.\\]\n\nExample 3.7 Seja \\[f(x,y)=21x^2y^3,\\] se \\(0&lt;x&lt;y&lt;1\\). Encontre a densidade condicional de \\(Y|X=x\\).\nSolução.\nPrimeiro, vamos encontrar a densidade marginal de \\(X\\):\n\\[\\begin{align}f_X(x)&=21x^2I_{(0,1)}(x)\\int_\\mathbb{R} y^3I_{(x,1)}(y)dy=21x^2I_{(0,1)}(x)\\int_x^1 y^3dy\\\\&=21\\left[\\left.\\frac{y^4}{4}\\right|_{x}^1\\right]I_{(0,1)}(x)\\\\&=\\frac{21}{4}x^2(1-x^4)I_{(0,1)}(x),\\end{align}\\]\npara \\(x\\in(0,1)\\). Portanto,\n\\[f(y|x)=\\frac{f(x,y)}{f_X(x)}=\\frac{21x^2y^3}{\\frac{21}{4}x^2(1-x^4)}=\\frac{4y^3}{(1-x^4)}I_{(x,1)}(y),\\]\n\n\nExercise 3.13 Suponha que\n\\[f(x,y)=\\frac{1}{2\\pi}\\exp\\left\\{−\\frac{1}{2}(x^2+2y^2−2xy)\\right\\},\\] com \\((x,y)\\in\\mathbb{R}^2\\). Encontre a densidade de \\(X|Y=y\\).\n\n\nExercise 3.14 Para \\(n&gt;0\\) inteiro, suponha que \\(X\\sim\\hbox{Gama}(n+1,x)\\). Além disso, suponha que dado \\(x\\), \\(Y_1,\\ldots,Y_n\\) são variáveis aleatórias independentes que possuem a seguinte densdidade condicional:\n\\[f(y_i|x)=\\frac{1}{x},\\] para \\(0&lt;y_i&lt;x\\).\n\nDetermine a densidade marginal do vetor \\((Y_1,\\ldots,Y_n)\\)\nDetermine a densidade condicional de \\(X\\) dado os valores de \\(Y_1,\\ldots,Y_n\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distribuição de vetores aleatórios contínuos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_continuos.html#função-de-vetores-aleatórios-contínuos",
    "href": "vetores_aleatorios_continuos.html#função-de-vetores-aleatórios-contínuos",
    "title": "3  Distribuição de vetores aleatórios contínuos",
    "section": "3.5 Função de vetores aleatórios contínuos",
    "text": "3.5 Função de vetores aleatórios contínuos\n\n3.5.1 Caso para uma variável\nSuponha que \\(X\\) é uma variável aleatória contínua e \\(g(.)\\) uma função real e contínua. Considerando a variável aleatória \\(Y=g(X)\\), teremos que\n\\[P(Y\\in A)=P(g(X)\\in A)=\\int_{\\{x:g(x)\\in A\\}}f_X(x)dx.\\]\nEm particular,\n\\[F_Y(y)=P(Y\\leq y)=P(g(X)\\leq y)=\\int_{\\{x:g(x)\\leq y\\}}f_X(x)dx.\\]\nAgora, suponha \\(g(.)\\) possui inversa. Então, podemos utilizar o método integral por substituição. Fazendo \\(u=g(x)\\), teremos que \\(x=g^{−1}(u)\\) e \\(dx=\\frac{d}{du}g^{−1}(u)du\\). Além disso,\n\\[\\{x:g(x)\\leq y\\}\\equiv\\{u\\leq y\\},\\] o que implica em\n\\[F_Y(y)=\\int_{-\\infty}^y f_X(g^{−1}(u))\\left|\\frac{d}{du}g^{−1}(u)\\right|du\\] logo, \\[f_Y(y)=f_X(g^{−1}(y))\\left|\\frac{d}{dy}g^{−1}(y)\\right|.\\] O termo dentro do módulo é denominado Jacobiano da transformação e a obtenção da densidade por esse método é denominada método do Jacobiano.\n\nExample 3.8 Suponha que \\(X\\sim\\hbox{Normal}(0,1)\\). Considere a transformação \\(Y=e^{X}\\). Como \\(g^{-1}(y)=\\log(y)\\), teremos que\n\\[f_Y(y)=f_X(\\log y )\\left|\\frac{d}{dy}\\log y\\right|=\\frac{1}{y\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\log y)^2}.\\] Essa distribuição é denominada Lognormal(0,1).\n\n\nExercise 3.15 Seja \\(X\\) uma variável aleatória com distribuição Uniforme no intervalo \\((0, 1)\\), ou seja, sua função de densidade de probabilidade é: \\[f_X(x) = I_{(0,1)}(x).\\] Encontre a função densidade de \\(Y = -\\ln(X)\\).\n\n\n\n3.5.2 Caso vetorial com \\(g\\) invertível\nAssim como no caso discreto, a extensão para vetores também é natural. Seja \\(\\textbf{X}\\) um vetor aleatório de comprimento \\(n\\) e considere a nova variável \\(\\textbf{Y}=g(X)\\), onde \\(g:\\mathbb{R}^n\\rightarrow \\mathbb{R}^m\\) é uma função real. Então\n\\[P(\\textbf{Y}\\in A)=P(g(\\textbf{X})\\in A)=\\int_{\\{\\textbf{x}:g(\\textbf{x})\\in A\\}}f_\\textbf{X}(\\textbf{x})d\\textbf{x}.\\]\nAgora, suponha que \\(g(.)\\) possui inversa (o que implica que \\(g:\\mathbb{R}^n\\rightarrow \\mathbb{R}^n\\)). Então, pelo método da integral por substituição, teremos que \\(\\textbf{u}=g^{-1}(\\textbf{y})\\), \\(d\\textbf{x}=|\\mathcal{J}g^{-1}(\\textbf{u})|d\\textbf{u}\\) e \\(\\{\\textbf{x}:g(\\textbf{x})\\in A\\}=\\{\\textbf{u}\\in A\\}\\), o que implica em\n\\[P(\\textbf{Y}\\in A)=\\int_{A}f_\\textbf{X}(g^{-1}(\\textbf{u})|\\det\\mathcal{J}g^{-1}(\\textbf{u})|d\\textbf{u}.\\]\nonde \\(\\mathcal{J}g^{-1}(\\textbf{u})\\) é denominada matriz Jacobiana, cujo o elemento \\((i,j)\\) é dado por \\[\\mathcal{J}_{i,j}=\\frac{\\partial x_i}{\\partial u_j}.\\]\nEm particular, teremos que\n\\[F_{\\textbf{Y}}(\\textbf{y})=\\int_{-\\infty}^{y_1}\\cdots \\int_{-\\infty}^{y_n}f_\\textbf{X}(g^{-1}(\\textbf{u}))|\\det\\mathcal{J}g^{-1}(\\textbf{u})|d\\textbf{u}.\\]\nPortanto, concluímos que \\[f_\\textbf{Y}(\\textbf{y})=f_\\textbf{X}(g^{−1}(\\textbf{y}))|\\det\\mathcal{J}g^{-1}(\\textbf{y})|.\\]\n\nExample 3.9 Sejam \\(X_1\\) e \\(X_2\\) variáveis aleatórias independentes com distribuição Normal(0,1). Vamos encontrar a função densidade conjunta de \\(\\textbf{Y}=(X_1+X_2,Y2=X_1−X_2)\\).\nPrimeiro, temos que encontrar a função inversa:\n\\[\\begin{array}{c}\nY_1=X_1+X_2\\\\\nY_2=X_1-X_2\\\\\n\\end{array} \\Leftrightarrow \\begin{array}{c}X_1=0,5(Y_1+Y_2)\\\\ X_2=0,5(Y_1-Y_2)\\end{array}\\]\ne o Jacobiano da transformação é dado por\n\\[\\mathcal{J}g^{-1}(\\textbf{y})=\\left[\\begin{array}{cc} 0,5 & 0,5 \\\\ 0,5 & - 0,5 \\end{array}\\right],\\]\ncujo determinante é igual a -1/2. Logo,\n\\[\\begin{align}f_\\textbf{Y}(\\textbf{y})&=f_{X_1}(0,5(y_1+y_2)f_{X_2}(0,5(y_1−y_2)\\frac{1}{2}\\\\&=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}[0,5(y_1+y_2)]^2}I_{\\mathbb{R}}(0,5(y_1+y_2))\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}[0,5(y_1-y_2)]^2}I_{\\mathbb{R}}(0,5(y_1-y_2))\\frac{1}{2}\\\\&=\\frac{1}{4\\pi}e^{-\\frac{1}{8}[(y_1-y_2)^2+(y_1+y_2)^2]}I_{\\mathbb{R}}(y_1)I_{\\mathbb{R}}(y_2)\\\\&=\\frac{1}{4\\pi}e^{-\\frac{1}{4}(y_1^2+y_2^2)}I_{\\mathbb{R}}(y_1)I_{\\mathbb{R}}(y_2).\\end{align}\\] Podemos notar que a densidade conjunta fatora em duas normais, ou seja \\(Y_1\\) e \\(Y_2\\) são independentes com marginais Normal(0,2).\n\n\nExercise 3.16 Sejam \\(X_1\\) e \\(X_2\\) variáveis aleatórias independentes com distribuição Normal(0,1).\n\nEncontre a função densidade conjunta de \\(Y_1=aX_1+X_2\\) e \\(Y_2=X_1−X_2\\), onde \\(a\\) é uma constante.\nQuais são os valores de \\(a\\) tais que \\(Y_1\\) é independente de \\(Y_2\\)?\n\n\n\nExample 3.10 Sejam \\(X\\) e \\(Y\\) variáveis aleatórias independentes com distribuição Exponencial(1). Vamos determinar a distribuição conjunta de \\(U=X+Y\\) e \\(V=Y/X\\).\nComo \\(X\\) e \\(Y\\) são independentes, sua densidade conjunta é \\[f(x,y)=f_X(x)f_Y(y)=e^{-x}e^{-y}I_{(0,\\infty)}(x)I_{(0,\\infty)}(y).\\]\nVamos escrever \\((x,y)\\) como função de \\((u,v)\\). Primeiro, \\[u=x+y\\Rightarrow x=u-y.\\] Substituindo \\(x=u-y\\) em \\(v=y/x\\), teremos que\n\\[y=vx=v(u-y)\\Rightarrow y(1+v)=vu\\Rightarrow y=\\frac{uv}{1+v}\\] logo \\[\\begin{cases}\nx=\\frac{u}{1+v}\\\\\ny=\\frac{uv}{1+v}\n\\end{cases}\\] o que implica na matriz jacobiana\n\\[\\mathcal{J}=\\left|\\begin{array}{cc}\\frac{\\partial x}{\\partial u} & \\frac{\\partial x}{\\partial v}\\\\ \\frac{\\partial y}{\\partial u} & \\frac{\\partial y}{\\partial v} \\end{array}\\right|=\\left|\\begin{array}{cc}\\frac{1}{1+v}&-\\frac{u}{(1+v)^2 } \\\\ \\frac{v}{1+v} & \\frac{u}{(1+v)^2}\\end{array}\\right|\\]\ncujo módulo do determinante é \\[|\\det\\mathcal{J}| = \\left| \\frac{u}{(1+v)^3} - \\left( -\\frac{uv}{(1+v)^3} \\right) \\right| = \\left| \\frac{u(1+v)}{(1+v)^3} \\right| = \\frac{u}{(1+v)^2}\\] Então,\n\\[\\begin{align}f_{U,V}(u,v)&=f_X\\left(\\frac{u}{1+v}\\right)f_Y\\left(\\frac{uv}{1+v}\\right)|\\det\\mathcal{J}|\\\\&=e^{-\\left(\\frac{u}{1+v}\\right)}I_{(0,\\infty)}\\left(\\frac{u}{1+v}\\right)e^{-\\left(\\frac{uv}{1+v}\\right)}I_{(0,\\infty)}\\left(\\frac{uv}{1+v}\\right)\\frac{u}{(1+v)^2}\\\\&=e^{-\\left(\\frac{u}{1+v}+\\frac{uv}{1+v}\\right)}I_{(0,\\infty)}\\left(\\frac{u}{1+v}\\right)I_{(0,\\infty)}\\left(\\frac{uv}{1+v}\\right)\\frac{u}{(1+v)^2}\\\\&=\\frac{u}{(1+v)^2}e^{-u}I_{(0,\\infty)}\\left(\\frac{u}{1+v}\\right)I_{(0,\\infty)}\\left(\\frac{uv}{1+v}\\right)\\end{align}\\] e, notando que as indicadoras são iguais a um quando \\(u,v&gt;0\\), teremos\n\\[\\begin{align}f_{U,V}(u,v)=\\frac{u}{(1+v)^2}e^{-u}I_{(0,\\infty)}\\left(u\\right)I_{(0,\\infty)}\\left(v\\right)\\end{align}\\]\n\n\nExercise 3.17 Sejam \\(X\\) e \\(Y\\) variáveis aleatórias independentes, ambas com distribuição Gama de parâmetros \\(\\a\\) e \\(b\\), especificamente \\(X \\sim \\text{Gama}(a, 1)\\) e \\(Y \\sim \\text{Gama}(b, 1)\\). Considere as seguintes transformações:\\[U = X + Y \\quad \\text{e} \\quad V = \\frac{X}{X+Y}\\]Determine a densidade conjunta \\(f_{U,V}(u, v)\\).Verifique se \\(U\\) e \\(V\\) são independentes.Identifique as distribuições marginais de \\(U\\) e \\(V\\)\nNota A função densidade da distribuição Gamma(\\(a,b\\)) é \\[f(x)=\\frac{b^a}{\\Gamma(a)}x^{a-1}e^{-bx}I_{(0,\\infty)}(x),\\] com \\(a,b&gt;0\\).\n\n\n\n3.5.3 Caso vetorial com \\(g:\\mathbb{R}^n\\rightarrow\\mathbb{R}^n\\), com \\(n&gt;m\\)\nConsidere o agora que \\(g:\\mathbb{R}^n\\rightarrow\\mathbb{R}^m\\), onde \\(n&gt;m\\). Nesse caso, \\(\\textbf{Y}=g(\\textbf{X})\\) ainda é um vetor aleatório, mas não podemos aplicar a integral por substitição \\(g(.)\\) não tem inversa. Neste caso, adicionamos um vetor \\(\\textbf{W}=h(X)\\) de dimensão \\(n−m\\) tal que a função \\[g_*(\\textbf{X})=(g(\\textbf{X}),h(\\textbf{X}))=(\\textbf{y},\\textbf{w})\\] tenha inversa. Então, obtemos a densidade conjunta de \\((\\textbf{Y},\\textbf{W})\\) através do método discutido anteriormente, ou seja\n\\[f_{\\textbf{Y},\\textbf{W}}(\\textbf{y},\\textbf{w})=f_X(g_ *^{−1}(\\textbf{y},\\textbf{w}))|\\det \\mathcal{J}g_ *^{−1}|.\\] Em seguida, podemos encontrar a densidade marginal de \\(\\textbf{Y}\\) integrando a conjunta acima em \\(\\textbf{W}\\):\n\\[f_\\textbf{Y}(\\textbf{y})=\\int f_\\textbf{X}(g_*^{−1}(\\textbf{y},\\textbf{w}))|\\det\\mathcal{J}g_*^{-1}(\\textbf{y},\\textbf{w})|d\\textbf{w}.\\] ::: {#exm-} Soma de duas variáveis aletórias contínuas independentes. Sejam \\(X_1,X_2\\) variáveis aleatórias independentes e considere o problema de encontrar a função densidade de \\(Y=X_1+X_2\\).\nComo \\(y=g(x_1,x_2)=x_1+x_2\\) não tem inversa, vamos utilizar a função \\(g_*(x_1,x_2)=(x_1+x_2,x_2)=(y,w)\\) ( como a escolha de \\(w=x_2\\) é arbitrária, aqui o fizemos de modo conveniente). Teremos que\n\\[\\begin{cases}\ny&= x_1+x_2\\\\ w &= x_1 \\end{cases}\\Rightarrow\\begin{cases}x_1&=y-w\\\\ x_2&=w\\end{cases}\\]\nO determinante da matriz Jacobiana é\n\\[\\det\\mathcal{J}g_*^{-1}=\\left|\\begin{array}{cc}\\frac{\\partial{x_1}}{\\partial{y}} & \\frac{\\partial{x_1}}{\\partial{w}} \\\\ \\frac{\\partial{x_2}}{\\partial{y}} & \\frac{\\partial{x_2}}{\\partial{w}} \\end{array}\\right|=\\det\\left|\\begin{array}{cc}1 & -1 \\\\ 0 & 1\\end{array}\\right|=1\\]\n(aqui, fica claro que \\(w=x_2\\) foi escolhido de modo a simplificar o derteminante), logo\n\\[f_{Y,W}(y,w)=f_{X_1}(y-w)f_{X_2}(w)\\] e a função densidade desejada é\n\\[f_{Y}(y)=\\int_{\\mathbb{R}}f_{X_1}(y-w)f_{X_2}(w)dw.\\]\n:::\n\nExercise 3.18 Sejam \\(X_1\\) e \\(X_2\\) variáveis aleatórias independentes com distribuição Exponencial(1), cuja função densidade é \\[f(x)=e^{-x}I_{(0,\\infty)}(x).\\]\nEncontre a função densidade de \\(Y=X_1+X_2\\).\n\n\nExercise 3.19 Sejam \\(X_1\\) e \\(X_2\\) variáveis aleatórias independentes com distribuição Uniforme(0,1), cuja função densidade é\n\\[f(x)=I_{(0,1)}(x)\\] Encontre a função densidade de \\(Y=X_1+X_2\\).\n\n\n\n3.5.4 Casos especiais\n\nExercise 3.20 Soma de normais independentes.\n\nSejam \\(X_1,X_2\\) variáveis aleatórias independentes com \\(X_i\\sim\\hbox{Normal}(\\mu_i,\\sigma^2_i)\\). Mostre que \\(Y=X_1+X_2\\sim\\hbox{Normal}(\\mu_1+\\mu_2,\\sigma_1^2+\\sigma_2^2)\\).\nSejam \\(X_1,\\ldots,X_n\\) variáveis aleatórias independentes com \\(X_i\\sim\\hbox{Normal}(\\mu_i,\\sigma^2_i)\\). Mostre por indução que \\(Y=X_1+\\cdots+X_n\\sim\\hbox{Normal}(\\sum_{i=1}^n \\mu_i,\\sum_{i=1}^n \\sigma^2_i)\\)\n\n\n\nExercise 3.21 Distribuição Chi Quadrado. A função densidade da distribuição \\(\\chi^2_\\nu\\) é\n\\[f(x) = \\frac{1}{2^{\\nu/2} \\Gamma(\\nu/2)} x^{\\nu/2 - 1} e^{-x/2}I_{(0,\\infty)}(x),\\] onde \\(\\nu&gt;0\\).\n\nSejam \\(X_1,X_2\\) variáveis aleatórias independentes com \\(X_i\\sim\\chi^2_{\\nu_i}\\). Mostre que \\(Y=X_1+X_2\\sim\\chi^2_{\\nu_1+\\nu_2}\\).\nSejam \\(X_1,\\ldots,X_n\\) variáveis aleatórias independentes com \\(X_i\\sim\\chi^2_{\\nu_i}\\). Mostre, por indução, que \\(Y=\\sum_{i=1}^{n}X_i\\sim\\chi^2_{\\sum_{i=1}^n \\nu_i}\\).\nSejam \\(Z_i\\sim\\hbox{Normal}(0,1)\\) variáveis independentes. Sabendo que \\(Z_i^2\\sim\\chi^2_1\\), qual é a distribuição de \\(Z_1^2+\\cdots+Z_n^2?\\)\n\n\n\nExercise 3.22 Distribuição t-Student. Sejam \\(X\\sim\\hbox{Normal}(0,1)\\) e \\(Y\\sim\\chi^2_{\\nu}\\) variáveis independentes. Mostre que a função densidade de\n\\[T=\\frac{X}{\\sqrt{Y/\\nu}}\\] é\n\\[f(t)= \\frac{\\Gamma\\left(\\frac{\\nu+1}{2}\\right)}{\\sqrt{\\nu\\pi} \\, \\Gamma\\left(\\frac{\\nu}{2}\\right)} \\left(1 + \\frac{t^2}{\\nu}\\right)^{-\\frac{\\nu+1}{2}}I_\\mathbb{R}(t).\\]\nSugestão. Considere a função \\(g_*(x,y)=(x/\\sqrt{y/\\nu}, y)=(t,w)\\).\n\n\nExercise 3.23 Distribuição F de Snedecor. Sejam \\(U\\) e \\(V\\) variáveis aleatórias independentes tais que \\(U \\sim \\chi^2_{\\nu_1}\\) e \\(V \\sim \\chi^2_{\\nu_2}\\). A distribuição F de Snedecor com \\(\\nu_1\\) e \\(\\nu_2\\) graus de liberdade é definida pela transformação:\\[W = \\frac{U/\\nu_1}{V/\\nu_2}\\]\n\nPara encontrar a densidade de \\(W\\), defina uma variável auxiliar \\(Z = V\\). Encontre a densidade conjunta \\(f_{W,Z}(w, z)\\) utilizando o método do Jacobiano.\nMostre que a densidade marginal de \\(W\\) é dada por:\\[f_W(w) = \\frac{\\Gamma\\left(\\frac{\\nu_1+\\nu_2}{2}\\right)}{\\Gamma\\left(\\frac{\\nu_1}{2}\\right)\\Gamma\\left(\\frac{\\nu_2}{2}\\right)} \\left(\\frac{\\nu_1}{\\nu_2}\\right)^{\\frac{\\nu_1}{2}} \\frac{w^{\\frac{\\nu_1}{2}-1}}{\\left(1 + \\frac{\\nu_1}{\\nu_2}w\\right)^{\\frac{\\nu_1+\\nu_2}{2}}} I_{(0, \\infty)}(w)\\]\nComo a distribuição \\(F\\) se relaciona com a distribuição \\(t\\) de Student? (Dica: Observe a definição de \\(T\\) no exercício anterior e considere o que ocorre com \\(T^2\\)).:::",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distribuição de vetores aleatórios contínuos</span>"
    ]
  },
  {
    "objectID": "vetores_mistos.html",
    "href": "vetores_mistos.html",
    "title": "4  Vetores aleatórios mistos",
    "section": "",
    "text": "É possível que o vetor \\(\\textbf{X}=(\\textbf{X}_d,\\textbf{X}_c)\\) possua um subvetor \\(\\textbf{X}_d\\) composto de variáveis aleatórias discretas e um subvetor \\(\\textbf{X}_c\\) composto de variáveis aleatórias contínuas. Suponha inicialmente que \\(\\textbf{X}_d\\) é independente de \\(\\textbf{X}_c\\). Considere a seguinte probabilidade:\n\\[P(\\textbf{X}_d=\\textbf{x}_d,\\textbf{X}_c\\leq\\textbf{x}_c)=P(\\textbf{X}_d=\\textbf{x}_d)F_{\\textbf{X}_c}(\\textbf{x}_c).\\]\nAssumindo que a função acima é diferenciável em \\(\\textbf{x}_c\\), teremos a existência da função:\n\\[g(\\textbf{x}_d,\\textbf{x}_c)=P(\\textbf{X}_d=\\textbf{x}_d)f_{\\textbf{X}_c}(\\textbf{x}_c).\\]\nA função acima é denominada função de densidade conjunta mista ou função de massa-densidade conjunta. É possível definir essa função mesmo quando \\(\\textbf{X}_c\\) é dependente de \\(\\textbf{X}_d\\). Para tanto, seja \\(B(\\varepsilon)=\\{\\textbf{y}: ||\\textbf{y}-\\textbf{x}_c||&lt;\\varepsilon\\}\\). Então, define-se\n\\[g(\\textbf{x}_d,\\textbf{x}_c)=\\lim_{\\varepsilon\\rightarrow 0} \\frac{P(\\textbf{X}_d=\\textbf{x}_d,\\textbf{X}_c\\in B(\\varepsilon))}{Vol(B(\\varepsilon))}.\\]\nObserve que\n\\[P(\\textbf{X}_d=\\textbf{x}_d,\\textbf{X}_c\\in B(\\varepsilon))=P(\\textbf{X}_d=\\textbf{x}_d|\\textbf{X}_c\\in B(\\varepsilon))P(\\textbf{X}_c\\in B(\\varepsilon)),\\] e, alternativamente: \\[P(\\textbf{X}_d=\\textbf{x}_d,\\textbf{X}_c\\in B(\\varepsilon))=P(\\textbf{X}_c\\in B(\\varepsilon)|\\textbf{X}_d=\\textbf{x}_d)P(\\textbf{X}_d=\\textbf{x}_d).\\]\nPelo Teorema do Valor Médio para integrais, existem \\(\\textbf{a}_1, \\textbf{a}_2 \\in B(\\varepsilon)\\) tais que\n\\[Vol(B(\\varepsilon))f_{\\textbf{X}_c|\\textbf{x}_d}(\\textbf{a}_1|\\textbf{x}_d)P(\\textbf{X}_d=\\textbf{x}_d) = P(\\textbf{X}_d=\\textbf{x}_d|\\textbf{X}_c\\in B(\\varepsilon))Vol(B(\\varepsilon))f_{\\textbf{X}_c}(\\textbf{a}_2).\\]\nDividindo ambos os lados por \\(Vol(B(\\varepsilon))\\) e fazendo \\(\\varepsilon \\rightarrow 0\\), os pontos \\(\\textbf{a}_1\\) e \\(\\textbf{a}_2\\) convergem para \\(\\textbf{x}_c\\), resultando em\n\\[g(\\textbf{x}_d,\\textbf{x}_c)=f_{\\textbf{X}_c|\\textbf{x}_d}(\\textbf{x}_c|\\textbf{x}_d)P(\\textbf{X}_d=\\textbf{x}_d)=P(\\textbf{X}_d=\\textbf{x}_d|\\textbf{X}_c= \\textbf{x}_c)f_{\\textbf{X}_c}(\\textbf{x}_c)\\]\n\nPropriedades\n\nProbabilidades:\n\n\\[P(\\textbf{X}_d\\in A,\\textbf{X}_c\\in B)=\\sum_{\\textbf{x}_d\\in A}\\int_{B}g(\\textbf{x}_d,\\textbf{x}_c)d\\textbf{x}_c.\\] 2. Distribuição marginal de \\(\\textbf{X}_d:\\)\n\\[P(\\textbf{X}_d=\\textbf{x}_d)=\\int g(\\textbf{x}_d,\\textbf{x}_c)d\\textbf{x}_c.\\]\n\nDistribuição marginal de \\(\\textbf{X}_c:\\)\n\n\\[f(\\textbf{x}_c)=\\sum_{\\textbf{x}_d} g(\\textbf{x}_d,\\textbf{x}_c).\\]\n\nCondicional de \\(\\textbf{X}_d|\\textbf{X}_c=\\textbf{x}_c\\):\n\n\\[P(\\textbf{X}_d=\\textbf{x}_d|\\textbf{X}_c=\\textbf{x}_c)=\\frac{g(\\textbf{x}_d,\\textbf{x}_c)}{f(\\textbf{x}_c)}.\\]\n\nCondicional de \\(\\textbf{X}_c|\\textbf{X}_d=\\textbf{x}_d\\):\n\n\\[f(\\textbf{x}_c|\\textbf{x}_d)=\\frac{g(\\textbf{x}_d,\\textbf{x}_c)}{P(\\textbf{X}_d=\\textbf{x}_d)}.\\]\n\n\nExample 4.1 Seja \\(X|y\\sim\\hbox{Bernoulli}(y)\\) e \\(y\\sim\\hbox{Uniforme}(0,1)\\). Então\n\\[g(x,y)=y^x(1-y)^{1-x}I_{\\{0,1\\}}(x)I_{(0,1)}(y).\\] Em particular, a marginal de \\(X\\) é \\[P(X=x)=\\int_0^1 y^{x}(1-y)^{1-x}dy=\\frac{\\Gamma(x+1)\\Gamma(2-x)}{\\Gamma(3)}I_{\\{0,1\\}}(x)\\] e 4\n\\[f(y|x)=\\frac{y^x(1-y)^{1-x}}{\\Gamma(x+1)\\Gamma(2-x)/\\Gamma(3)}=\\frac{\\Gamma(3)}{\\Gamma(x+1)\\Gamma(2-x)}y^{x}(1-y)^{1-x}I_{(0,1)}(y)\\]\n\n\nExercise 4.1 Sejam \\(X|y\\sim\\hbox{Binomial}(n,y)\\) e \\(y\\in\\hbox{Uniforme}(0,1)\\). Encontre a distribuição marginal de \\(X\\) e a condicional \\(Y|X=x\\).\n\n\nExercise 4.2 Sejam \\(X|y\\sim\\hbox{Poisson}(y)\\) e \\(y\\in\\hbox{Exponencial}(1)\\). Encontre a distribuição marginal de \\(X\\) e a condicional \\(Y|X=x\\).\n\n\nExercise 4.3 Sejam \\(X|y\\sim\\hbox{Geométrica}(y)\\) e \\(y\\in\\hbox{Uniforme}(0,1)\\). Encontre a distribuição marginal de \\(X\\) e a condicional \\(Y|X=x\\).\n\nExercício Solução Exercício 2.4Suponha que P(X=x)=12, com x=0,1 . Suponha ainda que Y|X=x∼Normal(x,1) . Mostre que\nP(X=0|Y=y)=(1+exp{y−12})−1\nExercício Solução Exercício 2.5Suponha que X∼Gama(2,1) e Y|X=x∼Poisson(x) . Encontre a densidade de X|Y=y .",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Vetores aleatórios mistos</span>"
    ]
  },
  {
    "objectID": "covariancia.html",
    "href": "covariancia.html",
    "title": "5  Covariância, correlação e esperança condicional",
    "section": "",
    "text": "5.1 Covariância\nNeste capítulo, estamos interessados na definição de covariância e correlação para um par \\((X,Y)\\) de variáveis aleatórias, assim como as propriedade de \\(E(Y|X=x)\\). É possível estender esses resultados de modo natural para o par \\((\\textbf{X},\\textbf{Y})\\) de vetores aleatórios, mas isso será feito no curso de Estatística Multivariada I\nSeja \\(\\textbf{x}\\) um vetor de comprimento \\(n\\). A distância de \\(\\textbf{x}\\) até a origem é denominada norma e é calculada por\n\\[||\\textbf{x}||=\\sqrt{\\sum_{i=1}^n x_i^2}.\\]\nAgora, considerando outro vetor \\(\\textbf{y}\\), também de comprimento \\(n\\), definimos o produto interno de \\(\\text{x}\\) e \\(\\textbf{y}\\) por\n\\[\\langle\\textbf{x},\\textbf{y}\\rangle=\\sum_{i=1}^n x_iy_i.\\] Pode-se mostrar que\n\\[\\langle\\textbf{x},\\textbf{y}\\rangle=||\\textbf{x}||||\\textbf{y}||\\cos\\theta,\\] onde \\(\\theta\\) é o ângulo formado entre os vetores \\(\\textbf{x}\\) e \\(\\textbf{y}\\). Portanto, o produto interno possui interpretação direta com a relação entre as direções de \\(\\textbf{x}\\) e \\(\\textbf{y}\\): a) se \\(\\langle\\textbf{x},\\textbf{y}\\rangle\\) é positivo, então os vetores apontam para o mesmo sentido (b) se negativo, eles apontam para o sentidos contrários e (c) se nulo, eles são ortogonais. É imediato que\n\\[||\\textbf{x}||=\\sqrt{\\langle \\textbf{x},\\textbf{x}\\rangle}.\\]\nAgora, sem perda de generalidade, assuma que \\(X\\) e \\(Y\\) são variáveis aleatórias discretas com média zero.\nDefina o produto interno ponderado\n\\[\\langle \\textbf{x},\\textbf{y}\\rangle_P=\\sum_{(x,y)\\in\\mathbb{Z}^2}xyP(X=x,Y=y)=E(XY),\\] onde pode-se notar que cada combinação possível de \\((x,y)\\) é ponderada com sua respectiva probabilidade. Observe que\n\\[||\\textbf{x}||_P=\\sqrt{\\langle \\textbf{x},\\textbf{x}\\rangle_P}=\\sqrt{E(X^2)}=\\sqrt{Var(X)},\\] onde a última igualdade é válida porque \\(E(X)=0\\). Essa quantidade, conhecida como desvio padrão, é interpretada como a norma do vetor \\(\\textbf{x}\\), o que explica porque o desvio padrão é considerado uma medida de distância. Se considerarmos que \\(E(X)=\\mu\\), o centro de massa não é mais zero. Podemos definir o vetor centrado em \\(\\mu\\), \\(\\tilde{\\textbf{x}}=\\textbf{x}-\\mu\\). A norma deste vetor considerando o produto interno ponderado é\n\\[||\\tilde{\\textbf{x}}||_P=\\sqrt{\\langle \\textbf{x}-\\mu,\\textbf{x}-\\mu\\rangle_P}=\\sqrt{E((X-\\mu)^2)}=\\sqrt{Var(X)},\\] que é o desvio padrão tradicional.\nSe consideramos que \\(E(X)=\\mu_X\\) e \\(E(Y)=\\mu_Y\\) são diferentes de zero, o produto interno ponderado dos vetores centrados \\(\\tilde{\\textbf{x}}=\\textbf{x}-\\mu_X\\) e \\(\\tilde{\\textbf{y}}=\\textbf{y}-\\mu_Y\\), teremos\n\\[\\langle \\tilde{\\textbf{x}},\\tilde{\\textbf{y}}\\rangle_P=\\sum_{(x,y)\\in\\mathbb{Z}^2} (x-\\mu_X)(y-\\mu_Y)P(X=x,Y=y)=E\\left((X-\\mu_X)(Y-\\mu_Y)\\right).\\] Observe que a definição do produto interno ponderado pode ser modificada para um par \\((X,Y)\\) de variáveis aleatórias contínuas:\n\\[\\langle \\textbf{x},\\textbf{y}\\rangle_P=\\int_{\\mathbb{R}^2}xyf(x,y)dxdy=E(XY),\\] o que gera as mesmas interpretações dadas para o caso discreto. Podemos então definir formalmente a covariância entre \\(X\\) e \\(Y\\).\nPode-se mostrar que\n\\[Cov(X,Y)=E(XY)-E(X)E(Y),\\] o que é, em geral, mais simples de se obter. Na prática, a covariância dá a relação entre as variáveis \\(X\\) e \\(Y\\) centradas em seus respectivos centros de massa: (a) Se \\(Cov(X,Y)&lt;0\\), então espera-se que o aumento(decrescimento) de \\(X\\) implique em um decrescimento(aumento) de \\(Y\\), (b) se \\(Cov(X,Y)&gt;0\\), então espera-se que o aumento(decrescimento) de \\(X\\) implique em um aumento(decrescimento) de \\(Y\\) e (c) \\(Cov(X,Y)=0\\) implica na ausência de relação linear entre \\(X\\) e \\(Y\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Covariância, correlação e esperança condicional</span>"
    ]
  },
  {
    "objectID": "covariancia.html#covariância",
    "href": "covariancia.html#covariância",
    "title": "5  Covariância, correlação e esperança condicional",
    "section": "",
    "text": "Definition 5.1 Sejam \\(X\\) e \\(Y\\) duas variáveis aleatórias quaisquer. Então, a covariância entre \\(X\\) e \\(Y\\) é dada por\n\\[Cov(X,Y)=E((X−E(X))(Y−E(Y))),\\]\n\n\n\n\nExample 5.1 A tabela abaixo mostra a função de probabilidade conjunta \\[\\begin{array}{|c|ccc|c|}\n\\hline\nX \\setminus Y & 1 & 2 & 3 & P(X=x) \\\\ \\hline\n0 & 0,1 & 0,2 & 0,3 & \\mathbf{0,6} \\\\\n1 & 0,2 & 0,1 & 0,1 & \\mathbf{0,4} \\\\ \\hline\nP(Y=y) & \\mathbf{0,3} & \\mathbf{0,3} & \\mathbf{0,4} & \\mathbf{1,0} \\\\ \\hline\n\\end{array}\\]\nVamos encontrar a covariância de \\((X,Y)\\):\n\nEsperanças marginais:\n\n\\[\\begin{align}E(X)&=0\\cdot 0,6+1\\cdot0,4=0,4\\\\\nE(Y)&=1\\cdot0,3+2\\cdot0,3+3\\cdot0,4=2,1\\end{align}\\]\n\nEsperança do produto\n\n\\[\\begin{align}E(XY)&=\\sum_{x=0}^1\\sum_{y=1}^2P(X=x,Y=y)\\\\&=\\sum_{y=1}^2 0\\cdot yP(X=0,Y=y)+\\sum_{y=1}^2 1\\cdot yP(X=0,Y=y)\\\\&=1\\cdot0,2+2\\cdot0,1+3\\cdot0,1=0,7\\end{align}\\] * Resultado da Covariância\n\\[Cov(X, Y) = 0,7 - 0,4\\cdot 2,1=0,7-0,84 = -0,14\\]\n\nInterpretação: A covariância negativa indica que as variáveis tendem a se mover em direções opostas.\n\n\n\nExercise 5.1 A tabela abaixo apresenta a função de probabilidade conjunta para \\((X,Y)\\).\\[\\begin{array}{|c|ccc|c|}\n\\hline\nX \\setminus Y & 1 & 2 & 3 & P(X=x) \\\\ \\hline\n0 & 0,05 & 0,15 & 0,30 & \\mathbf{0,50} \\\\\n1 & 0,25 & 0,15 & 0,10 & \\mathbf{0,50} \\\\ \\hline\nP(Y=y) & \\mathbf{0,30} & \\mathbf{0,30} & \\mathbf{0,40} & \\mathbf{1,00} \\\\ \\hline\n\\end{array}\\]\nDetermine a covariância \\(Cov(X, Y)\\) e interprete o resultado.\n\n\nExample 5.2 Seja a função de densidade de probabilidade conjunta de \\((X, Y)\\) dada por:\n\\[f(x,y) = \\frac{3}{2}(x^2 + y^2)I_{(0,1)}(x)I_{(0,1)}(y).\\]\nVamos encontrar a covariância de \\((X, Y)\\) e interpretar o resultado. Para evitar realizar muitas integrais, vamos encontrar\n\\[E(X^a Y^b)=\\int_{\\mathbb{R}^2} f(x,y)dxdy,\\] para \\(a,b\\geq 0\\). Observe que escolhendo \\(a=1\\) e \\(b=0\\) teremos \\(E(X^aY^b)=E(X)\\) e, de modo semelhante, podemos obter a esperança de \\(E(Y)\\) e \\(E(XY)\\).\n\\[\\begin{align}E(X^a Y^b) &= \\frac{3}{2}\\int_{0}^{1}\\int_0^1 x^a y^b(x^2 + y^2) dxdy \\\\&= \\frac{3}{2}\\int_0^1 \\left[ \\frac{x^{a+3}}{a+3}y^{b} + \\frac{x^{a+1}}{a+1}y^{2+b} \\right]_0^1dy \\\\&= \\frac{3}{2}\\int_0^1  \\frac{1}{a+3}y^{b} + \\frac{1}{a+1}y^{2+b} dy\\\\ &=\\frac{3}{2}\\left[ \\frac{1}{a+3}\\frac{y^{b+1}}{b+1} + \\frac{1}{a+1}\\frac{y^{3+b}}{3+b} \\right]_0^1\\\\&=\\frac{3}{2}\\left( \\frac{1}{(a+3)(b+1)} + \\frac{1}{(a+1)(3+b)} \\right).\\end{align}\\]\nDisto, teremos que \\[E(X)=\\frac{3}{2}\\left( \\frac{1}{4\\cdot 1} + \\frac{1}{2\\cdot3} \\right)=\\frac{5}{8}\\] e, \\(E(Y)=5/8\\). Já\n\\[E(XY) = \\frac{3}{2}\\left( \\frac{1}{4\\cdot 2} + \\frac{1}{2\\cdot 4} \\right)=\\frac{3}{8}\\]\ne a covariância de \\((X,Y)\\) é\n\\[Cov(X,Y)=E(XY)-E(X)E(Y)=\\frac{3}{8}-\\frac{5}{8}\\cdot\\frac{5}{8}=-\\frac{1}{64}\\] Como o valor é negativo, existe uma tendência de que, quando \\(X\\) aumenta, \\(Y\\) diminua (e vice-versa), embora a magnitude seja muito pequena.\n\n\nExercise 5.2 Seja\n\\[f(x,y)=2xy+\\frac{1}{2},\\] para \\((x,y)\\in(0,1)\\). Encontre a covariância de \\((X,Y)\\) e interprete o resultado.\n\n\nProposição Se \\(X\\) e \\(Y\\) são independentes, então \\(Cov(X,Y)=0\\).\nImportante: \\(Cov(X,Y)=0\\) não implica em \\(X\\) e \\(Y\\) serem independentes!\n\n\nExample 5.3 Suponha que\n\\[P(X=x,Y=y)=\\frac{1}{4}\\], com \\((x,y)\\in\\{−1,1\\}^2\\). Então\n\\[P(X=x)P(Y=y)=P(X=x,Y=−1)+P(X=x,Y=1)=\\frac{1}{2}=P(X=−1,Y=y)+P(X=1,Y=y)=\\frac{1}{2}.\\] Como\n\\[\\frac{1}{4}=P(X=x,Y=y)=\\frac{1}{2}\\frac{1}{2}=P(X=x)P(Y=y),\\] temos que \\(X\\) e \\(Y\\) são independentes e, portanto \\(Cov(X,Y)=0\\).\n\n\nExercise 5.3 Suponha que \\(X\\) e \\(Y\\) assumem valores em \\(\\{−1,0,1\\}\\) com a seguinte função de probabilidade conjunta:\n\\[P(X=x,Y=y)=\\frac{1}{5}\\] se, \\((x,y)\\in\\{(1,1),(−1,1),(1,−1),(−1,−1),(0,0)\\}\\) e \\(P(X=x,Y=y)=0\\) em caso contrário. Mostre que \\(X\\) e \\(Y\\) não são independentes e que \\(Cov(X,Y)=0\\).\n\n\nExercise 5.4 Considere a densidade conjunta\n\\[f(x,y)=\\frac{1}{y}e^{−(y+xy)}\\], para \\(x,y&gt;0\\). Encontre Cov(X,Y). É possível mostrar que \\(X\\) não é independente de \\(Y\\) através deste resultado?\n\n\nPropriedades\n\n\\(Cov(X,X)=Var(X)\\) (Identidade)\nPara \\(a\\)e \\(b\\) constantes e reais, \\(Cov(aX,bY)=abCov(X,Y)\\) (Escalonamento)\nPara \\(a\\) constante real, \\(Cov(X,a)=0\\) (Constante)\n\\(Cov(X+Y,Z)=Cov(X,Z)+Cov(Y,Z)\\) e \\(Cov(X,Z+Y)=Cov(X,Z)+Cov(X,Y)\\) (Aditividade bilinear)\n\n\n\nExample 5.4 Suponha que as variáveis aleatórias \\(X\\), \\(Y\\) e \\(Z\\) possuam as seguintes características:\n\n\\(\\text{Cov}(X, Y) = 5\\)\n\\(\\text{Cov}(X, Z) = -2\\)\n\\(\\text{Var}(X) = 4\\)\n\nCalcule os valores solicitados abaixo:\n\n\\(\\text{Cov}(3X, Y)\\)\n\\(\\text{Cov}(X, X)\\)\n\\(\\text{Cov}(X, Y + Z)\\)\n\\(\\text{Cov}(2X, 4)\\)\n\\(\\text{Cov}(4X, 2Y - 3Z)\\)\n\nSolução\n\nPela Propriedade 2 (Escalonamento):\n\n\\[\\text{Cov}(3X, Y) = 3 \\cdot \\text{Cov}(X, Y)= 3 \\cdot 5 = 15\\]\n\nPela Propriedade 1 (Identidade):\n\n\\[\\text{Cov}(X, X) = \\text{Var}(X)=4\\]\n\nPela Propriedade 4 (Aditividade bilinear):\n\n\\[\\text{Cov}(X, Y + Z) = \\text{Cov}(X, Y) + \\text{Cov}(X, Z)= 5 + (-2) = 3\\]\n\nPela Propriedade 3 (Constante): como 4 é uma constante,\n\n\\[\\text{Cov}(2X, 4) = 0\\]\n\nPelas Propriedades 2 e 4:\n\n\\[\\begin{align}\\text{Cov}(4X, 2Y - 3Z) &= \\text{Cov}(4X, 2Y) + \\text{Cov}(4X, -3Z)\\\\&= 4 \\cdot 2 \\cdot \\text{Cov}(X, Y) + 4 \\cdot (-3) \\cdot \\text{Cov}(X, Z)\\\\&= 8 \\cdot (5) + (-12) \\cdot (-2)= 40 + 24 = 64\\end{align}\\]\n\n\nExercise 5.5 Sabe-se que:\n\n\\(\\text{Cov}(X, Y) = -3\\)\n\\(\\text{Cov}(X, Z) = 4\\)\n\\(\\text{Cov}(Y, Z) = 1\\)\n\\(\\text{Var}(X) = 9\\)\n\\(\\text{Var}(Y) = 16\\)\n\nUtilizando as propriedades de covariância, determine o valor das seguintes expressões:\n\n\\(\\text{Cov}(X, 5Y)\\)\n\\(\\text{Cov}(X, X + Y)\\)\n\\(\\text{Cov}(2X, 3Z)\\)\n\\(\\text{Cov}(Y, -2)\\)\n\\(\\text{Cov}(X - Z, Y)\\)\n\n\n\nExercise 5.6 Verifique\n\n\\(Cov(X,Y)=Cov(Y,X)\\)\n\\(Cov(X,X)=Var(X)\\)\n\\(Cov(aX,Y)=Cov(X,aY)=aCov(X,Y)\\), \\(a\\) constante.\n\nConclua que \\(Cov(aX,bY)=abCov(X,Y)\\), com \\(a,b\\) constantes.\n\n\nExercise 5.7 Sejam \\(X_1,\\ldots,X_n\\) variáveis aleatórias. Mostre que\n\n\\(Var(X_1+X_2)=Var(X_1)+Var(X_2)+2Cov(X_1,X_2).\\)$\nMostre por indução que \\(Var(\\sum_{i=1}^n X_i)=\\sum_{i=1}^nVar(X_i)+\\sum_{i=1}^n\\sum_{j=1}^nCov(X_i,X_j).\\)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Covariância, correlação e esperança condicional</span>"
    ]
  },
  {
    "objectID": "covariancia.html#correlação",
    "href": "covariancia.html#correlação",
    "title": "5  Covariância, correlação e esperança condicional",
    "section": "5.2 Correlação",
    "text": "5.2 Correlação\nRecorde que, para o produto interno entre vetores, é verdadeiro que\n\\[\\langle \\textbf{x},\\textbf{y}\\rangle=||\\textbf{x}||||\\textbf{y}||\\cos\\theta,\\] onde \\(\\theta\\) é o ângulo formado entre os dois vetores. Logo, tem-se que\n\\[\\cos\\theta=\\frac{\\langle \\textbf{x},\\textbf{y}\\rangle}{||\\textbf{x}||||\\textbf{y}||},\\]\nEm particular, se \\(|\\cos\\theta|=1\\), então \\(\\textbf{x}\\) e \\(\\textbf{y}\\) são paralelos, o que implica que existe \\(b\\) tal que \\(\\textbf{y}=v\\textbf{x}\\) e \\(b\\) possui o mesmo sinal do cosseno.\nPodemos estender essa noção para o par de variáveis aleatórias \\((X,Y)\\), definindo o coeficiente de correlação de Pearson:\n\\[\\rho_{XY}=\\frac{Cov(X,Y)}{\\sqrt{Var(X)Var(Y)}},\\] que é o cosseno do ângulo entre as variáveis centralizadas \\(X-E(X)\\) e \\(Y-E(Y)\\). Esse coeficiente mede o quanto \\(Y\\) e \\(X\\) podem ser escritas como função linear uma da outra. De fato, se \\(|\\rho_{XY}|=1\\), então existem \\(a\\) e \\(b\\) tais que\n\\[P(Y=a+bX)=1,\\] onde o sinal de \\(b\\) é o mesmo de \\(\\rho_{XY}\\). Além disso, \\(\\rho = 0\\) implica em ausência de relação linear\n\nPropriedades. Sejam \\(X\\) e \\(Y\\) variáveis aleatórias e sejam \\(a,b,c\\) e \\(d\\) constantes conhecidas. Então, o coeficiente de correlação possui as seguintes propriedades:\n\nLimitação do Intervalo:\n\n\\[-1 \\leq \\rho(X,Y) \\leq 1\\]\n\nInvariância por mudança de locação e escala: Sejam \\(U = aX + b\\) e \\(V = cY + d\\). Então \\[\\rho(aX + b, cY + d) = \\text{sinal}(a \\cdot c) \\cdot \\rho(X,Y).\\] A função \\(\\text{sinal}(x)\\) retorna 1 se \\(x&gt;0\\), \\(-1\\) se \\(x&lt;0\\) e 0 em caso contrário. Se \\(a\\) e \\(c\\) tiverem o mesmo sinal (\\(ac &gt; 0\\)), a correlação não muda. Se \\(a\\) e \\(c\\) tiverem sinais opostos (\\(ac &lt; 0\\)), a correlação inverte o sinal. As constantes somadas (\\(b\\) e \\(d\\)) não afetam o resultado.\nSimetria:\n\n\\[\\rho(X,Y) = \\rho(Y,X)\\]\n\nCorrelação com a própria variável:\n\n\\[\\rho(X,X) = 1\\]\n\n\nExample 5.5 Suponha que a correlação entre a variável \\(X\\) e \\(Y\\) seja \\(\\rho(X,Y) = 0,6\\). Determine:\n\n\\(\\rho(2X, Y)\\)\n\\(\\rho(X + 10, Y - 5)\\)\n\\(\\rho(-3X, Y)\\)\n\\(\\rho(-2X, -4Y)\\)\n\nSolução.\n\nComo o coeficiente de \\(X\\) é positivo (\\(2\\)), a correlação permanece idêntica.\nSomar ou subtrair constantes não altera a correlação.\nComo multiplicamos uma das variáveis por um número negativo (sinais opostos), o sinal da correlação inverte. Resultado: \\(-0,6\\)\nAmbos os coeficientes são negativos. Como o produto de dois negativos é positivo (\\(ac &gt; 0\\)), o sinal original se mantém. Resultado: \\(0,6\\)\n\n\n\nExercise 5.8 Sejam \\(X\\) e \\(Y\\) variáveis aleatórias com \\(\\text{Var}(X) = 25\\), \\(\\text{Var}(Y) = 16\\), \\(\\text{Cov}(X, Y) = 12\\) e\\(\\rho(X, Y) = 0,6\\). Utilizando as propriedades, determine os novos valores para as situações abaixo:\n\n\\(\\text{Cov}(2X, 3Y)\\)\n\\(\\text{Cov}(X + 5, Y - 10)\\)\n\\(\\text{Cov}(X, X + Y)\\)\n\\(\\rho(4X, Y)\\)\n\\(\\rho(-X, Y)\\)\n\\(\\rho(X - 100, 2Y + 30)\\)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Covariância, correlação e esperança condicional</span>"
    ]
  },
  {
    "objectID": "covariancia.html#esperança-condicional",
    "href": "covariancia.html#esperança-condicional",
    "title": "5  Covariância, correlação e esperança condicional",
    "section": "5.3 Esperança condicional",
    "text": "5.3 Esperança condicional\nA esperança \\(X\\) condicionada à \\(Y=y\\) é denotada por \\(E(X|Y=y)\\) e se refere à esperança obtida a partir da distribuição de \\((X|Y=y)\\). Se \\(X\\) é uma variável aleatória contínua, a esperança condicional é dada por\n\\[E(X|Y=y)=\\int_{\\mathbb{R}}x f(x|y)dx, \\] e se \\(X\\) for discreta, \\[E(X|Y=y)=\\sum_{x\\in\\mathbb{Z}} xP(X=x|Y=y).\\]\nDe modo análogo, para qualquer função real \\(g(.)\\) podemos definir \\(E(g(X)|Y=y)\\).\n\nExample 5.6 Seja \\((X,Y)\\) um vetor aleatório com função de probabilidade conjunta dada por\n\\[P(X=x,Y=y)=\\frac{1}{2^yy}I_{\\{1,\\ldots,y\\}}(x)I_{\\{1,2,\\ldots\\}}(y).\\]\nVamos encontrar \\(E(X|Y=y)\\). A função de probabilidade marginal de \\(Y\\) é\n\\[\\begin{align}P(Y=y)&=\\sum_{x=-\\infty}^\\infty\\frac{1}{2^yy}I_{\\{1,\\ldots,y\\}}(x)I_{\\{1,2,\\ldots\\}}(y)\\\\&=\\frac{1}{2^y}I_{\\{1,2,\\ldots,\\}}(y)\\sum_{x=1}^y\\frac{1}{y}\\\\&=\\frac{1}{2^y}I_{\\{1,2,\\ldots,\\}}(y)\\end{align}\\] logo,\n\\[P(X=x|Y=y)=\\frac{\\frac{1}{2^yy}I_{\\{1,\\ldots,y\\}}(x)I_{\\{1,2,\\ldots\\}}(y)}{\\frac{1}{2^y}I_{\\{1,2,\\ldots,\\}}(y)}=\\frac{1}{y}I_{\\{1,\\ldots,y\\}}(x),\\] e\n\\[E(X|Y=y)=\\sum_{x=-\\infty}^\\infty x\\frac{1}{y}I_{\\{1,\\ldots,y\\}}(x)=\\frac{1}{y}\\sum_{x=1}^y x=\\frac{1+y}{2}.\\]\n\n\nExercise 5.9 Seja \\((X,Y)\\) um vetor aleatório com função de probabilidade conjunta dada por\n\\[P(X=x,Y=y)=\\frac{e^{-2}2^y}{y!y}I_{\\{1,\\ldots,y\\}}(x)I_{\\mathbb{N}}(y).\\]\nEncontre \\(E(X|Y=y)\\).\n\n\nExample 5.7 Seja \\((X,Y)\\) um vetor aleatório com função densidade conjunta dada por\n\\[f(x,y)=e^{-x}I_{(y,\\infty)}(x)I_{(0,\\infty)}(y)\\] Vamos encontrar \\(E(X|Y=y)\\). Primeiro, a função densidade marginal de \\(Y\\) é dada por\n\\[f_Y(y)=I_{(0,\\infty)}(y)\\int_\\mathbb{R}e^{-x}I_{(y,\\infty)}(x)dx=I_{(0,\\infty)}(y)\\int_y^\\infty e^{-x}dx=e^{-y}I_{(0,\\infty)}(y),\\] logo, a função densidade condicional de \\(X|Y=y\\) é\n\\[f(x|y)=\\frac{e^{-x}I_{(y,\\infty)}(x)I_{(0,\\infty)}(y)}{e^{-y}I_{(0,\\infty)}(y)}=e^{-(x-y)}I_{(y,\\infty)}(x)\\] e\n\\[\\begin{align}E(X|Y=y)&=\\int_y^\\infty xe^{-(x-y)}dx=\\int_0^\\infty (u+y)e^{-u}du\\\\&=1+y\\end{align}\\]\n\n\nExercise 5.10 Seja \\((X,Y)\\) um vetor aleatório com função densidade conjunta dada por\n\\[f(x,y)=\\frac{1}{y^3}I_{(0,y)}(x)I_{(1,\\infty)}(y)\\] Vamos encontrar \\(E(X|Y=y)\\).\n\nObviamente, outros momentos além do primeiro podem ser calculados. Disto, por exemplo, temos que\n\\[Var(X|Y=y)=E(X^2|Y=y)−E(X|Y=y)^2.\\]\n\nProposition 5.1 Sejam \\(X\\) e \\(Y\\) variáveis aleatórias com esperança finita. Então,\n\\[E(X)=E(E(X|Y)).\\]\nAlém disso, se a variância for finita, então,\n\\[Var(X)=E(Var(X|Y))+Var(E(X|Y)).\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Covariância, correlação e esperança condicional</span>"
    ]
  },
  {
    "objectID": "covariancia.html#exercícios-de-fixação",
    "href": "covariancia.html#exercícios-de-fixação",
    "title": "5  Covariância, correlação e esperança condicional",
    "section": "5.4 Exercícios de fixação",
    "text": "5.4 Exercícios de fixação\n\nExercise 5.11 Seja \\(X\\) uma variável aleatória tal que \\(E(X) = 0\\) e \\(Var(X) = 9\\). Considere \\(Y = -2X\\). Encontre \\(Cov(X,Y)\\) e \\(\\rho(X,Y)\\)\n\n\nExercise 5.12 Seja a função de densidade conjunta de \\((X, Y)\\) dada por:\\[f(x,y) = (x + y) \\cdot I_{(0,1)}(x) \\cdot I_{(0,1)}(y).\\]\nCalcule \\(Cov(X, Y)\\) e determine se as variáveis tendem a variar no mesmo sentido ou em sentidos opostos.\n\n\nExercise 5.13 Suponha que \\(X\\) tenha uma distribuição simétrica em relação a zero (ou seja, \\(E(X) = E(X^3) = 0\\)) e defina \\(Y = X^2\\).\n\nMostre que \\(Cov(X, Y) = 0\\).\nExplique por que, apesar da covariância nula, \\(X\\) e \\(Y\\) não são independentes.\n\n\n\nExercise 5.14 Considere três variáveis \\(X, Y\\) e \\(Z\\) tais que \\(Var(X)=4, Var(Y)=9, Var(Z)=1\\) e todas são independentes entre si. Defina \\(U = 2X - Y\\) e \\(V = X + 3Z\\).Calcule \\(Cov(U, V)\\).\n\n\nExercise 5.15 A correlação entre o consumo de combustível (\\(X\\)) e a distância percorrida (\\(Y\\)) é \\(\\rho(X, Y) = 0,85\\). Se mudarmos a unidade de \\(X\\) de litros para galões (multiplicando por \\(0,26\\)) e subtrairmos uma taxa fixa de manutenção de \\(Y\\), qual será a nova correlação? Justifique com base nas propriedades de invariância.\n\n\nExercise 5.16 Seja \\((X, Y)\\) tal que \\(Y \\sim \\text{Exponencial}(1)\\) e, dado \\(Y=y\\), a variável \\(X\\) tem distribuição Uniforme no intervalo \\((0, y)\\). Encontre \\(E(X|Y=y)\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Covariância, correlação e esperança condicional</span>"
    ]
  },
  {
    "objectID": "convergencia.html",
    "href": "convergencia.html",
    "title": "6  Convergência de variáveis aleatórias",
    "section": "",
    "text": "6.1 A noção de limite tradicional\nSeja \\(X_1,\\ldots,X_n\\) uma amostra de variáveis aleatórias (dizemos que esta amostra tem tamanho \\(n\\)). Qualquer função desta amostra é denominada estatística. Exemplos de estatística são a média amostral, variância amostral, mediana amostral etc. Por serem funções de variáveis aleatórias, qualquer estatística também será uma variável aleatória. Seja \\(T_n\\) uma estatística baseada em \\(X_1,\\ldots,X_n\\). A intuição nos diz que o aumento de \\(n\\) deve trazer alguma vantagem. Estamos então interessados em entender o comportamento de \\(P(T_n&lt;t)\\) quando \\(n\\rightarrow \\infty\\).\nA discussão acima é apenas um exemplo da importância do estudo de convergência de variáveis aleatórias, que é o tópico desse capítulo.\nNeste tópico iremos discutir:\nDizemos que \\(L\\) é o limite de \\(f(x)\\) quando \\(x\\) se aproxima de \\(x_0\\) se, para todo \\(\\varepsilon&gt;0\\), existe \\(\\delta&gt;0\\) tal que\nse \\(0&lt;|x-x_0|&lt;\\delta\\Rightarrow |f(x)−L|&lt;\\varepsilon\\)\nA notação \\[\\lim_{x\\rightarrow x_0}f(x)=L\\] é a mais usual em livros de cálculo mas nos será mais conveniente escrever \\(f(x)\\rightarrow L\\) quando \\(x\\rightarrow x_0\\) (lê-se \\(f(x)\\) tende a \\(L\\) quando \\(x\\) tende a \\(x_0\\)).\nEstamos interessados no caso em que \\(x \\rightarrow \\infty\\). Dizemos que \\(f(x) \\rightarrow L\\) quando \\(x \\rightarrow \\infty\\) se, para todo \\(\\epsilon &gt; 0\\), existe \\(x_0\\) tal que:\\[\\text{se } x &gt; x_0 \\Rightarrow |f(x) - L| &lt; \\epsilon\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergência de variáveis aleatórias</span>"
    ]
  },
  {
    "objectID": "convergencia.html#a-noção-de-limite-tradicional",
    "href": "convergencia.html#a-noção-de-limite-tradicional",
    "title": "6  Convergência de variáveis aleatórias",
    "section": "",
    "text": "Example 6.1 Vamos mostrar que \\(f(x)=1/x\\) tende a zero quando \\(x\\rightarrow\\infty\\).\nIsto implica em mostrar que, para qualquer \\(\\varepsilon&gt;0\\) deve existir \\(x_0\\) tal que, para qualquer \\(x&gt;x_0\\)\n\\[\\left|\\frac{1}{x}\\right|&lt;\\varepsilon\\].\nNote que, para qualquer \\(x_0&gt;0\\) arbitrário, é verdade que\n\\[x&gt;x_0\\Rightarrow \\frac{1}{x}&lt;\\frac{1}{x_0},\\] Logo, para qualquer \\(\\varepsilon&gt;0\\), podemos fazer \\(x_0=\\varepsilon^{-1}\\) de modo que\n\\[x&gt;x_0\\Rightarrow \\left|\\frac{1}{x}-0\\right|&lt;\\frac{1}{x_0}=\\varepsilon,\\] o que implica que o limite de \\(1/x\\) quando \\(x\\rightarrow\\infty\\) é igual a 0.\n\n\nTheorem 6.1 Teorema do Confronto (ou do Sanduíche)Suponha que, para todo \\(x\\) suficientemente grande, tenhamos:\\[0 \\leq |f(x)| \\leq g(x)\\]Se \\(\\lim_{x\\rightarrow\\infty} g(x) = 0\\), então:\\[\\lim_{x\\rightarrow\\infty} f(x) = 0\\]\n\n\nExercise 6.1 Limite de \\(1/x^2\\)\n\nSe \\(x &gt; 1\\), mostre que \\(x^2 &gt; x\\).\n\nUtilizando o resultado do item (a) e o Teorema do Confronto, prove que: \\[\\lim_{x \\to \\infty} \\frac{1}{x^2} = 0\\] (Dica: Lembre-se que \\(0 &lt; \\frac{1}{x^2} &lt; \\frac{1}{x}\\) para \\(x &gt; 1\\)).\n\n\n\nExercise 6.2 Limite de função racional\n\nSe \\(x &gt; 1\\), mostre que \\(x^2 + 1 &gt; x\\).\n\nUtilizando o resultado do item (a) e o Teorema do Confronto, mostre que: \\[\\frac{x}{x^2 + 1} \\to 0 \\text{ quando } x \\to \\infty\\]\n\n\n\nExercise 6.3 Limite da função exponencial\nSeja \\(0 &lt; a &lt; 1\\). Mostre que: \\[a^x \\to 0 \\text{ quando } x \\to \\infty\\] (Dica: Escreva \\(a = \\frac{1}{1+b}\\) onde \\(b &gt; 0\\) e utilize a desigualdade de Bernoulli \\((1+b)^x &gt; 1 + xb\\) para aplicar o Teorema do Confronto).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergência de variáveis aleatórias</span>"
    ]
  },
  {
    "objectID": "convergencia.html#convergência-em-probabilidade",
    "href": "convergencia.html#convergência-em-probabilidade",
    "title": "6  Convergência de variáveis aleatórias",
    "section": "6.2 Convergência em probabilidade",
    "text": "6.2 Convergência em probabilidade\nSejam \\(X_1,X_2,\\ldots\\) uma sequência de variáveis aleatórias definidas no mesmo espaço de probabilidade da variável aleatória \\(X\\). Dizemos que \\(X_n\\) converge em probabilidade para a variável aleatória \\(X\\) quando \\(n\\rightarrow\\infty\\) se para todo \\(\\varepsilon&gt;0\\)\n\\[P(|X_n−X|\\geq \\varepsilon)\\rightarrow 0,\\] quando \\(n\\rightarrow\\infty\\). Neste caso, utilizamos a notação \\(X_n\\stackrel{P}{\\rightarrow}X\\) quando \\(n\\rightarrow \\infty\\)(lê-se \\(X_n\\) converge em probabilidade para \\(X\\) quando \\(n\\) tende ao infinito).\nNote que se \\(X_n\\) converge em probabilidade para \\(X\\), então a probabilidade do evento \\(X_n\\in(X−\\varepsilon,X+\\varepsilon)\\) ocorrer tende a 1. De modo equivalente, podemos dizer que \\(X_n\\stackrel{P}{\\rightarrow}X\\) se\n\\[P(|X_n−X|&lt;\\varepsilon)\\rightarrow1,\\] quando \\(n\\rightarrow\\infty\\).\n\nExample 6.2 Sejam \\(X_1,X_2,\\ldots\\) uma sequência de variáveis aleatórias com \\(X_n\\sim\\hbox{Bernoulli}(1/n)\\). Intuitivamente, a probabilidade de sucesso será cada vez menor, até chegar ao ponto no qual apenas o fracesso será possível. Isto nos leva a considerar que \\(X_n\\stackrel{P}{\\rightarrow}0\\) quando \\(n\\rightarrow\\infty\\). Vamos mostrar que isso é verdade.\nPrimeiro, fixe um valor qualquer para \\(\\varepsilon&gt;0\\). Note que\n\\[|X_n−0|\\geq \\varepsilon\\equiv|X_n|\\geq \\varepsilon&gt;0.\\] Ora, \\(|Xn|=Xn\\), pois a variávei é sempre não negativa. Além disso, \\(X_n\\geq \\varepsilon&gt;0\\) implica que \\(X_n&gt;0\\), e por sua vez, apenas \\(X_n=1\\) é possível. Assim\n\\[P(|X_n−0|\\geq \\varepsilon)=P(X_n&gt;0)=P(X_n=1)=\\frac{1}{n}\\rightarrow 0,\\] quando \\(n\\rightarrow\\infty\\). Portanto, \\(X_n\\stackrel{P}{\\rightarrow}0\\).\n\n\nExample 6.3 Sejam \\(X_1,X_2,\\ldots\\) uma sequência de variáveis aleatórias com distribuição Uniforme(0,\\(\\theta\\)). No problema de inferência estatística, \\(\\theta\\) é desconhecido. Considere a estatística\n\\[T_n=\\hbox{max}\\{X_1,\\ldots,X_n\\}.\\] Vamos mostrar que \\(T_n\\stackrel{P}{\\rightarrow}\\theta\\). Primeiro, lembremos que\n\\[|X−a|&gt;b\\Rightarrow −b&gt;X−a \\hbox{   ou   } b&lt;X−a,\\] e que \\[Tn&lt;\\theta\\Rightarrow X_1&lt;\\theta,\\ldots ,X_n&lt;\\theta.\\]\nEntão, para qualquer \\(\\varepsilon&gt;0\\),\n\\[\\begin{align}P(|T_n−\\theta|&gt;\\varepsilon)&=P(T_n−\\theta&gt;\\varepsilon)+P(T_n−\\theta&lt;−\\varepsilon)\\\\&=P(T_n−\\theta&lt;−\\varepsilon)=P(T_n&lt;−\\varepsilon+\\theta)\\\\&\n=P(X_1&lt;−\\varepsilon+\\theta,\\ldots,X_n&lt;−\\varepsilon+\\theta)\\\\\n&=\\prod_{i=1}^n P(X_i&lt;−\\varepsilon+\\theta)=F(-\\varepsilon+θ)^n=\\left(\\frac{−\\varepsilon+\\theta}{\\theta}\\right)^n\\\\&=\\left(1-\\frac{\\varepsilon}{\\theta}\\right)^n\\rightarrow 0\\end{align}\\] quando \\(n\\rightarrow\\infty\\). Portanto, \\(T_n\\stackrel{P}{\\rightarrow}\\theta\\).\n\n\nExercise 6.4 Seja \\(X_1,X_2,\\ldots,\\) uma sequência de variáveis aleatórias independentes e identicamente distribuídas, com \\(X_n\\leq θ\\) para todo \\(n\\geq 1\\). Seja \\(T_n=\\max\\{X_1,…,X_n\\}.\\) Mostre que \\(T_n\\stackrel{P}{\\rightarrow}\\theta\\) quando \\(n\\rightarrow\\infty\\). Esse resultado mostra que o máximo amostral é uma estatística consistente para estimar \\(\\theta\\).\n\n\nTheorem 6.2 Se \\(X_n\\stackrel{P}{\\rightarrow}b\\), onde \\(b\\) é constante e se \\(g\\) é uma função real contínua em \\(b\\), então então \\(g(X_n)\\stackrel{P}{\\rightarrow}g(b)\\).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergência de variáveis aleatórias</span>"
    ]
  },
  {
    "objectID": "convergencia.html#lei-fraca-dos-grandes-números",
    "href": "convergencia.html#lei-fraca-dos-grandes-números",
    "title": "6  Convergência de variáveis aleatórias",
    "section": "6.3 Lei Fraca dos Grandes Números",
    "text": "6.3 Lei Fraca dos Grandes Números\nFoi John Graunt, um mercador de tecidos, que em 1662 publicou o primeiro trabalho utilizando a proporção amostral como uma probabilidade. A ideia funcionou perfeitamente, mas não se sabia o motivo até a publicação do Ars Conjectandi, de Jacob Bernoulli, em 1713. Ao terminar sua demonstração, ele diz: “Considero que não fiz muita coisa, somente demonstrei o que é conhecimento de todos”. Hoje, seu resultado é um dentro de uma coleção de teoremas denominada Leis dos Grandes Números.\n\nTheorem 6.3 Lei (Fraca) dos Grandes Números de Jacob Bernoulli. Sejam \\(X_1,X_2,\\ldots\\) uma sequência de variáveis aleatórias independentes com \\(X_i\\sim\\hbox{Bernoulli}(p)\\). Então\n\\[\\bar{X}_n=\\sum_{i=1}^n \\frac{X_i}{n}\\stackrel{P}{\\rightarrow}{p}\\] quando \\(n\\rightarrow\\infty\\).\n\nEm resumo, uma Lei dos Grandes Números é um teorema sobre a convergência de \\(\\bar{X}_n\\) quando \\(n\\rightarrow\\infty\\). Se o limite for em probabilidade, a lei é denominada fraca (existem as leis fortes, mas não serão tratadas nesse curso). Foi Simeón Poisson (1837) que cunhou o termo Lei dos Grandes Números e foi o primeiro a generalizar a lei para o caso no qual a sequência as variáveis não era identicamente distribuída. Contudo, esse resultado é mais conhecido como Lei Fraca de Chebyshev, devido à sua demonstração mais simples em 1867. Antes de introduzir essa lei, vamos mostrar o resultado-chave desenvolvido por Chebyshev.\n\nTheorem 6.4 Desigualdade de Chebyshev Seja \\(X\\) uma variável aleatória com média \\(\\mu\\) e variância \\(\\sigma^2\\). Então, para qualquer \\(\\varepsilon&gt;0\\), \\[P(|X-\\mu|\\geq \\varepsilon)\\leq \\frac{\\sigma^2}{\\varepsilon^2}.\\]\n\nVamos fazer a prova da desigualdade. Sem perda de generalidade, assuma que ela é contínua. Então, para qualquer \\(\\varepsilon&gt;0\\),\n\\[\\sigma^2=\\int_{\\mathbb{R}}(x-\\mu)^2f(x)dx\\geq \\int_{\\{x:|x-\\mu|\\geq \\varepsilon\\}}(x-\\mu)^2f(x)dx\\geq \\varepsilon^2P(|X−\\mu|\\geq \\varepsilon)\\] logo, \\[P(|X-\\mu|\\geq \\varepsilon)\\leq \\frac{\\sigma^2}{\\varepsilon^2}.\\]\nAgora vamos enunciar formalmente a Lei Fraca de Chebyshev.\n\nTheorem 6.5 Lei Fraca de Chebyshev. Sejam \\(X_1,X_2,\\ldots\\) uma sequência de variáveis aleatórias não correlacionadas com \\(E(X_n)=\\mu\\) e \\(Var(X_n)&lt;c&lt;\\infty\\). Então\n\\[\\bar{X}_n=\\sum_{i=1}^n\\frac{X_i}{n}\\stackrel{P}{\\rightarrow}\\mu,\\] quando \\(n\\rightarrow\\infty\\).\n\nVamos demonstrar a Lei Fraca de Chebyshev. Observe que, pela desigualdade de Chebyshev,\n\\[P(|\\bar{X}_n-\\mu|\\geq\\varepsilon)\\leq \\frac{Var(\\bar{X}_n)}{\\varepsilon^2}=\\frac{\\sum_{i=1}^nVar(X_i)}{n^2\\varepsilon^2}&lt;\\frac{c}{n\\varepsilon^2}\\rightarrow 0\\] quando \\(n\\rightarrow\\infty\\), o que prova que \\(\\bar{X}_n\\stackrel{P}{\\rightarrow}\\mu\\).\n\nExample 6.4 Seja \\(X_1, X_2, \\dots,\\) uma sequência de variáveis aleatórias independentes que seguem uma distribuição Poisson\\((2)\\). Considere a sequência \\(\\bar{X}_n\\) definida por\n\\[\\bar{X}_n=\\frac{X_1+\\cdots+X_n}{n}\\] Como \\(E(X_i)=2\\), pela Lei Fraca de Chebyshev teremos que \\(\\bar{X}\\stackrel{P}{\\to}2\\) quando \\(n\\to\\infty\\).\n\n\nExercise 6.5 Seja \\(X_1, X_2, \\dots,\\) uma sequência de variáveis aleatórias independentes que seguem uma distribuição Uniforme\\((0, 2)\\). Considere a sequência \\(Y_n\\) definida por\n\\[Y_n = \\frac{X_1^2 + X_2^2 + \\dots + X_n^2}{n}\\]\nDetermine para qual valor constante \\(c\\) a sequência \\(Y_n\\) converge em probabilidade quando \\(n \\to \\infty\\).\n\n\nExercise 6.6 Seja \\(X_1,X_2,\\ldots\\) uma sequencia de variáveis aleatórias com distribuição Bernoulli(\\(p\\)). Definimos a sequência:\\[W_n = \\frac{1}{n} \\sum_{i=1}^n X_i^2\\]\nEncontre o limite em probabilidade de \\(W_n\\) quando \\(n \\to \\infty\\).\n\n\nExercise 6.7 Seja \\(X_1, X_2, \\dots,\\) uma sequência de variáveis independentes e estritamente positivas, onde \\(E(\\log(X_i)) = L\\). Considere a média geométrica\n\\[G_n = \\sqrt[n]{X_1 \\cdot X_2 \\cdot \\dots \\cdot X_n}\\]\nMostre que \\(G_n\\) converge em probabilidade para \\(e^L\\).\n\n\nExercise 6.8 Seja \\(X_1, X_2, \\dots,\\) uma sequência de variáveis aleatórias independentes e identicamente distribuídas com uma função de distribuição \\(F(x) = P(X \\leq x)\\). A Função de Distribuição Empírica é definida por\n\\[\\hat{F}_n(x) = \\frac{1}{n} \\sum_{i=1}^n I_{(-\\infty,x]}(X_i),\\]\n\nFixe um valor real qualquer \\(x\\). Defina uma nova variável aleatória \\(Y_i = I_{(-\\infty,x)}(X_i)\\). Determine a distribuição de \\(Y_i\\) e calcule sua esperança \\(E(Y_i)\\).\nUtilize a Lei Fraca dos Grandes Números para mostrar que, para qualquer valor fixo de \\(x\\):\n\n\\[\\hat{F}_n(x) \\xrightarrow{P} F(x) \\quad \\text{quando } n \\to \\infty\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergência de variáveis aleatórias</span>"
    ]
  },
  {
    "objectID": "convergencia.html#convergência-em-distribuição",
    "href": "convergencia.html#convergência-em-distribuição",
    "title": "6  Convergência de variáveis aleatórias",
    "section": "6.4 Convergência em distribuição",
    "text": "6.4 Convergência em distribuição\n\nDefinition 6.1 Dizemos que a sequência de variáveis aleatórias \\(X_1,X_2,\\ldots\\) converge para \\(X\\) em distribuição se\n\\[\\lim_{n\\to\\infty}F_{X_n}(x)=F_X(x)\\] para todo \\(x\\). Neste caso, \\(X\\) é denominada limite em distribuição de \\(X_n\\).\nNotação: \\(X_n\\stackrel{D}{\\to}X\\) quando \\(n\\to\\infty\\).\n\nÉ importante ressaltar que o limite pode ser calculado em outras funções que caracterizam a distribuição. Por exemplo, também diremos que \\(X_n\\stackrel{D}{\\to}X\\) se\n\n\\(\\lim_{n\\to\\infty}P(X_n=x)=P(X=x)\\) (caso discreto)\n\\(\\lim_{n\\to\\infty}f_{X_n}(x)=f_X(x)\\) (caso contínuo)\n\\(\\lim_{n\\to\\infty}M_{X_n}(t)=M_X(t)\\) (quando existe a função geratriz de momentos).\n\n\nExample 6.5 Seja \\(X_1,X_2,\\ldots\\) uma sequência de variáveis aleatórias independentes e identicamente distribuídas, com \\(X_1\\sim\\hbox{Uniforme}(0,1)\\). Seja\n\\[Y_n=\\min\\{X_1,\\ldots,X_n\\}.\\]\nVamos encontrar o limite em distribuição de \\(Z_n=nY_n\\). Primeiro, lembre que\n\\[I_{(-\\infty,x_1)}(w)I_{(-\\infty,x_2)}(w)=I_{(-\\infty,\\min\\{x_1,x_2\\})}(w)=I_{(-\\infty,y_2)}(w)\\] e, de maneira geral \\[\\prod_{i=1^n}I_{(-\\infty,x_i)}(w)=I_{(-\\infty,y_n)}(w)\\] Isso implica que\n\\[w&lt; x_1,\\ldots,w&lt; x_n\\Leftrightarrow w&lt; y_n\\] Como\n\\[\\begin{align}P(Z_n\\leq z)&=P(nY_n\\leq z)=P\\left(Y_n\\leq\\frac{z}{n}\\right)\\\\&=1-P\\left(Y_n&gt;\\frac{z}{n}\\right)\\\\&=1-P\\left(X_1&gt;\\frac{z}{n},\\ldots,X_n&gt;\\frac{z}{n}\\right)\\\\&=1-\\prod_{i=1}^nP\\left(X_i&gt;\\frac{z}{n}\\right)\\\\&=1-\\left[1-\\frac{z}{n}\\right]^n\\end{align}\\] e, como\n\\[\\lim_{n\\rightarrow\\infty} P(Z_n\\leq z)=1-\\lim_{n\\rightarrow\\infty}\\left(1-\\frac{z}{n}\\right)^n=1-e^{-z},\\] temos que \\(Z_n\\stackrel{D}{\\to}Z\\) quando \\(n\\to\\infty\\), onde \\(Z\\sim\\hbox{Exponencial}(1)\\).\n\n\nTheorem 6.6 (Slutsky) Sejam \\(\\{X_n\\}\\) e \\(\\{Y_n\\}\\) duas sequências de variáveis aleatórias. Suponha que, quando \\(X_n \\xrightarrow{D} X\\) e \\(Y_n \\xrightarrow{P} c\\) \\(n \\to \\infty\\). Então, as seguintes convergências em distribuição são verdadeiras:\n\nSoma: \\(X_n + Y_n \\xrightarrow{d} X + c\\)\nProduto: \\(X_n \\cdot Y_n \\xrightarrow{d} cX\\)\nDivisão: \\(\\frac{X_n}{Y_n} \\xrightarrow{d} \\frac{X}{c}\\), desde que \\(c \\neq 0\\).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergência de variáveis aleatórias</span>"
    ]
  },
  {
    "objectID": "convergencia.html#teorema-central-do-limite",
    "href": "convergencia.html#teorema-central-do-limite",
    "title": "6  Convergência de variáveis aleatórias",
    "section": "6.5 Teorema Central do Limite",
    "text": "6.5 Teorema Central do Limite\nOs astrônomos perceberam cedo que as medições feitas sobre o mesmo corpo celeste geralmente apresentavam erros. Em uma linguagem moderna, eles acreditavam que a verdadeira medida era \\(\\theta\\), enquanto que a medida observada \\(x_i\\) era contaminada por um erro \\(\\xi_i\\), em uma relação aditiva, ou seja\n\\[x_i=\\theta+\\xi_i.\\] Thomas Simpson escreveu em 1755 “A vantagem de calcular a média na astronomia prática”. Nesse trabalho, ele assumiu que os erros \\(\\xi_i\\) deviam (a) ter natureza aleatória, (b) ser simétricos em torno de zero e (c) ter uma moda em 0, com as probabilidades decaindo à medida que nos afastamos da moda. Sua distribuição de erro era\n\\[\\begin{array}{c|ccccccccccc}\\hline\n\\xi & -5 & -4 & -3 & -2 & -1 & 0 & 1 & 2 & 3 & 4 & 5 \\\\ \\hline\nP(\\xi)& \\frac{1}{36} & \\frac{2}{36} & \\frac{3}{36} &\\frac{4}{36} & \\frac{5}{36} & \\frac{6}{36}&\\frac{5}{36}&\\frac{4}{36}&\\frac{3}{36}&\\frac{2}{36}&\\frac{1}{36}\\\\ \\hline\n\\end{array}\\]\nAssumindo essa lei, ele mostrou que calcular a média de triplicatas da medição diminuiria o erro. Atualmente, seria algo como\n\\[\\bar{x}_3=\\theta+\\bar{\\xi_3}\\]\nAbaixo, apresentamos o gráfico da função de probabilidade de \\(\\bar{\\xi}_3\\). Note, por exemplo, que a probabilidade de ocorrer um erro igual a -5 ou 5 é significativamente menor se considerarmos \\(\\bar{x}_3\\).\n\n\n\n\n\n\n\n\n\nNote que, embora fundamentada, a escolha de Simpson para a distribuição dos erros foi arbitrária. De modo não relacionado, De Moivre, na tentativa de calcular \\(P(X=x)\\) quando \\(X\\sim\\hbox{Binomial}(n,1/2)\\) e \\(n\\) é grande, publica em 1733 a expressão\n\\[P(X=x)\\approx\\frac{2}{\\sqrt{2\\pi n}}e^{-\\frac{2}{n}\\left(x-\\frac{n}{2}\\right)^2},\\] algo que identificaríamos hoje em dia com a densidade da Normal\\((n/2, n/4)\\). Voltando ao problema dos erros, em 1805 é publicado o método dos mínimos quadrados, com o qual prova-se que o valor de \\(\\theta\\) que minimiza \\(\\sum_{i=1}^n \\xi_i^2\\) é, de fato \\(\\bar{x}_n\\), o que corrobora o trabalho de Simpson. Com a introdução do Método dos Mínimos Quadrados, provou-se que o valor de \\(\\theta\\) que minimiza a soma dos quadrados dos erros é a média aritmética \\(\\bar{x}_n\\). Gauss, ao unir essas pontas, demonstrou que se os erros seguem a distribuição normal, a média não é apenas uma escolha intuitiva, mas o estimador que maximiza a probabilidade dos dados observados.\nContudo, a escolha da distribuição dos erros ainda parecia depender de suposições específicas até o trabalho de Laplace em 1812 (Théorie Analytique des Probabilités). Nele, Laplace demonstrou que a distribuição da média de um grande número de erros independentes tende à distribuição normal, independentemente da forma da distribuição original dos erros. Esse resultado, que hoje conhecemos como Teorema Central do Limite, forneceu a base teórica definitiva para o uso da média aritmética e da curva normal na ciência.\n\nTheorem 6.7 Teorema Central do Limite. Sejam \\(X_1,X_2\\ldots,\\) uma sequência de variáveis aleatórias independentes e identicamente distribuídas com \\(E(X_1)=\\mu\\) e \\(Var(X_1)=\\sigma^2\\). Então\n\\[Z_n=\\sqrt{n}\\frac{\\bar{X}_n-\\mu}{\\sigma}\\stackrel{D}{\\rightarrow}\\hbox{Normal}(0,1),\\] quando \\(n\\rightarrow\\infty\\).\n\nÉ importante ressaltar que, assim como ocorre com as Leis dos Grandes Números, existe uma coleção de resultados intitulados “Teorema Central do Limite”. O que difere esses teoremas são as condições impostas sobre a sequência \\(X_1, X_2, \\ldots\\), permitindo, em versões mais generalizadas, que as variáveis tenham distribuições distintas ou até mesmo algum grau de dependência. Abaixo, demonstramos o teorema enunciado.\n\nExample 6.6 Demonstração do Teorema Central do Limite. Vamos fazer a demonstração para o caso particular, quando existe a função geratriz de momentos (o caso geral possui uma demonstração similar, substituindo a função geratriz pela função característica, mas sua definição está além do escopo desse curso).\nAntes de prosseguir, lembremos que uma função \\(g(x)\\) contínua com pelo menos duas derivadas definidas em \\(x_0\\) pode escrita como\n\\[g(x)= g(x_0)+(x-x_0)g'(x_0)+\\frac{(x-x_0)^2}{2}g''(x_0)+o((x-x_0)^2).\\] \\(o(z)\\) representa um termo que converge para zero mais rápido do que \\(z\\). Para uma variável aleatória \\(Y\\) qualquer que possui função geratriz de momentos, é verdade que:\n\n\\(M_Y(0)=1\\)\n\n2 \\(M_Y'(0)=E(Y)\\)\n\n\\(M_Y''(0)=E(Y^2)\\).\n\nPortanto, a aproximação de \\(M_Y(t)\\) em torno de zero é \\[M_Y(t)= 1+tE(Y)+\\frac{t^2}{2}E(Y^2)+ o(t^2).\\]\nAgora, considere a sequência \\(X_1,X_2\\ldots,\\) enunciada no Teorema Central do Limite. Sem perda de generalidade, assuma que \\(E(X_i)=0\\). A função geratriz de momentos de \\(Z_n\\) é\n\\[\\begin{align}M_{Z_n}(t)&=E\\left(e^{\\frac{\\sqrt{n}\\bar{X}_n}{\\sigma}t}\\right)=E\\left(e^{\\frac{\\sqrt{n}}{n\\sigma}t\\sum_{i=1}^n X_i}\\right)=E\\left(\\prod_{i=1}^ne^{\\frac{\\sqrt{n}}{n\\sigma}t X_i}\\right)\\\\&=\\prod_{i=1}^nE\\left(e^{\\frac{t}{\\sigma\\sqrt{n}} X_i}\\right)=\\prod_{i=1}^nM_{X_i}\\left(\\frac{t}{\\sigma\\sqrt{n}}\\right)\\\\&=\\left[M_{X}\\left(\\frac{t}{\\sigma\\sqrt{n}}\\right)\\right]^n\\end{align}\\] Para \\(M_X(s)\\) em torno de 0, teremos a expansão\n\\[\\begin{align}M_X(s)= 1+\\frac{s^2}{2}\\sigma^2+ o(s^2),\\end{align}\\] e substituindo \\(s\\) por \\(t/(\\sigma/\\sqrt{n})\\), teremos\n\\[\\begin{align}M_X\\left(\\frac{t}{\\sigma\\sqrt{n}}\\right)= 1+\\frac{t^2}{2n}+ o\\left(\\frac{t^2}{n\\sigma^2}\\right),\\end{align}\\] onde o termo \\(o(t^2/n\\sigma^2)\\) pode ser negligenciado. Teremos então\n\\[M_{Z_n}(t)=\\left[1+ \\frac{t^2}{2n}\\right]^n\\]\nNote que \\[\\lim_{n\\to\\infty}\\log M_{Z_n}(t)=\\lim_{n\\to\\infty}n\\log\\left(1+\\frac{t^2}{2n}\\right)\\] como o logaritmo acima tende a 0, podemos reescrever limite como\n\\[\\lim_{n\\to\\infty}\\log M_{Z_n}(t)=\\lim_{n\\to\\infty}\\frac{\\log\\left(1+\\frac{t^2}{2n}\\right)}{1/n}\\] e aplicar a regra de l’Hôpital:\n\\[\\begin{align}\\lim_{n\\to\\infty}\\log M_{Z_n}(t)&=\\lim_{n\\to\\infty}\\frac{\\log\\left(1+\\frac{t^2}{2n}\\right)}{1/n}\\\\&=\\lim_{n\\to\\infty}\\frac{\\frac{d}{dn}\\log\\left(1+\\frac{t^2}{2n}\\right)}{\\frac{d}{dn}1/n}\\\\&=\\lim_{n\\to\\infty}\\frac{\\left(1+\\frac{t^2}{2n}\\right)^{-1}(-\\frac{t^2}{2n^2})}{-1/n^2}\\\\&=\\frac{t^2}{2}\\lim_{n\\to\\infty}\\left(1+\\frac{t^2}{2n}\\right)^{-1}=\\frac{t^2}{2}.\\end{align}\\] Portanto,\n\\[\\lim_{n\\to\\infty }M_{Z_n}=e^{t^2/2},\\] o que implica que o limite em distribuição de \\(Z_n\\) é a distribuição normal padrão.\n\n\nImportante. O Teorema Central do Limite é muito útil para apresentar uma distribuição aproximada pois\n\\[Z_n=\\sqrt{n}\\frac{\\bar{X}_n-\\mu}{\\sigma}\\stackrel{D}{\\rightarrow}\\hbox{Normal}(0,1),\\]\nintuitivamente implica que, para \\(n\\) grande o suficiente,\n\\[\\bar{X}\\approx \\hbox{Normal}\\left(\\mu,\\frac{\\sigma^2}{n}\\right).\\]\n\n\nExample 6.7 Sejam \\(X_1,X_2,\\ldots,\\) variáveis aleatórias independentes com distribuição Bernoulli(\\(p\\)). Como \\(E(X_1)=p\\) e \\(Var(X_1)=p(1-p)\\), teremos que\n\\[Z_n=\\sqrt{n}\\frac{\\bar{X}_n-p}{\\sqrt{p(1-p)}}\\stackrel{D}{\\to}N(0,1)\\] quando \\(n\\to\\infty\\). Isto implica que \\[\\bar{X}_n\\approx \\hbox{Normal}\\left(p,\\frac{p(1-p)}{n}\\right).\\]\n\n\nExercise 6.9 Considere a distribuição do erro de Simpson, dada abaixo:\n\\[\\begin{array}{c|ccccccccccc}\\hline\n\\xi & -5 & -4 & -3 & -2 & -1 & 0 & 1 & 2 & 3 & 4 & 5 \\\\ \\hline\nP(\\xi)& \\frac{1}{36} & \\frac{2}{36} & \\frac{3}{36} &\\frac{4}{36} & \\frac{5}{36} & \\frac{6}{36}&\\frac{5}{36}&\\frac{4}{36}&\\frac{3}{36}&\\frac{2}{36}&\\frac{1}{36}\\\\ \\hline\n\\end{array}\\]\nNesse trabalho ele mostrou que utilizar \\(\\bar{x}_3\\) era vantajoso porque a distribuição do erro \\(\\bar{\\xi}_3\\) era mais concentrada em torno de zero e se espalhava menos.\nQual seria a distribuição aproximada de \\(\\bar{\\xi}_n\\), para \\(n\\) suficientemente grande?\n\n\nExample 6.8 Considere novamente a sequÊncia \\(X_1,X_2\\ldots,\\) de variáveis aleatórias independentes com distribuição Bernoulli(\\(p\\)), onde foi mostrado que, para \\(n\\) suficientemente grande,\n\\[\\bar{X}_n\\approx \\hbox{Normal}\\left(p,\\frac{p(1-p)}{n}\\right).\\]\nEmbora não exista nada de errado com esse resultado, sob o ponto de vista da inferência estatística seria mais conveniente que a variância não tivesse \\(p\\). Nos textos básicos inferência, isso é feito simplesmente trocando \\(p\\) por \\(\\hat{p}=\\bar{X}_n\\) na variância, obtendo\n\\[\\bar{X}_n\\approx \\hbox{Normal}\\left(p,\\frac{\\hat{p}(1-\\hat{p})}{n}\\right).\\]\nEssa conta não fazer sentido, pois a própria variável se torna um parâmetro. Vamos explicar porque esse passo faz sentido para grandes amostras utilizando o Teorema Central do Limite e o Teorema de Slutsky. Primeiro, sabemos que\n\\[Z_n=\\sqrt{n}\\frac{\\bar{X}_n-p}{\\sqrt{p(1-p)}}\\stackrel{D}{\\to}N(0,1)\\]\nTambém, já mostramos que \\(\\bar{X}_n\\stackrel{P}{\\to}p\\), o que implica que\n\\[\\bar{X}_n(1-\\bar{X}_n)\\stackrel{P}{\\to}p(1-p).\\] Considere a variável\n\\[\\begin{align}W_n&=\\sqrt{n}\\frac{\\bar{X}_n-p}{\\sqrt{\\bar{X}_n(1-\\bar{X}_n)}}=\\frac{\\bar{X}_n-p}{\\sqrt{p(1-p)}}\\sqrt{\\frac{p(1-p)}{\\bar{X}_n(1-\\bar{X}_n)}}\\\\&=Z_n\\sqrt{\\frac{p(1-p)}{\\bar{X}_n(1-\\bar{X}_n)}}.\\end{align}\\] Como \\(Z_n\\stackrel{D}{\\to}N(0,1)\\) e\n\\[\\sqrt{\\frac{p(1-p)}{\\bar{X}_n(1-\\bar{X}_n)}}\\stackrel{P}{\\to}1,\\] pelo Teorema de Slutsky,\n\\[W_n\\stackrel{D}{\\to}Z_n\\cdot 1=Z_n\\sim N(0,1).\\]\nDeste modo, para \\(n\\) suficientemente grande, \\(W_n\\) e \\(Z_n\\) tem a mesma distribuição, o que justifica a troca de \\(p\\) por \\(\\bar{X}_n\\) na variância.\n\n\nExercise 6.10 Sejam \\(X_1,X_2,\\ldots\\) variáveis aleatórias independentes mesma distribuição e \\(E(X_i)=\\mu\\), \\(Var(X_i)=\\sigma^2\\).\n\nUtilize o Teorema Central do Limite para encontrar o limite em distribuição de\n\n\\[Z_n=\\sqrt{n}\\frac{\\bar{X}_n-\\mu}{\\sigma}.\\]\n\nSeja \\[S^2_n=\\frac{1}{n}\\sum_{i=1}^n(X_i-\\bar{X}_n)^2=\\frac{1}{n}\\sum_{i=1}^nX_i^2-\\bar{X}_n^2.\\] Utilizando a Lei Fraca dos Grandes Números, encontre o limite em probabilidade de \\(S_n^2\\).\nUtilizando o Teorema de Slutsky, encontre a distribuição limite de\n\n\\[W_n=\\sqrt{n}\\frac{\\bar{X}_n-\\mu}{S_n},\\] onde \\(S_n=\\sqrt{S^2_n}\\). (Note. Esse resultado é utilizado para fazer inferências sobre \\(\\mu\\) sem ter que lidar com \\(\\sigma^2\\)).\n\n\nExercise 6.11 Sejam \\(X_1,X_2,\\ldots\\) variáveis aleatórias independentes com distribuição Poisson(\\(\\lambda\\))\n\nUtilizando o Teorema Central do Limite, encontre a distribuição limite de\n\n\\[Z_n=\\sqrt{\\frac{n}{\\lambda}}\\left(\\bar{X}_n-\\lambda\\right).\\]\n\nUtilizando o Teorema de Slutsky, encontre a distribuição limite de\n\n\\[Z_n=\\sqrt{\\frac{n}{\\bar{X}_n}}\\left(\\bar{X}_n-\\lambda\\right).\\] (Nota. Esse resultado é utilizado para fazer inferências sobre \\(\\lambda\\) sem que o mesmo apareça na variância).\n\n\nExercise 6.14 Sejam \\(X_1, X_2, \\ldots\\) variáveis aleatórias independentes com distribuição Exponencial\\((\\lambda)\\), com função densidade dada por\n\\[f(x)=\\lambda e^{-\\lambda x}I_{(0,\\infty)}(x).\\]\n\nUtilize o Teorema Central do Limite para encontrar a distribuição limite de \\[Z_n = \\sqrt{n} \\lambda \\left( \\bar{X}_n - \\frac{1}{\\lambda} \\right)\\]\nUtilizando a Lei Fraca dos Grandes Números, determine o limite em probabilidade de\n\n\\[Y_n = \\frac{1}{\\bar{X}_n}\\]\n\nCombine os resultados anteriores para encontrar a distribuição limite de:\n\n\\[W_n = \\frac{\\sqrt{n} \\left( \\bar{X}_n - \\frac{1}{\\lambda} \\right)}{\\bar{X}_n}\\]\n(Nota: Observe que, assim como nos exercícios anteriores, o parâmetro \\(\\lambda\\) “sumiu” do denominador, permitindo que utilizemos apenas a média amostral \\(\\bar{X}_n\\) para estimar a variabilidade da estimativa).\n\n6.6 Exercícios de fixação\n\nExercise 6.12 Seja \\(X_1, X_2, \\ldots\\) uma sequência de variáveis aleatórias i.i.d. com distribuição Exponencial(\\(\\lambda\\)). Sabemos que \\(E(X_i) = 1/\\lambda\\) e \\(Var(X_i) = 1/\\lambda^2\\). Defina a estatística:\\[K_n = \\frac{1}{n} \\sum_{i=1}^n \\sqrt{X_i}\\] Considerando que \\(E(\\sqrt{X_i}) = \\Gamma(3/2)/\\sqrt{\\lambda} = \\frac{\\sqrt{\\pi}}{2\\sqrt{\\lambda}}\\), determine para qual valor constante \\(c\\) a sequência \\(K_n\\) converge em probabilidade quando \\(n \\to \\infty\\). Justifique citando a Lei Fraca utilizada.\n\n\nExercise 6.13 Considere uma sequência \\(X_1, X_2, \\ldots\\) de variáveis aleatórias independentes com distribuição Qui-quadrado com \\(k=1\\) grau de liberdade (\\(X_i \\sim \\chi^2_1\\)). Sabe-se que \\(E(X_i) = 1\\) e \\(Var(X_i) = 2\\).\n\nPelo TCL, qual a distribuição limite de \\(Z_n = \\sqrt{n} \\frac{(\\bar{X}_n - 1)}{\\sqrt{2}}\\)?\nMostre que \\(\\bar{X}_n^2 \\xrightarrow{P} 1\\).\nUtilizando o Teorema de Slutsky, encontre a distribuição limite de:\\[W_n = \\sqrt{n} \\frac{(\\bar{X}_n - 1)}{\\sqrt{2}\\bar{X}_n}\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergência de variáveis aleatórias</span>"
    ]
  },
  {
    "objectID": "convergencia.html#exercícios-de-fixação",
    "href": "convergencia.html#exercícios-de-fixação",
    "title": "6  Convergência de variáveis aleatórias",
    "section": "6.6 Exercícios de fixação",
    "text": "6.6 Exercícios de fixação\n\nExercise 6.12 Seja \\(X_1, X_2, \\ldots\\) uma sequência de variáveis aleatórias i.i.d. com distribuição Exponencial(\\(\\lambda\\)). Sabemos que \\(E(X_i) = 1/\\lambda\\) e \\(Var(X_i) = 1/\\lambda^2\\). Defina a estatística:\\[K_n = \\frac{1}{n} \\sum_{i=1}^n \\sqrt{X_i}\\] Considerando que \\(E(\\sqrt{X_i}) = \\Gamma(3/2)/\\sqrt{\\lambda} = \\frac{\\sqrt{\\pi}}{2\\sqrt{\\lambda}}\\), determine para qual valor constante \\(c\\) a sequência \\(K_n\\) converge em probabilidade quando \\(n \\to \\infty\\). Justifique citando a Lei Fraca utilizada.\n\n\nExercise 6.13 Considere uma sequência \\(X_1, X_2, \\ldots\\) de variáveis aleatórias independentes com distribuição Qui-quadrado com \\(k=1\\) grau de liberdade (\\(X_i \\sim \\chi^2_1\\)). Sabe-se que \\(E(X_i) = 1\\) e \\(Var(X_i) = 2\\).\n\nPelo TCL, qual a distribuição limite de \\(Z_n = \\sqrt{n} \\frac{(\\bar{X}_n - 1)}{\\sqrt{2}}\\)?\nMostre que \\(\\bar{X}_n^2 \\xrightarrow{P} 1\\).\nUtilizando o Teorema de Slutsky, encontre a distribuição limite de:\\[W_n = \\sqrt{n} \\frac{(\\bar{X}_n - 1)}{\\sqrt{2}\\bar{X}_n}\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergência de variáveis aleatórias</span>"
    ]
  },
  {
    "objectID": "cadeias_de_markov.html",
    "href": "cadeias_de_markov.html",
    "title": "7  Introdução às cadeias de Markov",
    "section": "",
    "text": "7.1 Processos estocásticos, propriedade de Markov e objetivos do capítulo\nConsidere um conjunto \\(\\mathcal{T}\\subseteq \\mathbb{R}\\), doravante denominado conjunto de índices. Para cada \\(t\\in\\mathcal{T}\\), seja \\(X(t)\\) uma variável aleatória. Então, o conjunto \\(\\{X(t),t\\in\\mathcal{T}\\}\\) é denominado processo estocástico.\nSeja \\(\\{X(t),t\\in\\mathcal{T}\\}\\) um processo estocástico. Considere que observamos o processo até o índice \\(s\\). Considere a probabilidade do processo no índice \\(t+s\\) estar no conjunto \\(A\\):\n\\[P( X(t+s)\\in A|X(u)=x(u),0\\leq u\\leq s).\\] O problema acima é complexo, uma vez que devemos entender a distribuição de \\(X(t+s)\\) para cada reazaliação do processo até o índice \\(s\\). Suponha então que apenas o último índice observado é relevante para o processo, ou seja\n\\[P( X(t+s)\\in A|X(u)=x(u),0\\leq u\\leq s)=P( X(t+s)\\in A|X(s)=x(s)).\\] Nesse caso, o processo mantém na memória apenas o índice mais recente. Isso é denominado propriedade de Markov.\nProcessos estocásticos com a propriedade de Markov são denominados cadeias de Markov. Existem inúmeras particularidades sobre esses processos que poderiam cobrir um curso regular de 60h. Portanto, nesse curso, nossos objetivos são",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introdução às cadeias de Markov</span>"
    ]
  },
  {
    "objectID": "cadeias_de_markov.html#processos-estocásticos-propriedade-de-markov-e-objetivos-do-capítulo",
    "href": "cadeias_de_markov.html#processos-estocásticos-propriedade-de-markov-e-objetivos-do-capítulo",
    "title": "7  Introdução às cadeias de Markov",
    "section": "",
    "text": "Example 7.1 Amostra aleatória. Seja \\(X_1,\\ldots,X_n\\) uma amostra aleatória, ou seja, uma coleção de variáveis aleatórias independentes e identicamente distribuídas. Fazendo \\(\\mathcal{T}=\\{1,\\ldots,n\\}\\) e \\(_t=X(t)\\), temos que a amostra aleatória é um processo estocástico.\n\n\nExample 7.2 Um dos objetivos principais dos processos estocásticos é relacionar um comportamento aleatório com um índice de interesse. Por exemplo, suponha que \\(X(t)\\), com \\(t&gt;0\\), é o número de vendas realizadas até o tempo \\(t\\). Obviamente, são esperadas mais vendas com o aumento de \\(t\\) e um modo simples de expressar isso é supor que\n\\[E(X(t))=\\mu t,\\] onde \\(\\mu\\) representa a média de vendas por unidade de tempo. Diferente das amostras aleatórias, para \\(t\\neq s\\), \\(X(t)\\) não tem a mesma distribuição que \\(X(s)\\). Além disso, se \\(s&lt;t\\) \\[E(X(s))=\\mu s\\leq\\mu t =E(X(t))\\] e, como o conhecimento de \\(X(s)\\) altera nosso conhecimento sobre \\(X(t)\\), temos que as variáveis \\(X(s)\\) e \\(X(t)\\) são dependentes.\n\n\n\n\n\n\napresentar as cadeias de Markov considerando apenas variáveis aleatórias discretas com conjunto de índice discreto\ndefinir probabilidade e matriz de transição\napresentar as classificações de estados\napresentar as ditribuições estacionárias",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introdução às cadeias de Markov</span>"
    ]
  },
  {
    "objectID": "cadeias_de_markov.html#definição-e-exemplos-de-cadeias-de-markov-à-tempo-discreto",
    "href": "cadeias_de_markov.html#definição-e-exemplos-de-cadeias-de-markov-à-tempo-discreto",
    "title": "7  Introdução às cadeias de Markov",
    "section": "7.2 Definição e exemplos de cadeias de Markov à tempo discreto",
    "text": "7.2 Definição e exemplos de cadeias de Markov à tempo discreto\nDoravante, vamos considerar que \\(\\mathcal{T}=\\{0,1,\\ldots\\}\\). Deste modo, a notação \\(X(t)\\) será substituída por \\(X_t\\). Além disso, \\(t\\) será interpretado como tempo de ocorrência. Por exemplo, \\(\\{X_{10}=3\\}\\) é evento da ocorrência de 3 no tempo \\(10\\).\nPara um tempo \\(t&gt;0\\) qualquer, o incremento de tempo \\(s\\) será denominado passo, como o passo do ponteiro de um relógio. Por exemplo \\(t+1\\) é um passo após o tempo \\(t\\).\nVamos também considerar que todas as variáveis aleatórias do processo são discretas. O conjunto de todos os valores possíveis para as variáveis do processo é denominado conjunto dos estados e cada valor em particular é denominado estado.\nVamos definir formalmente o nosso processo de interesse\n\nDefinition 7.1 Dizemos que o processo estocástico \\(\\{X_t, t=0,1,\\ldots\\}\\) é uma cadeia de Markov se, para quaisquer estados \\(i\\) e \\(j\\), \\[P(X_{n+1}=j|X_n=i,X_{n-1}=x_{n-1}\\ldots,X_0=x_0)=P(X_{n+1}=j|X_n=i)\\]\n\nNote que, para uma cadeia de Markov, é possível que, para \\(m\\neq n\\)|\n\\[P(X_{n+1}=j|X_n=i)\\neq P(X_{m+1}=j|X_m=i).\\] Estamos interessados apenas em cadeinas nas quais isso não ocorre.\n\nDefinition 7.2 Dizemos uma cadeia de Markov \\(\\{X_t, t=0,1,\\ldots\\}\\) é *homogênea se, para quaisquer estados \\(i\\) e \\(j\\) e para quaisquer tempos \\(n,m\\), \\[P(X_{n+1}=j|X_n=i)=P(X_{m+1}=j|X_m=i).\\]\n\nDoravante, todas as cadeias apresentadas serão consideradas homogêneas. Então, para \\(n\\) arbitrário, a probabilidade \\[p_{ij}=P(X_{n+1}=j|X_n=i)\\] será denominada probabilidade de transição (em um passo).\n\nExample 7.3 O passeio do sapo. Um sapo vive em uma lagoa, movimentando-se por nove vitória régias, conforme a ilustração abaixo.\n\n\n\n\n\n\n\n\n\nEstando na vitória régia \\(i\\), seu próximo movimento será dado ao acaso para uma vitória régia vizinha ((Norte, Sul, Leste ou Oeste).\nSeja \\(X_n\\) a vitória régia (estado) no qual o sapo se encontra no tempo \\(n\\). Calcule:\n\nAs probabilidades de transição partindo do estado 1.\nA probabilidades de transição partindo do estado 5.\n\nSolução.\n\nEstando no estado 1, o sapo pode apenas se deslocar para os estados 2 ou 4. Portanto\n\n\\[p_{1j}=\\begin{cases}\\frac{1}{2},&j=2,4\\\\0,&\\hbox{caso contrário}\\end{cases}\\]\n\nEstando no estado 5, o sapo pode se deslocar para os estados 2, 4, 6 ou 8. Portanto\n\n\\[p_{5j}=\\begin{cases}\\frac{1}{4},&j=2,4,6,8\\\\0,&\\hbox{caso contrário}\\end{cases}\\]\n\n\nExercise 7.1 Um rato é colocado no Estado 1 de um labirinto composto por 6 salas. Ele se move entre as salas adjacentes escolhendo uma ao acaso, conforme a ilustração abaixo. Se o rato chegar à sala 6, ele encontra o queijo e para de se mover. Se o rato entrar na sala 5, ele fica preso na ratoeira. Seja \\(X_n\\) a sala (estado) no qual o rato se encontra no tempo \\(n\\). Determine todas as probabilidades de transição.\n\n\n\n\n\n\n\n\n\n\n\nDefinition 7.3 Grafo de uma cadeia\nUm grafo orientado é formado por um conjunto de vértices e um conjunto de arcos. O grafo de uma cadeia de Markov é construído da seguinte forma:\n\nO conjunto de vértices é composto pelos estados do processo\nExiste um arco saindo do estado \\(i\\) e chegando ao estado \\(j\\) se \\(p_{ij}&gt;0\\).\nO arco \\((i,j)\\) recebe o rótulo \\(p_{ij}\\)\n\n\n\nExample 7.4 Considere uma cadeia de Markov onde \\(X_n=1\\) se chove no dia \\(n\\) e \\(X_{n}=0\\) em caso contrário. Suponha que:\n\nDado que hoje choveu, a probabilidade de chover amanhã é \\(\\alpha\\)\nDado que não choveu hoje, a probabilidade de não chover amanhã é \\(\\beta\\)\n\nConstrua o grafo desta cadeia e sua matriz de transição.\nSolução\nTemos que\n\\[p_{1j}=\\begin{cases}\\alpha,&j=1 \\\\1-\\alpha,&j=0\\end{cases}\\] e que\n\\[p_{0j}=\\begin{cases}1-\\beta,&j=1 \\\\\\beta,&j=0\\end{cases}\\] logo, podemos gerar o grafo abaixo.\n\n\n\n\n\n\n\n\nFigure 7.1: Grafo da cadeia de Markov para o modelo de chuva/sol.\n\n\n\n\n\n\nExercise 7.2 Todos os dias, João se desloca entre dois pontos: sua casa e seu trabalho. João tem apenas um guarda-chuva. Se no momento de seu deslocamento estiver chovendo, João utilizará seu guarda-chuva se o mesmo estiver no local. Caso contrário, João fará seu deslocamento na chuva. Além disso, João só leva consigo o guarda-chuva se estiver chovendo. Considere os seguintes estados:\n\n0 - João está em casa com o guarda-chuva\n1- João está no trabalho com o guarda-chuva\n2 - João está em casa sem o guarda-chuva\n3 - João está no trabalho sem o guarda-chuva\n\nSabendo que a probabilidade de estar chovendo quando João tem que sair de um local é de 0,25, construa o grafo dessa cadeia de Markov.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introdução às cadeias de Markov</span>"
    ]
  },
  {
    "objectID": "cadeias_de_markov.html#classificação-de-estados",
    "href": "cadeias_de_markov.html#classificação-de-estados",
    "title": "7  Introdução às cadeias de Markov",
    "section": "7.3 Classificação de estados",
    "text": "7.3 Classificação de estados\nUm passeio é uma sequência de estados \\(i_0,i_1, i_2, \\dots, i_n\\) tal que, para cada par sucessivo, a probabilidade de transição é positiva (existe uma aresta conectando-os). Partindo de \\(i_0\\), a probabilidade do processo passar pelo caminho \\(i_1,\\ldots,i_n\\) é\n\\[P(X_n=i_n,\\ldots,X_1=i_1|X_0=i_0)=p_{i_{n-1}i_n}\\cdots p_{0i_1}\\] Definimos por \\(p_{ij}^{(n)}\\) como a probabilidade do processo sair do estado \\(i\\) e chegar no estado \\(j\\) em \\(n\\) passos. Essa probabilidade é equivalente a soma das probabilidades de todos os passeios que saem de \\(i\\) e chegam em \\(j\\) em \\(n\\) passos.\n. ::: {#exr-} Considere uma cadeia com três estados e as seguintes probabilidades de transição:\n\\[\\begin{align}p_{01}&=1\\\\ p_{10}&=0,1\\\\ p_{11}&=0,2\\\\ p_{12}&=0,7\\\\\np_{22}&=0,6 \\\\ p_{20}&=0,4\\end{align}\\]\n\nConstrua o grafo da cadeia\nCalcule a probabilidade do passeio 0-1-2-0\nCalcule \\(p_{00}^{(4)}\\). :::\n\n\nExercise 7.3 Considere uma cadeia com quatro estados e as seguintes probabilidades de transição:\n\\[\\begin{align}p_{01}&=1\\\\ p_{11}&=0,3\\\\ p_{12}&=0,7\\\\\np_{22}&=0,6 \\\\ p_{20}&=0,2\\\\ p_{23}&=0,2\\\\p_{33}&=1\\end{align}\\]\n\nConstrua o grafo da cadeia\nCalcule a probabilidade do passeio 0-1-2-0\nComeçando no estado 0, é possível que o processo não consiga retornar para 0?\nExiste algum estado tal que, partindo dele, o processo vai retornar para ele certamente?\n\n\n\nExercise 7.4 Considere uma cadeia com quatro estados e as seguintes probabilidades de transição:\n\\[\\begin{align}p_{00}&=0,8\\\\p_{01}&=0,2\\\\ p_{10}&=0,3\\\\ p_{11}&=0,4\\\\\np_{12}&=0,3 \\\\ p_{22}&=0,2\\\\ p_{23}&=0,8\\\\p_{32}&=05\\\\p_{33}&=0,5\\end{align}\\]\n\nConstrua o grafo da cadeia\nComeçando no estado 0, é possível que esse estado nunca mais seja visitado pelo processo? Em qual sitação isso ocorre?\nComeçando no estado 3, é possível que esse estado nunca mais seja visitado pelo processo? Porquê?\n\n\nOs exercícios acima mostraram que alguns estados podem deixar de ser visitados pelo processo. Seja \\(f_i^{(n)}\\) a probabilidade de, saindo de \\(i\\), o processo voltar pela primeira vez para \\(i\\) em \\(n\\) passos, ou seja\n\\[f_i^{(n)}=P(X_n=i,X_{n-1}\\neq i,\\ldots,X_1\\neq i|X_0=i).\\] Então, a probabilidade de que o processo saia de \\(i\\) e volte para \\(i\\) em algum momento é\n\\[\\begin{align} f_i &=P(\\cup_{n=1}^\\infty \\hbox{ {voltar em exatos $n$ passos}}) \\\\ &=\\sum_{n=1}^\\infty P(\\hbox{ {voltar em exatos $n$ passos}})\\\\&=\\sum_{n=1}^\\infty f_i^{(n)} \\end{align}\\]\n\nDefinition 7.4 Dizemos que o estado \\(i\\) é recorrente se \\(f_i=1\\) e dizemos que ele é transiente se \\(f_i&lt;1\\).\n\n\nExercise 7.5 Considerando o grafo da cadeia abaixo, classifique os estados como transientes e recorrentes.\n\n\n\n\n\n\n\n\nFigure 7.2: Grafo da cadeia de Markov\n\n\n\n\n\n\nDefinition 7.5 Acessibilidade\nDizemos que o estado \\(j\\) é acessível a partir de \\(i\\), se existe pelo menos um passeio saindo de \\(i\\) e chegando em \\(j\\) Notação: \\(i\\to j\\).\nComunicação\nDizemos que os estados \\(i\\) e \\(j\\) se comunicam se \\(i\\to j\\) e \\(j\\to i\\). Notação: \\(i\\leftrightarrow j\\).\nClasse\nDizemos que \\(i\\) e \\(j\\) pertencem a mesma classe se \\(i\\leftrightarrow j\\).\n\n\nProposition 7.1 Se \\(i\\) e \\(j\\) estão na mesma classe e \\(i\\) é recorrente(transiente), então \\(j\\) também será recorrente(transiente).\n\nVamos demonstrar a proposição de forma intuitiva.\n\nSe \\(i\\) é recorrente, então certamente o processo sai do estado \\(i\\) e volta para ele. Portanto, partindo de \\(j\\) o processo vai acessar o estado \\(i\\) em algum momento, certamente voltar para \\(i\\) e então voltar para \\(j\\) em algum momento. Portanto, partindo de \\(j\\), o processo certamente retorna para \\(j\\), o que implica que \\(j\\) é recorrente.\nSe \\(i\\) é transiente, então é possível que o processo saia do estado \\(i\\) e nunca mais volte para ele. Mas como \\(i\\) se comunica com \\(j\\), é possível que o processo saia de \\(j\\), chegue em \\(i\\) e, a partir dali, nunca mais retorne para \\(j\\). Portanto, \\(j\\) é transiente.\n\n\nExercise 7.6 Considere uma cadeia de Markov com as seguintes probabilidades de transição\n\\[\\begin{array}{c|ccccccccccc}\\hline\ni\\setminus j\n  & 0   & 1   & 2   & 3   & 4   & 5   & 6   & 7   & 8 & 9 & 10\\\\ \\hline\n0 & 0,2 & 0,8 & 0   & 0   & 0   & 0   & 0   & 0   & 0 & 0 & 0 \\\\\n1 & 0,3 & 0   & 0,5 & 0,2 & 0   & 0   & 0   & 0   & 0 & 0 & 0 \\\\\n2 & 0   & 0   & 1   & 0   & 0   & 0   & 0   & 0   & 0 & 0 & 0 \\\\\n3 & 0   & 0   & 0   & 0   & 0,5 & 0,5 & 0   & 0   & 0 & 0 & 0 \\\\\n4 & 0   & 0   & 0   & 1   & 0   & 0   & 0   & 0   & 0 & 0 & 0 \\\\\n5 & 0   & 0   & 0   & 0   & 0,2 & 0   & 0,8 & 0   & 0 & 0 & 0 \\\\\n6 & 0   & 0   & 0   & 0   & 0   & 0   & 0,1 & 0,9 & 0 & 0 & 0 \\\\\n7 & 0   & 0   & 0   & 0   & 0   & 0   & 0,7 & 0,3 & 0 & 0 & 0 \\\\\n8 & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 1 & 0 & 0 \\\\\n9 & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0 & 0,2 & 0,8 \\\\\n10& 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0 & 0,7 & 0,3 \\\\ \\hline\n\\end{array}\\]\n\nConstrua o grafo da cadeia\nEncontre as classes\nClassifique cada classe como recorrente ou transiente.\n\n\nConsidere a cadeia de Markov abaixo:\n\n\n\n\nGrafo da cadeia de Markov\n\n\nObserve que para um estado \\(i\\) qualquer desta cadeia, \\(p_{ii}^{(n)}&gt;0\\) somente para \\(n\\) múltiplo de 4. Estados com essa característica são denominados periódicos.\n\nDefinition 7.6 O estado \\(i\\) de uma cadeia de Markov é dito ser periódico se todos os retornos ao estado ocorrem em um número de passos múltiplo de \\(k\\) (neste caso, é dito que o período de \\(i\\) é igual a \\(k\\)). Notação: \\(d_i=k\\).\nFormalmente, seja \\(D_i=\\{n\\geq 1: p_{ii}^{(n)}&gt;0\\}\\), ou seja, o conjunto com os números de passos necessários para o retorno ao estado e seja \\(k\\) o máximo divisor comum (mdc) de \\(D_i\\). Então \\(k\\) é denominado período do estado \\(i\\).\nSe \\(D_i=\\varnothing\\), então \\(d_i=0\\) e se \\(d_i=1\\), o estado \\(i\\) é denominado aperiódico.\n\nVoltando ao grafo dado, pode-se notar, por exemplo, que \\(D_0=\\{4,8,\\ldots\\}\\), logo, o período do estado é 4.\nÉ importante separar a noção de período com o número mínimo de passos necessários para retornar ao estado. Se um estado possui período \\(d\\), então o processo só retornará ao estado em passos que são múltiplos de, mas não em todos os passos múltiplos de \\(d\\). O exemplo abaixo ilustra esse fato.\n\nExample 7.5 Considere o grafo da cadeia abaixo:\n\n\n\n\nGrafo da cadeia de Markov\n\n\nObserve que, partindo do estado 0, a cadeia só pode retornar a 0 pelos seguintes passeios:\n\\[0\\to 1\\to 2\\to 3 \\to 4 \\to 5 \\to 6\\to 7 \\to 0\\] e \\[0\\to 1\\to 2\\to 3 \\to 4 \\to 5 \\to 0.\\] O primeiro caminho é feito em 8 passos, logo \\(p_{00}^{(n)}&gt;0\\) para múltiplos de 8. O segundo caminho é feito em 6 passos, logo \\(p_{00}^{(n)}&gt;0\\) para múltiplos de 6. Como o máximo divisor comum entre 6 e 8 é 2, o período do estado 0 é 2.\nContudo \\(p_{00}^{(2)}=0\\). O período igual a 2 implica que se \\(p_{00}^{(n)}&gt;0\\), então \\(n\\) é par.\n\n\nExercise 7.7 Considerando as probabilidades de transição abaixo, faça o grafo das cadeias e encontre o período do estado 0.\n\n\\[\\begin{array}{c|ccc} \\hline i\\setminus j\n  & 0 & 1 & 2 \\\\ \\hline\n0 & 0 & 1 & 0 \\\\\n1 & 0 & 0 & 1 \\\\\n2 & 1 & 0 & 0 \\\\ \\hline\\end{array}\\]\n\nb .\n\\[\\begin{array}{c|ccc} \\hline i\\setminus j\n  & 0 & 1 & 2 \\\\ \\hline\n0 & 0 & 1 & 0 \\\\\n1 & 0 & 0,8 & 0,2 \\\\\n2 & 1 & 0 & 0 \\\\ \\hline\\end{array}\\]\n\n\n\n\\[\\begin{array}{c|cccc} \\hline i\\setminus j\n  & 0 & 1 & 2 & 3\\\\ \\hline\n0 & 0 & 1 & 0 & 0 \\\\\n1 & 0 & 0 & 0,2 & 0,8 \\\\\n2 & 1 & 0 & 0 & 0\\\\\n3 & 0 & 1 & 0 & 0 \\\\ \\hline\\end{array}\\]\n\n\n\n\\[\\begin{array}{c|cccc} \\hline i\\setminus j\n  & 0 & 1 & 2 & 3\\\\ \\hline\n0 & 0 & 1 & 0 & 0 \\\\\n1 & 0 & 0 & 0,2 & 0,8 \\\\\n2 & 1 & 0 & 0 & 0\\\\\n3 & 0 & 0 & 0 & 1 \\\\ \\hline\\end{array}\\]\n\n\n\n\\[\\begin{array}{c|ccccc} \\hline i\\setminus j\n  & 0  & 1 & 2 & 3  &4\\\\ \\hline\n0 & 0  & 1 & 0 & 0  &0 \\\\\n1 & 0  & 0 & 1 & 0  &0 \\\\\n2 & 0,5& 0 & 0 & 0,5&0\\\\\n3 & 0  & 0 & 0 & 0 & 1 \\\\\n4 & 1 & 0 & 0 & 0 & 0 \\\\\\hline\\end{array}\\]\n\n\nProposition 7.2 Todos os estados de uma mesma classe possuem o mesmo período.\n\nDemonstração intuitiva. Considere \\(i\\) um estado dentro de uma classe \\(C\\) e que \\(d_i=k\\). Para cada \\(j\\in C\\) só é possível sair de \\(i\\) e chegar em \\(j\\) em \\(n_{ij}\\) passos e volta para \\(i\\) em \\(n_{ji}\\) passos se \\(n_{ij}+n_{ji}=n_j\\) é um múltiplo de \\(k\\). Agora, seja \\(m\\) um valor tal que \\(p_{jj}^{(m)}&gt;0\\). Considere então um passeio maior, saindo de \\(i\\) echegando em \\(j\\) em \\(n_{ij}\\) passos, retornando para \\(j\\) depois de \\(m\\) passos e e finalmente chegando de \\(i\\) em \\(n_{ji}\\) passos. Então, esse passeio, com \\(n_j+m\\) passos, também deve ser múltiplo de \\(k\\), o que implica que \\(m\\) também é múltiplo de \\(k\\) e, portanto \\(d_j=k\\).\n\nExercise 7.8 Considere a cadeia de Markov com as seguintes probabilidades de transição\n\\[\\begin{array}{c|cccccc}\\hline\ni\\setminus j & 0 & 1 & 2 & 3 & 4 & 5 \\\\ \\hline\n0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n1 & 0,5 & 0 & 0,5 & 0 & 0 & 0 \\\\\n2 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n3 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n4 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n5 & 0 & 0 & 0 & 0 & 0 & 1\\\\ \\hline \\end{array}\\]\n\nIdentifique as classes e classifique-as como recorrenteou transiente\nDetermine o período de cada classe.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introdução às cadeias de Markov</span>"
    ]
  },
  {
    "objectID": "cadeias_de_markov.html#distribuição-estacionária",
    "href": "cadeias_de_markov.html#distribuição-estacionária",
    "title": "7  Introdução às cadeias de Markov",
    "section": "7.4 Distribuição estacionária",
    "text": "7.4 Distribuição estacionária\nAté o presente momento, as cadeias de Markov foram caracterizadas pela probabilidade de transição. De fato, a probabilidade do processo estar no estado \\(j\\) no tempo \\(n\\) é dada por\n\\[P(X_n=j)=\\sum_{i=-\\infty}^\\infty p_{ij}^{(n)}P(X_0=i),\\] de modo que, em princípio, essa probabilidade é calculável apenas quando a função de probabilidade de \\(X_0\\) é conhecida.\nConsidere o caso particular, no qual \\(P(X_n=j)=\\pi_j\\) não depende de \\(n\\). Isso implica que\n\\[\\pi_j=\\sum_{i=-\\infty}^\\infty p_{ij}^{(n)}\\pi_i.\\] Nessa caso, dizemos que \\(\\pi_i\\) é a distribuição estacionária da cadeia de Markov. Observe que\n\\[\\begin{align}\\pi_j=\\lim_{n\\rightarrow\\infty}\\pi_j=\\lim_{n\\to\\infty}\\sum_{i=-\\infty}^\\infty p_{ij}^{(n)}\\pi_i=\\sum_{i=-\\infty}^\\infty\\left[\\lim_{n\\to\\infty}p_{ij}^{(n)}\\right]\\pi_i.\\end{align}\\] Acontece que é natural supor que, para \\(n\\) suficientemente grande, o estado inicial perca relevância em \\(p_{ij}^{(n)}\\), ou seja \\(p_{ij}^{(n)}\\approx a_j\\), onde \\(a_j\\) não depende de \\(i\\). Mas, nesse caso\n\\[\\begin{align}\\pi_j=\\sum_{i=-\\infty}^\\infty\\left[\\lim_{n\\to\\infty}p_{ij}^{(n)}\\right]\\pi_i=a_j\\sum_{i=-\\infty}^\\infty \\pi_i=a_j,\\end{align}\\] e, portanto, \\[\\pi_j=\\lim_{n\\rightarrow\\infty}p_{ij}^{(n)}.\\]\nPortanto, a existência da distribuição estacionária está intimamente relacionada com o comportamento de \\(p_{ij}^{(n)}\\) quando \\(n\\to\\infty\\).\n\nProposition 7.3 Estados transientes não podem ter distribuição estacionária.\nDemonstração intuitiva. Se \\(j\\) é transiente, então \\(f_j&lt;1\\), o que implica que, em algum momento, esse estado nunca mais será visitado. Portanto \\(p_{ij}^{(n)}\\to 0\\) quando \\(n\\to \\infty\\).\n\n\nProposition 7.4 Cadeias com mais de uma classe não tem distribuição estacionária.\nDemonstração intuitiva. Suponha que a cadeia possui duas classes, \\(C_1\\) e \\(C_2\\). Como os estados entre as classes não se comunicam, temos as seguintes situações:\n\nUma classe é recorrente e a outra transiente: nesse caso, por causa dos estados transientes, não há distribuição estacionária.\nAs duas são recorrentes. Nesse caso, uma classe não pode ser acessível a partir da outra e a cadeia está sujeita ao estado inicial em \\(X_0\\), logo não há distribuição estacionária.\n\n\n\nProposition 7.5 Considere uma cadeia com apenas uma classe recorrente, com período maior que 1. Então, não há distribuição estacionária.\nDemonstração intuitiva. Se o período de \\(j\\) é \\(k&gt;1\\), então \\(p_{ij}^{(n)}=0\\) para todo \\(n\\) não múltiplo de \\(k\\). Logo para a sequência \\(p_{ij}^{(1)},p_{ij}^{(2)},\\ldots\\) existe uma subsequência que converge para zero e, portanto, não pode existir \\(\\lim_{n\\rightarrow\\infty}p_{ij}^{(n)}\\).\n\n\nProposition 7.6 Cadeias com uma única classe, recorrente e aperiódica, com um número finito de estados, tem distribuição estacionária.\n\nPara uma cadeia com estados \\(\\{0,1,\\ldots,m\\}\\), auando a distribuição estacionária existe, ela pode ser encontrada resolvendo\n\\[\\pi_{j}=\\sum_{i=0}^m p_{ij}\\pi_i\\] com a restrição \\(\\sum_{i=1}^m\\pi_i=1\\).\n\nImportante. A distribuição estacionária é interpretada como distribuição em longo prazo, pois as frequências relativas dos estados da cadeia tendem para a distribuição estacionária.\n\n\nExample 7.6 Considere a cadeia de Markov com as seguintes probabilidades de transição \\(p_{ij}\\):\n\\[\\begin{array}{c|cc}\\hline\ni\\setminus j & 0 & 1 \\\\ \\hline\n0 & 0,2 & 0,8 \\\\\n1 & 0,7 & 0,3\\\\\\hline\\end{array}\\]\nÉ simples mostrar que a cadeia tem uma única classe recorrente e aperiódica. Temos então que a distribuição estacionária satisfaz\n\\[\\begin{align}\\pi_0&=p_{00}\\pi_0+p_{10}\\pi_1=0,2\\pi_0+0,7\\pi_1 \\\\ \\pi_1&=p_{01}\\pi_0+p_{11}\\pi_1=0,8\\pi_0+0,3\\pi_1\\\\\n1&=\\pi_0+\\pi_1\\end{align}\\]\nPela restrição de soma 1, temos que \\(\\pi_0=1-\\pi_1\\) e substituindo essa informação na primeira equação teremos\n\\[(1-\\pi_1)=0,2(1-\\pi_1)+0,7\\pi_1\\Rightarrow \\pi_1=\\frac{8}{15}\\] e, por consequência, \\(\\pi_0=7/15\\).\n\n\nExercise 7.9 Uma empresa de streaming classifica seus clientes em três estados mensais:\n\nEstado 0 (Inativo): O cliente não assinou o serviço.\nEstado 1 (Básico): O cliente assinou o plano simples.\nEstado 2 (Premium): O cliente assinou o plano completo com 4K.\n\nA matriz de transição \\(P\\) entre os meses é:\n\\[\\begin{array}{c|ccc}i\\setminus j & 0 & 1 & 2 \\\\ \\hline0 & 0,5 & 0,5 & 0 \\\\1 & 0,2 & 0,5 & 0,3 \\\\2 & 0 & 0,4 & 0,6\\end{array}\\]\n\nVerifique se a cadeia possui uma única classe recorrente e é aperiódica.\nEncontre a distribuição estacionária\nSe o serviço tiver 1 milhão de clientes em potencial, quantos estarão no plano Premium no longo prazo?\n\n\n\nExercise 7.10 Uma fábrica monitora uma máquina essencial que pode estar em três estados:\n\nEstado 0: Operando perfeitamente.\nEstado 1: Operando com falhas menores (requer atenção).\nEstado 2: Quebrada (parada total).\n\nA matriz de transição semanal é:\n\\[\\begin{array}{c|ccc}i\\setminus j & 0 & 1 & 2 \\\\ \\hline0 & 0,7 & 0,2 & 0,1 \\\\1 & 0 & 0,6 & 0,4 \\\\2 & 1 & 0 & 0\\end{array}\\]\n\nDesenhe o grafo.\nVerifique se a cadeia é irredutível e aperiódica.\nCalcule a distribuição estacionária\nSe o custo de manter a máquina parada (estado 2) é de R$ 10.000,00 por semana, qual é o gasto médio semanal esperado com quebras no longo prazo?",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introdução às cadeias de Markov</span>"
    ]
  },
  {
    "objectID": "cadeias_de_markov.html#exercícios-de-fixação",
    "href": "cadeias_de_markov.html#exercícios-de-fixação",
    "title": "7  Introdução às cadeias de Markov",
    "section": "7.5 Exercícios de fixação",
    "text": "7.5 Exercícios de fixação\n\nExercise 7.11 Um prédio possui 3 andares (0, 1 e 2). Um elevador se movimenta da seguinte forma: se ele está no andar 0, no próximo passo ele vai para o andar 1 com probabilidade 1. Se ele está no andar 2, ele vai para o andar 1 com probabilidade 1. Se ele está no andar 1, ele escolhe o próximo andar (0 ou 2) com probabilidade 0,5 para cada. Defina o conjunto de estados \\(\\mathcal{S}\\) e encontre as probabilidaes de transição.\n\n\nExercise 7.12 Uma loja de eletrônicos tem capacidade para 2 consoles em estoque. No fim de cada dia, se o estoque estiver zerado (estado 0), a loja recebe 2 novos consoles para o dia seguinte. Se houver 1 ou 2 consoles, a loja não faz pedido. A probabilidade de um cliente comprar um console em um dia é 0,4 (supunha que no máximo 1 cliente tenta comprar por dia).\n\nConstrua o grafo desta cadeia de Markov com os estados {0, 1, 2}.\nDetermine as probabilidades de transição \\(p_{02}\\) e \\(p_{10}\\).\n\n\n\nExercise 7.13 Considere uma cadeia de Markov com as seguintes probabilidades de transição:\n\\[\\begin{array}{c|cccc}\\hline\ni\\setminus j & 0 & 1 & 2 & 3 \\\\ \\hline\n0 & 1 & 0 & 0 & 0 \\\\\n1& 0,2 & 0,3 & 0,5 & 0 \\\\\n2&0 & 0 & 0,4 & 0,6 \\\\\n3& 0 & 0 & 0 & 1 \\\\ \\hline \\end{array}\\]\n\nDesenhe o grafo da cadeia.\nIdentifique as classes.\nClassifique cada classe como transiente ou recorrente e encontre seu período.\n\n\n\nExercise 7.14 Determine o período (\\(d_i\\)) do estado 0 para as seguintes situações:\n\n\\(p_{01}=1, p_{12}=1, p_{20}=1\\).\n\\(p_{01}=1, p_{10}=0,5, p_{12}=0,5, p_{20}=1\\).\nO estado 0 possui um arco para si mesmo (\\(p_{00} &gt; 0\\)). Qual é o seu período?\n\n\n\nExercise 7.15 Em uma cidade, o clima pode ser Seco (0) ou Chuvoso (1). As probabilidades de transição são\n\\[\\begin{array}{c|cc}\\hline i\\setminus j & 0 & 1 \\\\\\hline  0 &0,8 & 0,2 \\\\ 1&0,4 & 0,6 \\\\ \\hline\\end{array}\\]\n\nCalcule a distribuição estacionária \\((\\pi_0, \\pi_1)\\).\nUm vendedor de sorvetes lucra R$200,00 em dias secos e perde R$ 50,00 em dias chuvosos. Qual o lucro médio diário esperado no longo prazo?\n\n\n\nExercise 7.16 Três operadoras de celular (A, B e C) disputam o mercado. As probabilidades de transição mensal dos clientes são entre as operadoras são:\n\nDe \\(A\\): 70% ficam na \\(A\\), 20% vão para \\(B\\), 10% vão para \\(C\\).\nDe \\(B\\): 10% vão para \\(A\\), 80% ficam na \\(B\\), 10% vão para \\(C\\).\nDe \\(C\\): 10% vão para \\(A\\), 10% vão para \\(B\\), 80% ficam na \\(C\\).\n\nPergunta: No longo prazo, qual operadora terá a maior fatia de mercado? :::",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introdução às cadeias de Markov</span>"
    ]
  },
  {
    "objectID": "provas.html",
    "href": "provas.html",
    "title": "8  Provas anteriores resolvidas",
    "section": "",
    "text": "8.1 Parcial I - 2025/2–Férias",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Provas anteriores resolvidas</span>"
    ]
  },
  {
    "objectID": "provas.html#parcial-i---20252férias",
    "href": "provas.html#parcial-i---20252férias",
    "title": "8  Provas anteriores resolvidas",
    "section": "",
    "text": "Questão 1Solução\n\n\nConsidere duas variáveis aleatórias discretas \\(X\\) e \\(Y\\). A distribuição de probabilidade conjunta dessas variáveis é apresentada na tabela abaixo, onde \\(k\\) é uma constante real.\n\n\n\n\\(X \\setminus Y\\)\n1\n2\n3\n\n\n\n\n0\n\\(k\\)\n\\(2k\\)\n\\(k\\)\n\n\n1\n\\(2k\\)\n\\(k\\)\n\\(3k\\)\n\n\n\n\nDetermine o valor da constante \\(k\\) para que a função acima seja uma função de probabilidade conjunta válida.\nDetermine as funções de probabilidade marginais de \\(X\\) e \\(Y\\).\nCalcule a probabilidade condicional \\(P(Y=3 \\mid X=1)\\).\n\n\n\n\nA constante \\(k\\) é o valor tal que a soma de todas as probabilidades é igual a 1. Portanto\n\n\\[1=k+2k+k+2k+k+3k=10k\\Rightarrow k=\\frac{1}{10}\\]\n\nA função de probabilidade marginal de \\(X\\) é\n\n\\[P(X=x)=\\sum_{y=1}^3P(X=x,Y=y)=\\begin{cases}0,4&x=0\\\\\n0,6&x=1\\end{cases}\\]\ne a função de probabilidade marginal de \\(Y\\) é\n\\[P(Y=y)=\\sum_{x=0}^1P(X=x,Y=y)=\\begin{cases}0,3&y=1\\\\\n0,3&y=2\\\\0,4&y=3\\end{cases}\\]\n\nTemos que\n\n\\[P(Y=3 \\mid X=1)=\\frac{P(X=1,Y=3)}{P(X=1)}=\\frac{3}{6}=0,5.\\]\n\n\n\n\nQuestão 2Solução\n\n\nSejam \\(X\\) e \\(Y\\) duas variáveis aleatórias contínuas com função de densidade conjunta dada por:\n\\[\nf(x, y) =\n\\begin{cases}\n    k(x + y) & \\text{se } 0 \\leq x \\leq 1, \\, 0 \\leq y \\leq 2 \\\\\n    0 & \\text{caso contrário}\n\\end{cases}\n\\]\nonde \\(k\\) é uma constante real. Pede-se:\n\nDetermine o valor da constante \\(k\\) para que \\(f(x, y)\\) seja uma função de densidade de probabilidade válida.\nEncontre as funções de densidade marginais \\(f_X(x)\\) e \\(f_Y(y)\\).\nCalcule a probabilidade condicional \\(P(X &lt; 0,5 \\mid Y = 1)\\).\n\n\n\n\nA constante \\(k\\) é o valor que satisfaz\n\n\\[1=\\int_{\\mathbb{R}^2}f(x,y)dxdy\\] e como,\n\\[\\int_0^2\\int_0^1k(x+y)dxdy=k\\int_0^2\\frac{1}{2}+ydy=3k,\\] teremos que \\(k=1/3\\).\n\nA marginal de \\(X\\) é\n\n\\[f_X(x)=\\frac{1}{3}\\int_0^2(x+y)dyI_{(0,1)}(x)=\\frac{2}{3}(1+x)I_{(0,1)}(x).\\] e a marginal de \\(Y\\) é\n\\[f_Y(y)=\\frac{1}{3}\\int_0^1(x+y)dxI_{(0,2)}(y)=\\frac{1}{3}\\left(\\frac{1}{2}+y\\right)I_{(0,2)}(y).\\]\n\nA densidade condicional de \\(X|Y=y\\) é\n\n\\[f(x|y)=\\frac{f(x,y)}{f_Y(y)}=\\frac{\\frac{1}{3}(x+y)I_{(0,1)}(x)I_{(0,2)}(y)}{\\frac{1}{3}\\left(\\frac{1}{2}+y\\right)I_{(0,2)}(y)}=2\\frac{(x+y)}{(1+2y)}I_{(0,1)}(x),\\]\nlogo \\[P(X&lt;0,5|Y=1)=\\frac{2}{3}\\int_0^{0,5}(x+1)dx=\\frac{2}{3}\\left[\\left(\\frac{1}{2}\\right)^3+\\frac{1}{2}\\right]=\\frac{5}{12}\\]\n\n\n\n\nQuestão 3Solução\n\n\nSejam \\(X_1\\) e \\(X_2\\) duas variáveis aleatórias independentes com função de probabilidade dada por:\n\\[P(X=x)=\\frac{1}{2^{x+1}}I_{\\mathbb{N}}(x)\\]\nDetermine a função de probabilidade de \\(Y = X_1 + X_2\\).\n\n\n\\[\\begin{align}P(Y=y)&=\\sum_{x_2=-\\infty}^\\infty P(X_1=y-x_2,X_2=x_2)\\\\&=\\sum_{x_2=-\\infty}^\\infty P(X_1=y-x_{2})P(X_2=x_2)\\\\&=\\sum_{x_2=-\\infty}^\\infty \\frac{1}{2^{y-x_2+1}}I_{\\mathbb{N}}(y-x_2)\\frac{1}{2^{x_2+1}}I_{\\mathbb{N}}(x_2)\\\\&=\\frac{1}{2^{y+2}}\\sum_{x_2=0}^y1=\\frac{1+y}{2^{y+2}},\\;\\;y=0,1,\\ldots.\\end{align}\\]\n\n\n\n\nQuestão 4Solução\n\n\nSejam \\(X_1, X_2\\) variáveis aleatórias independentes com distribuição \\(\\text{Uniforme}(0,1)\\). Sejam \\(Y=-\\log(X_1X_2)\\) e \\(W=X_2\\).\n\nEncontre a densidade conjunta de \\((Y,W)\\).\nEncontre a densidade marginal de \\(Y\\).\n\n\nLembrete: &gt; 1. \\(e^{-x} &lt; 1\\) para todo \\(x &gt; 0\\) 2. \\(\\int x^{-1}dx = \\log x\\)\n\n\n\n\nVamos utilizar o método do jacobiano.\n\nEncontrando a inversa: Teremos que \\[\\begin{align}x_2&=w \\\\ x_1&=\\frac{e^{-y}}{w}\\end{align}\\]\nEncontrando a matriz jacobiana:\n\\[\\left(\\begin{array}{cc}\\frac{\\partial x_1}{\\partial y} & \\frac{\\partial x_1}{\\partial w } \\\\ \\frac{\\partial x_2}{\\partial y} & \\frac{\\partial x_2}{\\partial w}\\end{array}\\right)=\\left(\\begin{array}{cc}-\\frac{e^{-y}}{w} & -\\frac{e^{-y}}{w^2} \\\\ 0 & 1\\end{array}\\right)\\]\nMódulo do determinante da matriz jacobiana:\n\\[\\frac{e^{-y}}{w}\\]\nDistribuição conjunta de \\(Y\\) e \\(W\\):\n\\[f_{Y,W}(y,w)=f_{X_1}\\left(\\frac{e^{-y}}{w}\\right)f_{X_2}(w)\\frac{e^{-y}}{w}=I_{(0,1)}\\left(\\frac{e^{-y}}{w}\\right)I_{(0,1)}(w)\\frac{e^{-y}}{w}\\]\n\nObserve que \\(0&lt;e^{-y}&lt;w&lt;1\\), logo\n\n\\[f_Y(y)=e^{-y}\\int_{e^{-y}}^1 \\frac{1}{w}dw=e^{-y}[\\log 1 - \\log e^{-y}]=ye^{-y},\\;\\;y&gt;0.\\]\n\n\n\n\nQuestão 5Solução\n\n\nSejam \\(X_1\\) e \\(X_2\\) duas variáveis aleatórias independentes com distribuição \\(\\text{Normal}(0, 1/2)\\). Considere a nova variável aleatória definida pela soma \\(S = X_1 + X_2\\). Prove que \\(S \\sim \\text{Normal}(0,1)\\).\n\n\n\\[\\begin{align}f_Y(y)&=\\int_\\mathbb{R}f_{X_1}(y-x_2)f_{X_2}(x_2)dx_2\n\\\\&=\\int_\\mathbb{R}\\frac{1}{\\sqrt{\\pi}}e^{-(y-x_2)^2}\\frac{1}{\\sqrt{\\pi}}e^{-x_2^2}dx_2\\\\&=\\frac{1}{\\pi}\\int_\\mathbb{R}e^{-(y^2+x_2^2-2x_2y)-x^2_2}dx_2\\\\&=\\frac{e^{-y^2}}{\\pi}\\int_\\mathbb{R}e^{-[2x_2^2-2x_2y]}dx_2\\end{align}\\]\nnote que\n\\[2x_2^2-2x_2y=2\\left(x_2^2 -2x_2\\frac{y}{2}\\right)=2\\left(x_2^2 -2x_2\\frac{y}{2}\\pm\\frac{y^2}{4}\\right)=2\\left(x_2-\\frac{y}{2}\\right)^2-\\frac{y^2}{2}\\] logo\n\\[\\begin{align}f_Y(y)&=\\frac{e^{-y^2}}{\\pi}\\int_\\mathbb{R}e^{-2\\left(x_2-\\frac{y}{2}\\right)^2+\\frac{y^2}{2}}dx_2\\\\&=\\frac{e^{-\\frac{y^2}{2}}}{\\pi}\\int_\\mathbb{R}e^{-2\\left(x_2-\\frac{y}{2}\\right)^2}dx_2\\\\&=\\frac{e^{-\\frac{y^2}{2}}}{\\pi}\\sqrt{2\\pi/4}=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{y^2}{2}},\\;\\;y\\in\\mathbb{R}\\end{align}\\]",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Provas anteriores resolvidas</span>"
    ]
  }
]