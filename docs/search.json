[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Probabilidade C",
    "section": "",
    "text": "Prefácio",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introdução",
    "section": "",
    "text": "1.1 Vetores aleatórios\nNeste curso vamos utilizar o negrito para designar um vetor. Por exemplo,\n\\[\\textbf{x}=(x_1,…,x_n)\\], é um vetor de comprimento \\(n\\).\nAgora, sejam \\(X_1,…,X_n\\) variáveis aleatórias. Então, dizemos que\n\\[\\textbf{X}=(X_1,…,X_n)\\] é um vetor aleatório (também é usual o termo variável aleatória \\(n\\) -dimensional).\nUtilizamos a vírgula para denotar a interseção de eventos relacionados aos vetores aleatórios. Por exemplo,\n\\[P(X_1\\in A,X_2\\in B)=P(\\{X_1\\in A\\}\\cap\\{X_2\\in B\\})\\],\nAssim como as variáveis aleatórias, os vetores aleatórios possuem funções de densidade/probabilidade e funções de distribuição. Para frisar que mais de uma variável está sendo considerada, utilizamos o adjetivo conjunta. Deste modo, existem para os vetores aleatórias a função de distribuição conjunta e a função de densidade/probabilidade conjunta. Por sua vez, a distribuição de um subvetor de \\(\\textbf{X}\\) é denominada marginal.\nTambém é possível encontrar funções de distribuição ou densidade/probabilidade para o vetor aleatório \\(\\textbf{X}\\) condicionado com o vetor aleatório \\(\\textbf{Y}\\).\nUma vez que essas funções, já conhecidas para o caso univariado, possuem seu equivalente para vetores, é natural expandir conceitos como espança e variância para vetores, assim como a esperança e variância para distribuições condicionais. Nesse momento, novas medidas que medem o relacionamento entre variáveis aleatórias, como covariância e correlação, serão apresentadas.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "intro.html#vetores-aleatórios",
    "href": "intro.html#vetores-aleatórios",
    "title": "1  Introdução",
    "section": "",
    "text": "Dois dados de seis faces são lançados. Sejam \\(X_1\\) e \\(X_2\\) os resultados do dado 1 e 2, respectivamente. Então, \\(\\textbf{X}=(X_1,X_2)\\) é um vetor aleatório.\n\n\n\n\nDois dados de seis faces são lançados. Sejam \\(X_1\\) e \\(X_2\\) os resultados do dado 1 e 2, respectivamente. Então, \\(P(X_1=3,X_2=5)\\) é o mesmo que \\(P(\\{X_1=3\\}\\cap\\{X_2=5\\})\\). Em palavras, este número representa a probabilidade de sair 3 no primeiro dado e 5 no segundo.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "intro.html#teoremas-limites",
    "href": "intro.html#teoremas-limites",
    "title": "1  Introdução",
    "section": "1.2 Teoremas limites",
    "text": "1.2 Teoremas limites",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "intro.html#cadeias-de-markov",
    "href": "intro.html#cadeias-de-markov",
    "title": "1  Introdução",
    "section": "1.3 Cadeias de Markov",
    "text": "1.3 Cadeias de Markov",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_discretos.html",
    "href": "vetores_aleatorios_discretos.html",
    "title": "2  Distribuição de vetores aleatórios discretos",
    "section": "",
    "text": "2.1 Função de probabilidade conjunta\nOs objetivos deste capítulo são:\nObserve que a função de probabilidade conjunta é a interseção dos eventos \\(\\{X_1=x_1\\},\\ldots,\\{X_n=x_n\\}\\). Portanto, se \\(X_1,\\ldots,X_n\\) são mutuamente independentes, teremos\n\\[P(\\textbf{X}=\\textbf{x})=\\prod_{i=1}^n P(X_i=x_i).\\] Também é possível que subconjuntos de variáveis do vetor sejam independentes. Por exemplo, \\(\\tilde{\\textbf{X}}_1=\\{X_1,\\ldots,X_m\\}\\) podem ser independentes de \\(\\tilde{\\textbf{X}}_2=\\{X_{m+1},\\ldots,X_n\\}\\), o que resulta em\n\\[P(\\textbf{X}=\\textbf{x})=P(\\tilde{\\textbf{X}}_1=\\tilde{\\textbf{x}}_1)P(\\tilde{\\textbf{X}}_2=\\tilde{\\textbf{x}}_2).\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Distribuição de vetores aleatórios discretos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_discretos.html#função-de-probabilidade-conjunta",
    "href": "vetores_aleatorios_discretos.html#função-de-probabilidade-conjunta",
    "title": "2  Distribuição de vetores aleatórios discretos",
    "section": "",
    "text": "Definition 2.1 Sejam \\(X_1,\\ldots,X_n\\) variáveis aleatórias discretas. Então, a função\n\\[P(\\textbf{X}=\\textbf{x})=P(X_1=x_1,\\ldots,X_n=x_n),\\] é denominada função de probabilidade conjunta.\n\n\nProposition 2.1 Seja \\(\\textbf{X}\\) um vetor de variáveis aleatórias discretas. Teremos que \\[P(\\textbf{X}=\\textbf{x})=P(X_1=x_1,\\ldots,X_n=x_n)\\] é uma função de probabilidade se:\n\\[\n\\sum_{\\textbf{x}\\in\\mathbb{Z}^n}P(\\textbf{X}=\\textbf{x})=1\\] e se \\[P(\\textbf{X}=\\textbf{x})\\geq 0,\\;\\;\\forall\\;\\textbf{x}\\in\\mathbb{Z}^n.\\]\n\n\nExample 2.1 Seja \\(\\textbf{X}=(X_1,X_2)\\) um vetor aleatório discreto e considere a função\n\\[P(X_1=x_1,X_2=x_2)=\\left\\{\\begin{array}{ll}\\frac{1}{20},& x_1=1,x_2=1\\\\\n\\frac{4}{20},&x_1=1,x_2=2\\\\\n\\frac{5}{20},&x_1=2,x_2=1\\\\\n\\frac{7}{20},&x_1=2,x_2=2\\\\\n\\frac{2}{20},&x_1=3,x_2=1\\\\\n\\frac{1}{20},&x_1=3,x_2=2\\\\ 0,&\\hbox{caso contrário}\\end{array}\\right.\\]\nObserve que todas as probabilidades são não negativas a soma para todos os pares \\((x_1,x_2)\\in\\mathbb{Z}^2\\) é igual a 1, logo a função dada é de fato uma função de probabilidade conjunta para o vetor \\(\\textbf{X}\\).\n\n\nExercise 2.1 Seja\n\\[P(\\textbf{X}=\\textbf{x})=P(X_1=x_1,X_2=x_2)=cq^{x_1+x_2},\\] onde \\((x_1,x_2)\\in\\{0,1\\}^2\\) e \\(q&gt;0\\). Encontre o valor de \\(c\\) para que \\(P(\\textbf{X}=\\textbf{x})\\) seja uma função de probabilidade.\n\n\n\n\n\nExample 2.2 Considere uma moeda com os números 0 e 1 em cada lado. Considere ainda que os dois resultados são equiprováveis. A moeda é lançada duas vezes. Seja \\(X_i\\) o resultado do \\(i\\)-ésimo lançamento. Considerando que \\(X_1\\) e \\(X_2\\) são independentes, encontre a função de probabilidade conjunta de \\(\\textbf{X}=(X_1,X_2)\\).\nSolução. Para \\(i=1,2\\), teremos que\n\\[P(X_i=0)=P(X_i=1)=\\frac{1}{2}.\\]\nComo \\(X_1\\) e \\(X_2\\) são lançamentos independentes, teremos\n\\[P(\\textbf{X}=(0,0))=P(X_1=0,X_2=0)=P(X_1=0)P(X_2=0)=\\frac{1}{4}.\\] Todos os resultados possíveis são \\(\\{(0,0),(0,1),(1,0),(1,1)\\}\\) e podemos mostrar, de modo análogo ao que foi exposto acima, todos esses eventos têm probabilidade 1/4.\n\n\nExercise 2.2 Lança-se um dado de 6 faces. Seja \\(\\textbf{X}=(X_1,X_2)\\) onde\n\\[X_1=\\left\\{\\begin{array}{ll}1,& \\hbox{ se o resultado é par}\\\\0,&\\hbox{ caso contrário}\\end{array}\\right.\\] e\n\\[X_2=\\left\\{\\begin{array}{ll}1,& \\hbox{ se o resultado é maior que 3}\\\\ 0,&\\hbox{ caso contrário}\\end{array}\\right.\\]\nEncontre a função de probabilidade conjunta de \\(\\textbf{X}\\).\n\n\nExercise 2.3 Considere o vetor aleatório \\(\\mathbf{X} = (X_1, X_2, X_3)\\) e os subconjuntos \\(\\tilde{\\mathbf{X}}_1 = \\{X_1\\}\\) e \\(\\tilde{\\mathbf{X}}_2 = \\{X_2, X_3\\}\\). A função de probabilidade conjunta de \\(\\tilde{\\mathbf{X}}_2\\) é dada pela tabela abaixo:\n\n\n\n\\(x_2 \\setminus x_3\\)\n0\n1\n\\(P(X_2 = x_2)\\)\n\n\n\n\n0\n0,2\n0,3\n0,5\n\n\n1\n0,1\n0,4\n0,5\n\n\n\\(P(X_3 = x_3)\\)\n0,3\n0,7\n1,0\n\n\n\nSabendo que \\(X_1\\) assume valores no conjunto \\(\\{0, 1\\}\\) com probabilidades \\(P(X_1=0)=0,6\\) e \\(P(X_1=1)=0,4\\), e que o bloco \\(\\tilde{\\mathbf{X}}_1\\) é independente do bloco \\(\\tilde{\\mathbf{X}}_2\\):\nCalcule a probabilidade conjunta do vetor completo para o ponto \\((X_1=0, X_2=1, X_3=0)\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Distribuição de vetores aleatórios discretos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_discretos.html#função-de-distribuição-conjunta",
    "href": "vetores_aleatorios_discretos.html#função-de-distribuição-conjunta",
    "title": "2  Distribuição de vetores aleatórios discretos",
    "section": "2.2 Função de distribuição conjunta",
    "text": "2.2 Função de distribuição conjunta\n\nDefinition 2.2 A função de distribuição conjunta é definida por\n\\[F(\\textbf{x})=P(X_1\\leq x_1,\\ldots,X_n\\leq x_n)=\\sum_{u_1=-\\infty}^{x_1}\\cdots\\sum_{u_n=-\\infty}^{x_n}P(X_1=u_1,\\ldots,X_n=u_n).\\]\n\n\nExample 2.3 Considere novamente a função de probabilidade conjunta dada por\n\\[P(X=x,Y=y)=\\left\\{\\begin{array}{ll}\\frac{1}{10},& x=1,y=1\\\\\n\\frac{4}{10},&x=1,y=2\\\\\n\\frac{3}{10},&x=2,y=1\\\\\n\\frac{2}{10},&x=2,y=2\\\\\n\\\\ 0,&\\hbox{caso contrário}\\end{array}\\right.\\]\nA função de distribuição conjunta é dada por\n\\[F(x,y)=\\left\\{\\begin{array}{ll}0,& x&lt;1,y&lt;1\\\\\nP(X=1,Y=1)=\\frac{1}{10},& x=1,y=1\\\\\nP(X=1,Y=1)+P(X=1,Y=2)=\\frac{5}{10},&x=1,y=2\\\\\nP(X=1,Y=1)+P(X=2,Y=1)=\\frac{4}{10},&x=2,y=1\\\\\n1,&x\\geq 2,y\\geq 2\\end{array}\\right.\\]\n\n\nExercise 2.4 Considere o vetor \\((X,Y)\\) de variáveis aleatórias com função de probabilidade conjunta dada por\n\\[P(X=x,Y=y)=\\frac{2^{x+y}}{9},\\] com \\((x,y)\\in\\{0,1\\}^2\\). Encontre a função de distribuição conjunta deste vetor aleatório.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Distribuição de vetores aleatórios discretos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_discretos.html#distribuição-marginal",
    "href": "vetores_aleatorios_discretos.html#distribuição-marginal",
    "title": "2  Distribuição de vetores aleatórios discretos",
    "section": "2.3 Distribuição marginal",
    "text": "2.3 Distribuição marginal\n\nDefinition 2.3 Seja \\(\\textbf{X} = (X_1, \\ldots, X_n)\\) um vetor aleatório discreto. Considere um subvetor \\(\\textbf{X}_a\\) com índices \\(a \\subset \\{1, \\ldots, n\\}\\). A função de probabilidade marginal de \\(\\textbf{X}_a\\) é obtida somando-se a função conjunta sobre todos os valores possíveis das variáveis cujos índices não estão em \\(a\\) (denotados por \\(a^c\\)):\\[P(\\textbf{X}_a = \\textbf{x}_a) = \\sum_{\\textbf{x}_{a^c}} P(X_1=x_1, \\ldots, X_n=x_n)\\]onde o somatório é estendido a todos os valores possíveis de cada \\(x_j\\) tal que \\(j \\notin a\\).\n\nNota: No caso de um vetor bidimensional \\(\\textbf{X} = (X, Y)\\), se quisermos a marginal de \\(X\\), marginalizamos \\(Y\\) somando sobre todos os seus valores:\\[P(X=x) = \\sum_{y=-\\infty}^\\infty P(X=x, Y=y)\\]\n\nExample 2.4 Considere a tabela abaixo, cujo corpo contém a função distribuição de probabilidade conjunta das variáveis \\(X\\) e \\(Y\\).\n\\[\\begin{array}{c|cccc}\\hline\n&y\\\\\nx&  1&  2&  3&  4\\\\ \\hline\n1&  0,1&    0,05&   0,02&   0,07\\\\\n2&  0,08&   0,05&   0,1&    0,19\\\\\n3&  0,1&    0,2&    0,04&   0\\\\ \\hline\\end{array}\\]\nVamos encontrar as distribuições marginais de \\(X\\) e \\(Y\\):\n\\[\\begin{align}\nP(X=1)&=\\sum_{y=1}^4P(X=1,Y=y)=0,24\\\\\nP(X=2)&=\\sum_{y=1}^4P(X=2,Y=y)=0,42\\\\\nP(X=3)&=\\sum_{y=1}^4P(X=3,Y=y)=0,34\\end{align}\\] e \\[\\begin{align}\nP(Y=1)&=\\sum_{x=1}^3P(X=x,Y=1)=0,28\\\\\nP(Y=2)&=\\sum_{x=1}^3P(X=x,Y=1)=0,3\\\\\nP(Y=3)&=\\sum_{x=1}^3P(X=x,Y=1)=0,16\\\\\nP(Y=4)&=\\sum_{x=1}^3P(X=x,Y=1)=0,26.\n\\end{align}\\]\nObserve que a função de probabilidade marginal de \\(X\\) é obtida a partir da soma das linhas da tabela, enquanto que a função de probabilidade marginal de \\(Y\\) é obtida a partir da soma das colunas. Nessas funções podem ser colocadas nas margens da tabela:\n\\[\\begin{array}{c|cccc|c}\\hline\n&y\\\\\nx&  1&  2&  3&  4& P(X=x)\\\\ \\hline\n1&  0,10&   0,05&   0,02&   0,07&0,24\\\\\n2&  0,08&   0,05&   0,10&   0,19&0,42\\\\\n3&  0,10&   0,20&   0,04&   0,00&0,34\\\\ \\hline\nP(Y=y)&0,28&0,30&0,16&0,26&\\end{array}\\]\n\n\nExercise 2.5 Considere a tabela de probabilidade conjunta das variáveis aleatórias discretas \\(X\\) (linhas) e \\(Y\\) (colunas) apresentada abaixo, onde um dos valores foi substituído pela constante \\(k\\).\n\\[\\begin{array}{c|ccc}\\hline\n&y\\\\\nx&  1&  2&  3\\\\ \\hline\n1&  0,15&   0,10&   k\\\\\n2&  0,05&   0,20&   0,15\\\\\n3&  0,05&   0,10&   0,10\\\\ \\hline\\end{array}\\]\n\nEncontre o valor de \\(k\\) para que a tabela represente uma distribuição de probabilidade conjunta válida.\nDetermine as funções de probabilidade marginais de \\(X\\) e \\(Y\\).\n\n\n\nExercise 2.6 Sejam \\(X\\) e \\(Y\\) variáveis aleatórias discretas com a seguinte função de probabilidade conjunta:\n\\[P(X=x,Y=y)=\\frac{e^{−x}x^y}{2^xy!},\\] onde \\(x=1,2,\\ldots\\) e \\(y=0,1,\\ldots\\). Encontre a função de probabilidade marginal de \\(X\\).\n\n\nExercise 2.7 Considere novamente o vetor aleatório \\(\\mathbf{X} = (X_1, X_2, X_3)\\) e os subconjuntos \\(\\tilde{\\mathbf{X}}_1 = \\{X_1\\}\\) e \\(\\tilde{\\mathbf{X}}_2 = \\{X_2, X_3\\}\\). A função de probabilidade conjunta de \\(\\tilde{\\mathbf{X}}_2\\) é dada pela tabela abaixo:\n\n\n\n\\(x_2 \\setminus x_3\\)\n0\n1\n\\(P(X_2 = x_2)\\)\n\n\n\n\n0\n0,2\n0,3\n0,5\n\n\n1\n0,1\n0,4\n0,5\n\n\n\\(P(X_3 = x_3)\\)\n0,3\n0,7\n1,0\n\n\n\nSabendo que \\(X_1\\) assume valores no conjunto \\(\\{0, 1\\}\\) com probabilidades \\(P(X_1=0)=0,6\\) e \\(P(X_1=1)=0,4\\), e que o bloco \\(\\tilde{\\mathbf{X}}_1\\) é independente do bloco \\(\\tilde{\\mathbf{X}}_2\\):\n\nMostre que \\(X_1\\) é independente de \\(X_2\\) e que \\(X_1\\) é independente de \\(X_3\\)\nMostre que \\(X_2\\) e \\(X_3\\) não são independentes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Distribuição de vetores aleatórios discretos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_discretos.html#distribuição-condicional",
    "href": "vetores_aleatorios_discretos.html#distribuição-condicional",
    "title": "2  Distribuição de vetores aleatórios discretos",
    "section": "2.4 Distribuição condicional",
    "text": "2.4 Distribuição condicional\n\nDefinition 2.4 Sejam \\(\\textbf{X}\\) e \\(\\textbf{Y}\\) vetores aleatórios discretos. Então, a distribuição de probabilidade condicional de \\(\\textbf{X}\\) dado \\(\\textbf{Y=y}\\) é definida por\n\\[P(\\textbf{X}=\\textbf{x}|\\textbf{Y}=\\textbf{y})=\\frac{P(\\textbf{X}=\\textbf{x},\\textbf{Y}=\\textbf{y})}{P(\\textbf{Y}=\\textbf{y})},\\] e a respectiva função distribuição é dada por\n\\[F(\\textbf{x}|\\textbf{y})=P(\\textbf{X}\\leq \\textbf{x}|\\textbf{Y}=\\textbf{y}).\\]\n\n\nExample 2.5 Considere a seguinte distribuição conjunta:\n\\[P(X=x,Y=y)=\\left\\{\\begin{array}{ll}0,1,&x=0,y=0\\\\\n0,2,&x=0,y=1\\\\\n0,3,&x=1,y=0\\\\\n0,4,&x=1,y=1\\\\\n0,&\\hbox{caso contrário}\\end{array}\\right.\\]\nQual é a distribuição de \\(Y\\) dado \\(X=1\\)?\nSolução: Primeiro, temos que \\[P(X=1)=P(X=1,Y=0)+P(X=1,Y=1)=0,7\\] logo, \\[P(Y=y|X=1)=\\left\\{\\begin{array}{ll}\n\\frac{3}{7},&y=0\\\\\n\\frac{4}{7},&y=1\\\\\n0,&\\hbox{caso contrário}\\end{array}\\right.\\]\n\n\nExercise 2.8 Considere a variável aleatória bidimensional \\((X, Y)\\) com a seguinte função de probabilidade conjunta:\n\\[P(X=x, Y=y) = \\begin{cases}\nk, & x=1, y=1 \\\\\n2k, & x=1, y=2 \\\\\n3k, & x=2, y=1 \\\\\n4k, & x=2, y=2 \\\\\n0, & \\text{caso contrário}\n\\end{cases}\\]\n\nDetermine o valor da constante \\(k\\).\nCalcule a probabilidade marginal de \\(X\\), ou seja, \\(P(X=x)\\).\nEncontre a distribuição de probabilidade condicional de \\(X\\) dado que \\(Y=2\\).\n\n\n\nExercise 2.9 Considere a função de probabilidade abaixo: \\[P(X=x,Y=y)={y \\choose x}\\frac{1}{2^{2y}}\\] onde \\(x=0,\\ldots,y\\) e \\(y=1,2,\\ldots\\). Encontre a função de probabilidade de \\(X\\) dado \\(Y=y\\).\n\n\nExercise 2.10 Sejam\n\\[P(X=x|Y=y)={y\\choose x}\\frac{1}{2^y}\\] onde \\(x=0,\\ldots,y\\) e \\[P(Y=y)=\\frac{e^{−1}}{y!},\\] onde \\(y=0,1,\\ldots\\). Encontre a função de probabilidade de \\(Y\\) dado \\(X=x\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Distribuição de vetores aleatórios discretos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_discretos.html#funções-de-vetores-aleatórios-discretos",
    "href": "vetores_aleatorios_discretos.html#funções-de-vetores-aleatórios-discretos",
    "title": "2  Distribuição de vetores aleatórios discretos",
    "section": "2.5 Funções de vetores aleatórios discretos",
    "text": "2.5 Funções de vetores aleatórios discretos\nSeja \\(X\\) uma variável aleatória e seja \\(g(.)\\) uma função real. Considere a variável \\(Y=g(X)\\), com \\(g:\\mathbb{R}\\rightarrow \\mathbb{Z}\\). É sempre verdade que\n\\[P(Y\\in A)=P(g(X)\\in A)\\].\nSe \\(X\\) é uma variável discreta, então\n\\[P(Y\\in A)=\\sum_{x:g(x)\\in A}P(X=x).\\]\n\nExample 2.6 Seja \\(X\\) uma variável discreta com\n\\[P(X=x)=\\begin{cases}0,1,& x=-1\\\\ 0,2,& x=0,\\\\ 0,3,&x=1\\\\ 0,4,& x=2 \\end{cases}.\\] Vamos encontrar a função de probabilidade de \\(Y=X^2\\).\n\\[\\begin{array}{c|cccc}\\hline\nx&  -1 &    0&  1&  2& \\\\ \\hline\ny=x^2   &1  &0& 1&  4\\\\ \\hline\nP(X=x)  &0,1    &0,2    &0,3&   0,4\\\\\n\\hline \\end{array}\\]\nDeste modo,\n\\[\\begin{align}\nP(Y=0)&=P(X=0)=0,2\\\\\nP(Y=1)&=P(X=-1)+P(X=1)=0,4\\\\\nP(Y=4)&=P(X=2)=0,4\n\\end{align}\\]\n\n\nExercise 2.11 Seja \\(X\\) uma variável discreta com\\[P(X=x)=\\begin{cases}0,2,& x=-1\\\\ 0,1,& x=0,\\\\ 0,4,&x=1\\\\ 0,3,& x=2 \\end{cases}.\\] Encontre a função de probabilidade de \\(Y=|X|\\).\n\nObserve que a extensão é natural para vetores aleatórios. Seja \\(\\textbf{X}\\) um vetor aleatório discreto de comprimento \\(n\\) e seja \\(g:\\mathbb{R}^n\\rightarrow \\mathbb{Z}^m\\). Então a função de probabilidade de \\(\\textbf{Y}=g(\\textbf{X})\\) é dada por\n\\[P(\\textbf{Y}=\\textbf{y})=P(g(\\textbf{X})=\\textbf{y})=\\sum_{\\textbf{x}\\in\\mathbb{Z}^n:g(\\textbf{x})=\\textbf{y}}P(\\textbf{X}=\\textbf{x}).\\]\n\nExample 2.7 Seja \\(\\textbf{X}=(X_1,X_2)\\) um vetor aleatório com função de probabilidade conjunta dada por\n\\[P(\\textbf{X}=\\textbf{x})=\\frac{x_1+x_2}{12},\\] onde \\((x_1,x_2)\\in\\{1,2\\}^2\\). Vamos encontrar a função de probabilidade de \\(\\textbf{Y}=g(\\textbf{X})=(x_1,x_1+x_2).\\) Observe que\n\\[\\begin{array}{cc|cc}\nx_1 &x_2    &y_1 & y_2 \\\\ \\hline\n1   &1    & 1 & 2\\\\\n1   &2   & 1 & 3\\\\\n2   &1   & 2 & 3\\\\\n2   &2   & 2 & 4\\\\ \\hline\n\\end{array}\n\\] Então,\n\\[\\begin{align}\nP(\\textbf{Y}=(1,2))=P(\\textbf{X}=(1,1))=\\frac{2}{12}\\\\\nP(\\textbf{Y}=(1,3))=P(\\textbf{X}=(1,2))=\\frac{3}{12}\\\\\nP(\\textbf{Y}=(2,3))=P(\\textbf{X}=(2,1))=\\frac{3}{12}\\\\\nP(\\textbf{Y}=(2,4))=P(\\textbf{X}=(2,2))=\\frac{4}{12}\\\\\n\\end{align}\\]\n\n\nExercise 2.12 Seja \\(\\textbf{X}=(X_1,X_2)\\) um vetor aleatório com função de probabilidade conjunta dada por\\[P(\\textbf{X}=\\textbf{x})=\\frac{x_1+x_2}{12},\\] onde\\((x_1,x_2)\\in\\{1,2\\}^2\\). Encontre a função de probabilidade de\\(\\textbf{Y}=g(\\textbf{X})=(X_1-X_2, X_1+X_2).\\)\n\nAté o momento, utilizamos um vetor aleatório discreto de comprimento \\(n\\) para encontrar a distribuição de \\(\\textbf{Y}=g(\\textbf{X})\\), também de comprimento \\(n\\). Contudo, é comum ter \\(g:\\mathbb{R}^n\\rightarrow \\mathbb{Z}^m\\), onde \\(m&lt;n\\). Para o caso no qual \\(n=2\\) e \\(m=1\\), teremos\n\\[P(Y=y)=P(g(\\textbf{X})=y)=\\sum_{\\textbf{x}\\in\\mathbb{Z}^2:g(\\textbf{x})=y}P(X_1=x_1,X_2=x_2).\\] Sem perda de generalidade, assuma que para um dado \\(y\\), existe uma função \\(h\\) tal que a condição \\(g(x_1, x_2) = y\\) é equivalente a \\(x_1 = h(x_2, y)\\). Então \\[\\begin{align}P(Y=y)&=\\sum_{\\textbf{x}\\in\\mathbb{Z}^2:g(\\textbf{x})=y}P(X_1=h(x_2,y),X_2=x_2)\\\\&=\\sum_{x_2=-\\infty}^\\infty P(X_1=h(x_2,y),X_2=x_2).\\end{align}\\]\n\nProposition 2.2 Soma de variáveis aleatórias Seja \\(\\textbf{X}=(X_1,X_2)\\) um vetor aleatório discreto e considere da variável \\(Y=g(X_1,X_2)=X_1+X_2\\). Observe que é possível escrever \\[x_1=y-x_2=h(y,x_2),\\] logo \\[P(Y=y)=\\sum_{x_2=-\\infty}^\\infty P(X_1=y-x_2,X_2=x_2).\\]\n\n\nExample 2.8 A função de probabilidade de \\(\\textbf{X}=(X_1,X_2)\\) é dada na tabela abaixo:\n\\[\\begin{array}{c|cc}\\hline & x_1 \\\\  \nx_2 & -1 & 1 \\\\ \\hline\n0 & 0,10 & 0,05\\\\\n1 & 0,15 & 0,20\\\\\n2 & 0,25 & 0,25 \\\\ \\hline\\end{array}\\]\nA função de probabilidade de \\(Y=X_1+X_2\\) é dada por \\[\\begin{align}P(Y=y)&=\\sum_{x_2=0}^2 P(X_1=y-x_2,X_2=x_2)\\\\&=P(X_1=y,X_2=0)+P(X_1=y-1,X_2=1)+P(X_1=y-2,X_2=2)\\end{align}\\] Por exemplo, para \\(y=-1\\) teremos\n\\[\\begin{align}P(Y=-1)&=P(X_1=-1,X_2=0)+P(X_1=-2,X_2=1)+P(X_1=-3,X_2=2)\\\\&=P(X_1=-1,X_2=0)=0,1\\end{align}\\]\n\n\nExercise 2.13 Com base no exemplo anterior, determine os valores restantes da função de probabilidade de \\(Y\\).\n\n\n2.5.1 Alguns resultados importantes\n\n2.5.1.1 Funções indicadoras\nVamos discutir alguns resultados importantes sobre funções de vetores discretos. Contudo, é relevante a discussão de alguns resultados relacionados a funções indicadoras.\n\nFunção indicadora.Seja \\(A \\subset \\Omega\\). A função \\(I_A: \\Omega \\rightarrow \\{0,1\\}\\), definida por\\[I_A(x)=\\begin{cases} 1, & \\text{se } x \\in A \\\\ 0, & \\text{se } x \\notin A \\end{cases}\\]é denominada função indicadora do conjunto \\(A\\)\n\n\nIndicadora da interseção \\[I_{A\\cap B}(x)=I_A(x)I_B(x)\\]\n\n\nExample 2.9 Seja \\(A=\\{x\\in \\mathbb{N}:x \\leq 5 \\}\\) e \\(B=\\{x\\in\\mathbb{N}:x\\hbox{ é ímpar}\\}\\). É simples notar que os valores que satisfazem simultaneamente as restrições de \\(A\\) e \\(B\\) são 1, 3 e 5. Vamos chegar a essa conclusão utilizando indicadoras:\n\\[\\begin{array}{c|cccccc|ccc}\\hline\nx & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & \\cdots \\\\ \\hline\nI_A(x)& 1 & 1 & 1& 1 & 1 & 1 & 0 & 0 & \\cdots & \\\\\\hline\nI_B(x)& 0 & 1 & 0& 1 & 0 & 1 & 0 & 1 & \\cdots & \\\\\\hline\nI_{A\\cap B}(x)& 0 & 1 & 0& 1 & 0 & 1 & 0 & 0 & 0 & \\\\\\hline\\end{array}\\]\n\n\nExercise 2.14 Considere o conjunto universo \\(\\Omega = \\{0, 1, 2, 3, 4, 5, 6, 7\\}\\). Definimos dois subconjuntos de \\(\\Omega\\) através das seguintes propriedades:\\(A = \\{x \\in \\Omega : x \\text{ é múltiplo de 3}\\}\\)\\(B = \\{x \\in \\Omega : x^2 - 7x + 10 \\leq 0\\}\\)A) Liste os elementos de \\(A\\) e \\(B\\) e determine seus respectivos vetores indicadores \\(I_A(x)\\) e \\(I_B(x)\\) para todo \\(x \\in \\Omega\\).B) Utilizando a proposição \\(I_{A \\cap B}(x) = I_A(x)I_B(x)\\), complete a tabela abaixo para identificar os elementos da interseção:\n\\[\\begin{array}{c|cccccccc}\n\\hline\nx & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\\\ \\hline\nI_A(x) & & & & & & & & \\\\ \\hline\nI_B(x) & & & & & & & & \\\\ \\hline\nI_A(x)I_B(x) & & & & & & & & \\\\ \\hline\n\\end{array}\\]C) Com base no resultado da última linha da tabela, escreva o conjunto \\(A \\cap B\\) por extensão.\n\nAs funções indicadoras são úteis para definir para quais valores as probabilidades são positivas. Por exemplo, em vez que escrever\n\\[P(X=x)=p^x(1-p)^{1-x}\\] para \\(x\\in\\{0,1\\}\\), podemos escrever\n\\[P(X=x)=p^x(1-p)^{1-x}I_{\\{0,1\\}}(x).\\]\n\n\n2.5.1.2 O Método da Indução Matemática\nA demonstração por indução é uma ferramentada matemática para provar que uma afirmação é verdadeira para todos os números inteiros a partir de um valor inicial. O método divide-se em dois passos fundamentais:\n\nBase da Indução: Verificamos se a afirmação vale para o primeiro caso (geralmente \\(n=1\\)).\nPasso Indutivo: Assumimos que a afirmação vale para um número \\(k\\) (nossa Hipótese de Indução) e provamos que, a partir disso, ela obrigatoriamente vale para \\(k+1\\).\n\n\nExample 2.10 A Soma dos Primeiros Inteiros. Prove que, para todo \\(n \\geq 1\\):\\[1 + 2 + 3 + \\ldots + n = \\frac{n(n+1)}{2}\\]\nDemonstração:\n\nBase: Para \\(n=1\\):O lado esquerdo é \\(1\\). O lado direito é \\(\\frac{1(1+1)}{2} = 1\\). A base está verificada.\nHipótese de Indução (H.I.): Supomos que para um \\(k\\) qualquer a fórmula é válida:\\[S_k = 1 + 2 + \\ldots + k = \\frac{k(k+1)}{2}\\]\nPasso Indutivo: Queremos mostrar que a soma até \\(k+1\\) segue a mesma lógica. Note que a soma até \\(k+1\\) é a soma até \\(k\\) mais o próximo termo:\\[S_{k+1} = \\underbrace{1 + 2 + \\ldots + k}_{S_k} + (k+1)\\]Substituindo pela nossa H.I.:\\[S_{k+1} = \\frac{k(k+1)}{2} + (k+1)\\]Colocando em um denominador comum:\\[S_{k+1} = \\frac{k(k+1) + 2(k+1)}{2} = \\frac{(k+1)(k+2)}{2}\\]Como chegamos na fórmula original com \\(n\\) substituído por \\(k+1\\), a prova está concluída.\n\n\n\nExercise 2.15 Utilize o método da indução matemática para provar que a soma das primeiras \\(n\\) potências de 2 (começando em \\(2^1\\)) é dada por:\\[2^1 + 2^2 + 2^3 + \\ldots + 2^n = 2^{n+1} - 2\\]\n\n\n\n\n2.5.2 Distribuição Binomial como soma de Bernoullis independentes\n\nRecordando Dizemos que \\(X\\sim\\hbox{Bernoulli(p)}\\) se sua função de probabilidade é dada por\n\\[P(X=x)=p^{x}(1-p)^{1-x}I_{\\{0,1\\}}(x).\\]\nDizemos que \\(Y\\sim\\hbox{Binomial}(n,p)\\) se sua função de probabilidade é dada por\n\\[P(Y=y)={n\\choose y}p^{y}(1-p)^{n-y}I_{\\{0,\\ldots,n\\}}(y).\\]\n\n\nResultado chave: Para \\(0&lt;y&lt;n\\) natural, \\[{n-1\\choose y}+{n-1\\choose y-1}={n\\choose y}.\\]\n\nSejam \\(X_1\\) e \\(X_2\\) variáveis aleatórias independentes com distribuição Bernoulli(\\(p\\)). Vamos encontrar a função de probabilidade de \\(Y=X_1+X_2\\). Primeiro, já sabemos que\n\\[P(Y=y)=\\sum_{x_2=0}^1 P(X_1=y-x_2,X_2=x_2),\\] e, como \\(X_1\\) é independente de \\(X_2\\),\n\\[P(Y=y)=\\sum_{x_2=0}^1 P(X_1=y-x_2)P(X_2=x_2).\\] como \\(X_1\\) e \\(X_2\\) tem distribuição Bernoulli(\\(p\\)), teremos\n\\[\\begin{align}P(Y=y)&=\\sum_{x_2=0}^1 \\left[p^{y-x_2}(1-p)^{1-y+x_2} I_{\\{0,1\\}}(y-x_2)\\right]\\left[p^{x_2}(1-p)^{1-x_2}I_{\\{0,1\\}}(x_2)\\right]\\\\&=p^{y}(1-p)^{2-y}\\sum_{x_2=0}^1 I_{\\{0,1\\}}(x_2)I_{\\{0,1\\}}(y-x_2)\\end{align},\\]\nSabemos que \\(y\\in\\{0,1,2\\}\\). Vamos obter o valor de \\(\\sum_{x_2=0}^1 I_{\\{0,1\\}}(x_2)I_{\\{0,1\\}}(y-x_2)\\) para cada \\(y\\).\n\nse \\(y=0\\),\n\n\\[\\begin{array}{l|cc|c}\n\\hline\nx_2 & 0 & 1 &\\hbox{soma}\\\\ \\hline\nI_{\\{0,1\\}}(x_2) & 1& 1\\\\ \\hline\nI_{\\{0,1\\}}(y-x_2)& 1& 0 \\\\ \\hline\nI_{\\{0,1\\}}(x_2)I_{\\{0,1\\}}(y-x_2) & 1& 0 & 1\\\\ \\hline\n\\end{array}\\] logo, \\(\\sum_{x_2=0}^1 I_{\\{0,1\\}}(x_2)I_{\\{0,1\\}}(0-x_2)=1\\)\n\nse \\(y=1\\),\n\n\\[\\begin{array}{l|cc|c}\n\\hline\nx_2 & 0 & 1 &\\hbox{soma}\\\\ \\hline\nI_{\\{0,1\\}}(x_2) & 1& 1\\\\ \\hline\nI_{\\{0,1\\}}(y-x_2)& 1& 1 \\\\ \\hline\nI_{\\{0,1\\}}(x_2)I_{\\{0,1\\}}(y-x_2) & 1& 1 & 2\\\\ \\hline\n\\end{array}\\] logo, \\(\\sum_{x_2=0}^1 I_{\\{0,1\\}}(x_2)I_{\\{0,1\\}}(1-x_2)=2\\)\n\nse \\(y=2\\),\n\n\\[\\begin{array}{l|cc|c}\n\\hline\nx_2 & 0 & 1 & \\hbox{soma}\\\\ \\hline\nI_{\\{0,1\\}}(x_2) & 1& 1\\\\ \\hline\nI_{\\{0,1\\}}(y-x_2)& 0& 1 \\\\ \\hline\nI_{\\{0,1\\}}(x_2)I_{\\{0,1\\}}(y-x_2) & 0& 1 & 1\\\\ \\hline\n\\end{array}\\] logo, \\(\\sum_{x_2=0}^1 I_{\\{0,1\\}}(x_2)I_{\\{0,1\\}}(2-x_2)=1\\)\nAgora, note que\n\\[\\begin{array}{c|ccc}\\hline\ny & 0 & 1 & 2 \\\\ \\hline\n\\sum_{x_2=0}^1 I_{\\{0,1\\}}(x_2)I_{\\{0,1\\}}(y-x_2) & 1 & 2 & 1 \\\\ \\hline\n{2 \\choose y} &  1 & 2 & 1 \\\\ \\hline\n\\end{array}\\]\nlogo,\n\\[P(Y=y)={2\\choose y}p^y(1-p)^{2-y}I_{\\{0,1,2\\}}(y).\\]\n\nExercise 2.16 Sejam \\(X_1,X_2,X_3\\) variáveis aleatórias independentes com distribuição Bernoulli\\((p)\\). Mostre que a distribuição de \\(Y=X_1+X_2+X_3\\) é\n\\[P(Y=y)={3 \\choose y}p^{y}(1-p)^{3-y}I_{\\{0,1,2,3\\}}(y)\\] Dica: Você já sabe que \\(Z=X_1+X_2\\) é \\[P(Z=z)={2\\choose z}p^z (1-p)^{2-z}I_{\\{0,1,2\\}}(z),\\] e, como \\(Y=X_1+X_2+X_3=Z+X_3\\), basta encontrar \\[P(Y=y)=\\sum_{x_3=0}^1 P(Z=y-x_3,X_3=x_3).\\]\n\nObserve que \\(X_1+X_2\\sim\\hbox{Binomial}(2,p)\\) e \\(X_1+X_2+X_3\\sim\\hbox{Binomial}(3,p)\\). De fato, sejam \\(X_1,\\ldots,X_n\\) variáveis aleatórias independentes com distribuição Bernoulli(\\(p\\)). Suponha, por indução, que\n\\[Z=\\sum_{i=1}^{n-1} X_i\\sim\\hbox{Binomial}(n-1,p).\\] Então \\[Y=\\sum_{i=1}^n X_i=X_n+Z\\] e\n\\[\\begin{align}\nP(Y=y)&=\\sum_{x=0}^1 P(X_n=x, Z=y-x)=\\sum_{x=0}^1 P(X_n=x)P(Z=y-x)\\\\\n&=\\sum_{x=0}^1 P(X_n=x)P(Z=y-x)\\\\&=\\sum_{x=0}^1 \\left[p^x(1-p)^{1-x}I_{\\{0,1\\}}(x)\\right]\\left[{n-1\\choose y-x}p^{y-x}(1-p)^{n-1-y+x}I_{\\{0,\\ldots,n-1\\}}(y-x)\\right]\\\\\n&=p^y(1-p)^{n-y}\\sum_{x=0}^1\\left[{n-1\\choose y-x}I_{\\{0,1\\}}(x)I_{\\{0,\\ldots,n-1\\}}(y-x)\\right].\n\\end{align}\\]\nVamos analizar o somatório acima:\n\nse \\(y=0\\), teremos que \\(I_{\\{0,\\ldots,n-1\\}}(0-x)=1\\) somente quando \\(x=0\\). Logo,\n\n\\[\\sum_{x=0}^1\\left[{n-1\\choose y-x}I_{\\{0,1\\}}(x)I_{\\{0,\\ldots,n-1\\}}(0-x)\\right]={n-1\\choose 0}=1={n\\choose 0}\\]\n\nse \\(y=n\\), teremos que \\(I_{\\{0,\\ldots,n-1\\}}(n-x)=1\\) somente quando \\(x=1\\). Logo,\n\n\\[\\sum_{x=0}^1\\left[{n-1\\choose y-x}I_{\\{0,1\\}}(x)I_{\\{0,\\ldots,n-1\\}}(n-x)\\right]={n-1\\choose n-1}=1={n\\choose n}\\] * para \\(y=1,\\ldots,n-1\\), teremos que \\(I_{\\{0,\\ldots,n-1\\}}(y-x)=1\\) para \\(x=0,1\\). Logo,\n\\[\\sum_{x=0}^1\\left[{n-1\\choose y-x}I_{\\{0,1\\}}(x)I_{\\{0,\\ldots,n-1\\}}(y-x)\\right]={n-1\\choose y}+{n-1\\choose y-1}={n\\choose y}\\]\nportanto,\n\\[\\begin{align}\nP(Y=y)&=p^y(1-p)^{n-y}\\sum_{x=0}^1\\left[{n-1\\choose y-x}I_{\\{0,1\\}}(x)I_{\\{0,\\ldots,n-1\\}}(y-x)\\right]\\\\&={n\\choose y}p^y(1-p)^{n-y}I_{\\{0,\\ldots,n\\}}(y).\n\\end{align}\\]\n\nExercise 2.17 Sejam \\(X_1,X_2\\) variáveis aleatórias independentes, onde \\(X_i\\sim\\hbox{Binomial}(m_i,p),\\) com \\(i=1,2\\).\n\nMostre que \\(Y=X_1+X_2\\sim\\hbox{Binomial}(m_1+m_2,p)\\). Sugestão: escreva \\(X_i\\) como soma de Bernoullis independentes.\nE qual a distribuição de \\(Z=X_1+\\cdots+X_n\\), onde \\(X_i\\sim\\hbox{Binomial}(m_i,p)\\) e \\(X_1,\\ldots,X_n\\) são independentes?\n\n\n\n\n2.5.3 Soma de Poissons independentes\n\nRecordando Dizemos que \\(X\\sim\\hbox{Poisson}(\\lambda)\\) se sua função de probabilidade é dada por\n\\[P(X=x)=\\frac{e^{-\\lambda}\\lambda^x}{x!}I_{\\mathbb{N}}(x)\\] e \\(\\lambda&gt;0\\).\nResultado chave (Teorema binomial): Para quaisquer \\(a,b\\), \\[\\sum_{x=0}^n{ n\\choose x}a^x b^{n-x}=(a+b)^n.\\]\n\nSejam \\(X_1,X_2\\) variáveis aleatórias independentes com distribuição \\(\\hbox{Poisson}(\\lambda)\\). Seja \\(Y=X_1+X_2\\). Note que\n\\[\\begin{align}P(Y=y)&=\\sum_{x_2=0}^\\infty P(X_1=y-x_2,X_2=x_2)\n\\\\&=\\sum_{x_2=0}^\\infty \\frac{e^{-\\lambda}\\lambda^{y-x_2}}{(y-x_2)!}I_{\\mathbb{N}}(y-x_2)\\frac{e^{-\\lambda}\\lambda^{x_2}}{x_2!}I_{\\mathbb{N}}(x_2)\\\\\n&=e^{-2\\lambda}\\lambda^{y}\\sum_{x_2=0}^\\infty \\frac{1}{x_2!(y-x_2)!}I_{\\mathbb{N}}(y-x_2)I_\\mathbb{N}(x_2).\n\\end{align}\\] Para que \\(I_\\mathbb{N}(y-x_2)=1\\), é necessário que \\(x_2\\leq y\\). Logo, \\[\\begin{align}P(Y=y)&=e^{-2\\lambda}\\lambda^{y}\\sum_{x_2=0}^{y} \\frac{1}{x_2!(y-x_2)!}\\\\\n&=\\frac{e^{-2\\lambda}\\lambda^{y}}{y!}\\sum_{x_2=0}^{y} \\frac{y!}{x_2!(y-x_2)!}=\\frac{e^{-2\\lambda}\\lambda^{y}}{y!}\\sum_{x_2=0}^y{ y\\choose x_2}.\n\\end{align}\\]\nAgora, observe que\n\\[\\sum_{x_2=0}^y{ y\\choose x_2}=\\sum_{x_2=0}^y{ y\\choose x_2}1^{x_2}1^{y-x_2}=(1+1)^y=2^y,\\] portanto, \\[\\begin{align}P(Y=y)&=\\frac{e^{-2\\lambda}\\lambda^y}{y!}2^y=\\frac{e^{-2\\lambda}(2\\lambda)^y}{y!}.\n\\end{align}\\]\nIsso implica que \\(X_1+X_2\\sim\\hbox{Poisson}(2\\lambda)\\).\n\nExercise 2.18 Sejam \\(X_1\\) e \\(X_2\\) variáveis aleatórias independentes com \\(X_1\\sim\\hbox{Poisson}(\\lambda_1)\\) e \\(x_2\\sim\\hbox{Poisson}(\\lambda_2)\\).\n\nMostre que \\(X_1+X_2\\sim\\hbox{Poisson}(\\lambda_1+\\lambda_2)\\)\nCom base nesse resultado, qual é a distribuição de \\(\\sum_{i=1}^n X_i\\) quando as variáveis são independentes com \\(X_i\\sim\\hbox{Poisson}(\\lambda_i)\\)?\n\n\n\nExercise 2.19 Sejam \\(X_1\\) e \\(X_2\\) variáveis aleatórias independentes com \\(X_1\\sim\\hbox{Poisson}(\\lambda_1)\\) e \\(x_2\\sim\\hbox{Poisson}(\\lambda_2)\\). Encontre\n\\[P(X_1=x|X_1+X_2=n).\\]\n\n\n\n2.5.4 Distribuição binomial negativa como soma de distribuições geométricas independentes\n\nRecordando Dizemos que \\(X\\sim\\hbox{Geométrica}(p)\\) se sua função de probabilidade é dada por \\[P(X=x)=p(1-p)^x I_{\\mathbb{N}}(x)\\] e dizemos que \\(Y\\sim\\hbox{Binomial Negativa}(n,p)\\) se sua função de probabilidade é dada por \\[P(Y=y)={y+n-1\\choose y}p^n(1-p)^y I_{\\mathbb{N}}(y).\\]\n\n\nResultado relevante: para \\(t&gt;0\\),\n\\[\\sum_{j=0}^m{m+t-j\\choose m-j}={m+t+1\\choose m}\\]\n\n\nExercise 2.20 Sejam \\(X_1,X_2\\) variáveis aleatórias independentes com distribuição Geométrica\\((p)\\). Mostre que \\(Y=X_1+X_2\\sim\\hbox{Binomial Negativa}(2,p)\\)\n\n\nExercise 2.21 Sejam \\(X_1,X_2,X_3\\) variáveis aleatórias independentes com distribuição Geométrica\\((p)\\). Mostre que \\(Y=X_1+X_2+X_3\\sim\\hbox{Binomial Negativa}(3,p)\\)\n\n\nExercise 2.22 Sejam \\(X_1,X_2,\\ldots,X_n\\) variáveis aleatórias independentes com distribuição Geométrica\\((p)\\). Mostre que \\(Y=\\sum_{i=1}^nX_i\\sim\\hbox{Binomial Negativa}(n,p)\\). Especificamente, suponha por indução que\n\\[Z=\\sum_{i=1}^{n-1}X_i\\sim\\hbox{Binomial Negativa}(n-1,p).\\] Então, conclua o exercício encontrando a distribuição de \\(Y=Z+X_n\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Distribuição de vetores aleatórios discretos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_continuos.html",
    "href": "vetores_aleatorios_continuos.html",
    "title": "3  Distribuição de vetores aleatórios contínuos",
    "section": "",
    "text": "3.1 Função de densidade conjunta\nOs objetivos deste capítulo são:\nSeja \\(\\textbf{X}=(X_1,…,X_n)\\) um vetor de variáveis aleatórias absolutamente contínuas. Dizemos que a função contínua\n\\[f(\\textbf{x})=f(x_1,…,x_n)\\] é a função de densidade conjunta de \\(\\textbf{X}\\) se\n\\[P(X_1\\in A_1,\\ldots,X_n\\in A_n)=\\int_{A_1}\\cdots\\int_{A_n}f(\\textbf{x})d\\textbf{x}.\\]\n::: {.alert -alert-success} Nota importante Observe que \\[P(\\textbf{X}\\in A)=\\int_{A}f(\\textbf{x})d\\textbf{x}=\\int_{\\mathbb{R}^n}f(\\textbf{x})I_{A}(\\textbf{x})d\\textbf{x}.\\]\nEm palavras, o conjunto da função indicadora é sempre o conjunto de integração. :::",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distribuição de vetores aleatórios contínuos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_continuos.html#função-de-densidade-conjunta",
    "href": "vetores_aleatorios_continuos.html#função-de-densidade-conjunta",
    "title": "3  Distribuição de vetores aleatórios contínuos",
    "section": "",
    "text": "Proposition 3.1 Dizemos que \\(f(\\textbf{x})\\) (contínua) é a função de densidade conjunta para um vetor aleatório \\(\\textbf{X}\\) se\n\\[f(\\textbf{x})\\geq 0,\\;\\;\\forall\\;\\textbf{x}\\in\\mathbb{R}^n\\] e \\[\\int_{\\mathbb{R}^n}f(\\textbf{x})d\\textbf{x}=1.\\]\n\n\n\n\nExample 3.1 Mostre que \\[f(x,y)=xe^{−(1+y)x},\\] com \\(x,y&gt;0\\) é uma função de densidade conjunta.\nSolução. Note que \\(x&gt;0\\), logo \\(f(x,y)&gt;0\\) para todo \\((x,y)&gt;0\\). Portanto, basta mostrar que\n\\[\\int_{\\mathbb{R}^2} f(x,y)dxdy=\\int_{\\mathbb{R}^2}xe^{-(1+y)x}I_{\\mathbb{R}^+}(x)I_{\\mathbb{R}^+}(y)dxdy=\\int_0^\\infty\\int_0^\\infty xe^{-(1+y)x}dxdy=1\\]\nRecorde que, para \\(a,b&gt;0\\), \\[\\int_0^\\infty u^{a-1}e^{-bu}du=\\frac{\\Gamma(a)}{b^a}.\\]\nPortanto, considerando apenas a integral em \\(x\\), teremos\n\\[\\int_0^\\infty xe^{-x(1+y)}dx=\\frac{\\Gamma(2)}{(1+y)^2}=\\frac{1!}{(1+y)^2}=\\frac{1}{(1+y)^2}.\\] Então, \\[\\int_0^\\infty\\int_0^\\infty xe^{-(1+y)x}dxdy=\\int_0^\\infty \\frac{1}{(1+y)^2}dy\\]\nA integral da direita pode ser resolvida por integração por substituição. Fazendo \\(u=1+y\\), teremos e \\(du=dy\\) e\n\\[\\int_0^\\infty \\frac{1}{(1+y)^2}dy=\\int_1^\\infty \\frac{1}{u^2}du=\\left.-\\frac{1}{u}\\right|_1^\\infty=1.\\] Portanto, a função dada é uma densidade conjunta.\n\n\nExercise 3.1 Mostre que \\[f(x,y)=x^2e^{−(1+y)x},\\] com \\(x,y&gt;0\\) é uma função de densidade conjunta.\n\n\nExample 3.2 Seja \\[f(x,y)=kx^2,\\] onde \\(x\\in(0,1)\\) e \\(y\\in(0,x)\\). Encontre o valor de \\(k\\) para que \\(f(x,y)\\) seja uma função densidade.\nSolução. Como \\(x&gt;0\\), temos que \\(f(x,y)&gt;0\\) sempre que \\(k&gt;0\\). Portanto, basta encontrar o valor \\(k&gt;0\\) tal que\n\\[\\int_{\\mathbb{R}^2}f(x,y)dxdy=\\int_{\\mathbb{R}^2}kx^2 I_{(0,1)}(x)I_{(0,x)}(y)dxdy=\\int_0^1\\int_0^x kx^2 dydx=1\\]\nA integral em \\(y\\) é\n\\[\\int_0^x kx^2 dy=\\left.kx^2y\\right|_0^x=kx^3\\] logo, \\[\\int_0^1\\int_0^x kx^2 dydx=\\int_0^1 kx^3dx=\\left.\\frac{k}{4}x^4\\right|_0^1=\\frac{k}{4}.\\] Portanto, \\(f(x,y)\\) será função densidade conjunta quando \\(k=4\\).\n\n\nExercise 3.2 Seja \\[f(x,y)=k yx^2,\\] onde \\(x\\in(0,1)\\) e \\(y\\in(0,x)\\). Encontre o valor de \\(k\\) para que \\(f(x,y)\\) seja uma função densidade.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distribuição de vetores aleatórios contínuos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_continuos.html#função-de-distribuição-conjunta",
    "href": "vetores_aleatorios_continuos.html#função-de-distribuição-conjunta",
    "title": "3  Distribuição de vetores aleatórios contínuos",
    "section": "3.2 Função de distribuição conjunta",
    "text": "3.2 Função de distribuição conjunta\nComo vimos no capítulo anterior, \\[F(\\textbf{x})=P(\\textbf{x}\\leq \\textbf{x})=P(X_1\\leq x_1,\\ldots,X_n\\leq x_n),\\] é denominada função de distribuição conjunta (ou ainda função de distribuição multivariada).\n\nProposition 3.2 A função de distribuição de um vetor de variáveis aleatórias contínuas é dada por \\[F(\\textbf{x})=\\int_{-\\infty}^{x_1}\\cdots\\int_{-\\infty}^{x_n}f(y_1,\\ldots,y_n)d\\textbf{y}.\\]\n\n::: {.alert -alert-success} Nota importante Recorde que \\[I_{A\\cap B}(\\textbf{x})=I_{A}(\\textbf{x})I_{B}(\\textbf{x}).\\] Em particular, sejam \\(A\\) e \\(B\\) os intervalos \\((a_1,a_2)\\) e \\((b_1,b_2)\\). Então\n\\[I_{A\\cap B}(x)=I_{(a_1,a_2)}(x)I_{(b_1,b_2)}(x)=I_{(\\max\\{a_1,b_1\\},\\min\\{a_2,b_2\\})}(x).\\] :::\n\nExample 3.3 Encontre a função distribuição do vetor \\((X,Y)\\) cuja função de densidade conjunta é\n\\[f(x,y)=2xI_{(0,1)}(x)I_{(0,1)}(y).\\] Solução.\n\\[\\begin{align}F(u,v)&=\\int_{-\\infty}^u\\int_{-\\infty}^v f(x,y)dydx=\\int_{-\\infty}^u\\int_{-\\infty}^v 2xI_{(0,1)}(x)I_{(0,1)}(y)dydx\\end{align}\\] Considerando que \\(u,v\\in(0,1)\\), teremos\n\\[\\begin{align}I_{(-\\infty,u)}(x)I_{(0,1)}(x)I_{(-\\infty,v)}(y)I_{(0,1)}(y)&=I_{(0,u)}(x)I_{(0,v)}(y),\\end{align}\\] logo\n\\[\\begin{align}F(u,v)&=\\int_{0}^u\\int_{0}^v 2xI_{(0,1)}(x)I_{(0,1)}(y)dydx\\end{align}\\] A integral em \\(y\\) é \\[\\int_0^{v}2xdy=2x\\left.y\\right|_{0}^{v}=v\\] logo, \\[F(u,v)=2v\\int_0^{u}xdx=2v\\left.\\frac{x^2}{2}\\right|_0^u=vu^2\\] para \\(u,v\\in(0,1)\\).\n\n\nExercise 3.3 Encontre a função de distribuição conjunta a partir da densidade conjunta abaixo:\n\\[f(x,y)=\\frac{3}{80}(x^2+xy)\\], com \\(0&lt;x&lt;2\\) e \\(0&lt;y&lt;4\\).\n\n\nExample 3.4 Considere o vetor aleatório com função densidade conjunta dada por \\[f(x,y)=e^{-y}I_{(0,\\infty)}(x)I_{(x,\\infty)}(y).\\] Encontre a função de distribuição conjunta.\n\\[\\begin{align}F(u,v)&=\\int_{-\\infty}^u\\int_{-\\infty}^v f(x,y)dydx=\\int_{-\\infty}^u\\int_{-\\infty}^v e^{-y}I_{(0,\\infty)}(x)I_{(x,\\infty)}(y)dydx\\end{align}\\] Note que \\[\\begin{align}I_{(-\\infty,u)}(x)I_{(0,\\infty)}(x)I_{(-\\infty,v)}(y)I_{(x,\\infty)}(y)&=I_{(0,u)}(x)I_{(x,v)}(y),\\end{align}\\] logo \\[\\begin{align}F(u,v)&=\\int_{0}^u\\int_{x}^v e^{-y}dydx\\end{align}\\] A integral em \\(y\\) é \\[\\int_x^{v}e^{-y}dy=\\left.-e^{-y}\\right|_{x}^{v}=e^{-x}-e^{-v}\\] logo, para \\(u&lt;v\\), \\[F(u,v)=\\int_0^{u}e^{-x}-e^{-v}dx=\\left[\\left.-e^{-x}\\right|_0^u\\right]-ue^{-v}=1-e^{-u}-ue^{-v}.\\]\n\n\nExercise 3.4 Seja a função densidade conjunta:\\[f(x, y) =\\frac{3}{2}I_{(-1,1)}(x)I_{(x^2,1)}(y).\\] Encontre a função de distribuição.\n\n::: ::: {#prp-} Se \\(\\textbf{X}\\) é um vetor aleatório comprimento \\(n\\), então\n\\[f(\\textbf{x})=\\frac{\\partial}{\\partial x_1}\\cdots \\frac{\\partial}{\\partial x_n} F(\\textbf{x}).\\]\n:::\n\nExercise 3.5 Seja\n\\[F(x,y)=1−e^{−x}−e^{−y}+e^{-(x+y)},\\] com \\((x,y)\\in\\mathbb{R}^2_+\\). Encontre a densidade conjunta correspondente.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distribuição de vetores aleatórios contínuos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_continuos.html#distribuições-marginais",
    "href": "vetores_aleatorios_continuos.html#distribuições-marginais",
    "title": "3  Distribuição de vetores aleatórios contínuos",
    "section": "3.3 Distribuições Marginais",
    "text": "3.3 Distribuições Marginais\nSeja \\(\\textbf{X}\\) um vetor aleatório de dimensão \\(n\\). A distribuição de uma coordenada qualquer de \\(\\textbf{X}\\) é denominada distribuição marginal.\nComo em geral utilizamos as letras \\(F\\), \\(P\\) e \\(f\\) para designar as funções de distribuição, probabilidade e densidade, é importante acrescentar uma notação que identifique explicitamente a variável. Quando isto for necessário, adicionaremos a letra que designa a variável subscrita na função. Por exemplo, \\(F_{X_1}(x)\\) é a função de distribuição marginal de \\(X_1\\).\n\nProposition 3.3 Seja \\(\\textbf{X}=(\\textbf{X}_a,\\textbf{X}_b)\\) um vetor de variáveis aleatórias contínuas. A função de densidade marginal do subvetor \\(\\textbf{X}_a\\) é dada por \\[f_{\\textbf{X}_a}(\\textbf{x}_a)=\\int f(\\textbf{x})d\\textbf{x}_{b}.\\]\n\n\nExample 3.5 Seja \\((X,Y)\\) um par de variáveis aleatórias com densidade conjunta dada por \\[f(x,y)=8xyI_{(0,y)}(x)I_{(0,1)}(y),\\] Determine as densidades marginais de \\(X\\) e \\(Y\\).\nSolução A densidade marginal de \\(Y\\) é\n\\[\\begin{align}f_Y(y)&=\\int_{\\mathbb{R}}f(x,y)dx=8yI_{(0,1)}(y)\\int_\\mathbb{R} I_{(0,y)}(x)xdx\\\\&=8yI_{(0,1)}(y)\\int_0^y xdx=8yI_{(0,1)}(y)\\left.\\frac{x^2}{2}\\right|_0^y=4y^3I_{(0,1)}(y).\\end{align}\\]\nPara determinar a marginal de \\(X\\), observe que\n\\[I_{(0,y)}(x)I_{(0,1)}(y)=1\\Rightarrow 0&lt;x&lt;y\\hbox{ e } 0&lt;y&lt;1\\] note que o primeiro intervalo possui informações tanto sobre \\(x\\) quanto sobre \\(y\\). Olhando apenas como função de \\(y\\), podemos escrever a seguinte indicadora para o primeira intervalo: \\(I_{(x,\\infty)}(y)\\). Deste modo,\n\\[I_{(0,y)}(x)I_{(0,1)}(y)=I_{(x,\\infty)}(y)I_{(0,1)}(y)=I_{(x,1)}(y)I_{(0,1)}(x),\\] logo \\[f_X(x)=\\int_x^1 f(x,y)dx=8xI_{(0,1)}(x)\\left.\\frac{y^2}{2}\\right|_{x}^1=4x(1-x^2)I_{(0,1)}(x).\\]\n\n\nExercise 3.6 Seja a função densidade conjunta:\\[f(x, y) =\\frac{3}{2}I_{(-1,1)}(x)I_{(x^2,1)}(y).\\] Encontre as densidades marginais de \\(X\\) e \\(Y\\).\n\n\nExercise 3.7 Considere a seguinte função de densidade conjunta, \\[f(x,y)=xy^2e^{−y(x+1)}.\\] onde \\(x,y&gt;0\\). Encontre a função densidade marginal de \\(X\\) e \\(Y\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distribuição de vetores aleatórios contínuos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_continuos.html#distribuição-condicional",
    "href": "vetores_aleatorios_continuos.html#distribuição-condicional",
    "title": "3  Distribuição de vetores aleatórios contínuos",
    "section": "3.4 Distribuição condicional",
    "text": "3.4 Distribuição condicional\nSejam \\(\\textbf{X}\\) e \\(\\textbf{Y}\\) vetores aleatórios contínuos. Sabemos que\n\\[P(\\textbf{X}\\leq \\textbf{x}|\\textbf{Y}\\in B)=\\frac{P(\\textbf{X}\\leq\\textbf{x},\\textbf{Y}\\in B)}{P(\\textbf{Y}\\in B)}.\\]\nComo \\(\\textbf{Y}\\) é um vetor de variáveis aleatórias contínuas, sabemos que \\(P(\\textbf{Y}=\\textbf{y})=0\\). Entretanto, a probabilidade \\(P(\\textbf{X}\\leq \\textbf{x}|\\textbf{Y}=\\textbf{y})\\) faz todo o sentido. Para mostrar este fato, seja \\(B(\\varepsilon)\\) uma bola fechada de raio \\(\\varepsilon\\) e centro \\(\\textbf{y}\\). Pelo Teorema do Valor Médio, existe \\(\\tilde{y}\\in B(\\varepsilon)\\) tal que\n\\[P(\\textbf{Y}\\in B(\\varepsilon) )=\\int_{B(\\varepsilon)} f_{\\textbf{Y}}(\\textbf{u})d\\textbf{u}=\\hbox{Vol}(B(\\varepsilon))f_{\\textbf{Y}}(\\tilde{\\textbf{y}})\\] e\n\\[P(\\textbf{X}\\leq \\textbf{x},\\textbf{Y}\\in B(\\varepsilon) )=\\int_{\\textbf{v}\\leq \\textbf{x}}\\int_{B(\\varepsilon)} f_{\\textbf{X},\\textbf{Y}}(\\textbf{v},\\textbf{u})d\\textbf{u}d\\textbf{v}=\\hbox{Vol}(B(\\varepsilon))\\int_{\\textbf{v}\\leq \\textbf{x}}f_{\\textbf{X},\\textbf{Y}}(\\textbf{v},\\tilde{\\textbf{y}}_{\\textbf{v}})d\\textbf{v}.\\] Portanto,\n\\[P(\\textbf{X}\\leq \\textbf{x}|\\textbf{Y}\\in B(\\varepsilon) )=\\frac{\\hbox{Vol}(B(\\varepsilon))\\int_{\\textbf{v}\\leq \\textbf{x}}f_{\\textbf{X},\\textbf{Y}}(\\textbf{v},\\tilde{\\textbf{y}})d\\textbf{v}}{\\hbox{Vol}(B(\\varepsilon))f_{\\textbf{Y}}(\\tilde{\\textbf{y}})}=\\int_{\\textbf{v}\\leq \\textbf{x}}\\frac{f_{\\textbf{X},\\textbf{Y}}(\\textbf{v},\\tilde{\\textbf{y}}_{\\textbf{v}})}{f_{\\textbf{Y}}(\\tilde{\\textbf{y}})}d\\textbf{v}.\\] Agora, note que \\(B(\\varepsilon)\\rightarrow\\textbf{y}\\) quando \\(\\varepsilon\\rightarrow0\\), logo \\(\\tilde{\\textbf{y}}\\rightarrow\\textbf{y}\\) e \\(\\tilde{\\textbf{y}}_{\\textbf{v}}\\rightarrow\\textbf{y}\\) para todo \\(\\textbf{v}\\), o que implica em\n\\[\\lim_{\\varepsilon\\rightarrow 0}P(\\textbf{X}\\leq \\textbf{x}|\\textbf{Y}\\in B(\\varepsilon) )=P(\\textbf{X}\\leq \\textbf{x}|\\textbf{Y}= \\textbf{y})=F(\\textbf{x}|\\textbf{y})=\\int_{\\textbf{v}\\leq \\textbf{x}}\\frac{f_{\\textbf{X},\\textbf{Y}}(\\textbf{v},{\\textbf{y}})}{f_{\\textbf{Y}}({\\textbf{y}})}d\\textbf{v}.\\] o que implica em\n\\[f(\\textbf{x}|\\textbf{y})=\\frac{f_{\\textbf{X},\\textbf{Y}}(\\textbf{x},\\textbf{y})}{f_{\\textbf{Y}}(\\textbf{y})}.\\]\n\nExample 3.6 Seja \\[f(x,y)=21x^2y^3,\\] se \\(0&lt;x&lt;y&lt;1\\). Encontre a densidade condicional de \\(Y|X=x\\).\nSolução.\nPrimeiro, vamos encontrar a densidade marginal de \\(X\\):\n\\[f(x)=21x^2\\int_x^1 y^3dy=\\frac{21}{4}x^2(1-x^4),\\]\npara \\(x\\in(0,1)\\). Portanto,\n\\[f(y|x)=\\frac{f(x,y)}{f(x)}=\\frac{21x^2y^3}{\\frac{21}{4}x^2(1-x^4)}=\\frac{4y^3}{(1-x^4)},\\] com \\(0&lt;x&lt;y&lt;1\\).\n\n\nExercise 3.8 Suponha que\n\\[f(x,y)=\\frac{1}{2\\pi}\\exp\\left\\{−\\frac{1}{2}(x^2+2y^2−2xy)\\right\\},\\] com \\((x,y)\\in\\mathbb{R}^2\\). Encontre a densidade de \\(X|Y=y\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distribuição de vetores aleatórios contínuos</span>"
    ]
  },
  {
    "objectID": "vetores_aleatorios_continuos.html#função-de-vetores-aleatórios-contínuos",
    "href": "vetores_aleatorios_continuos.html#função-de-vetores-aleatórios-contínuos",
    "title": "3  Distribuição de vetores aleatórios contínuos",
    "section": "3.5 Função de vetores aleatórios contínuos",
    "text": "3.5 Função de vetores aleatórios contínuos\nSuponha que \\(X\\) é uma variável aleatória contínua e \\(g(.)\\) uma função real e contínua. Considerando a variável aleatória \\(Y=g(X)\\), teremos que\n\\[P(Y\\in A)=P(g(X)\\in A)=\\int_{x:g(x)\\in A}f_X(x)dx.\\]\nEm particular,\n\\[F_Y(y)=P(Y\\leq y)=P(g(X)\\leq y)=\\int_{x:g(x)\\leq y}f_X(x)dx.\\]\nAgora, suponha \\(g(.)\\) possui inversa. Então, podemos utilizar o método integral por substituição. Fazendo \\(u=g(x)\\), teremos que \\(x=g^{−1}(u)\\) e \\(dx=\\frac{d}{du}g^{−1}(u)du\\). Além disso,\n\\[\\{x:g(x)\\leq y\\}\\equiv\\{u\\leq y\\},\\] o que implica em\n\\[F_Y(y)=\\int_{-\\infty}^y f_X(g^{−1}(u))\\left|\\frac{d}{du}g^{−1}(u)\\right|du\\] logo, \\[f_Y(y)=f_X(g^{−1}(y))\\left|\\frac{d}{dy}g^{−1}(y)\\right|.\\] O termo dentro do módulo é denominado Jacobiano da transformação e a obtenção da densidade por esse método é denominada método do Jacobiano.\n\nExample 3.7 Suponha que \\(X\\sim\\hbox{Normal}(0,1)\\). Considere a transformação \\(Y=e^{X}\\). Como \\(g^{-1}(y)=\\log(y)\\), teremos que\n\\[f_Y(y)=f_X(\\log y )\\left|\\frac{d}{dy}\\log y\\right|=\\frac{1}{y\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\log y^2}.\\] Essa distribuição é denominada Lognormal(0,1).\n\nAssim como no caso discreto, a extensão para vetores também é natural. Seja \\(\\textbf{X}\\) um vetor aleatório de comprimento \\(n\\) e considere a nova variável \\(\\textbf{Y}=g(X)\\), onde \\(g:\\mathbb{R}^n\\rightarrow \\mathbb{R}^m\\) é uma função real. Então\n\\[P(\\textbf{Y}\\in A)=P(g(\\textbf{X})\\in A)=\\int_{\\{\\textbf{x}:g(\\textbf{x})\\in A\\}}f_\\textbf{X}(\\textbf{x})d\\textbf{x}.\\]\nAgora, suponha que \\(g(.)\\) possui inversa (o que implica que \\(g:\\mathbb{R}^n\\rightarrow \\mathbb{R}^n\\)). Então, pelo método da integral por substituição, teremos que \\(\\textbf{u}=g^{-1}(\\textbf{y})\\), \\(d\\textbf{x}=|\\mathcal{J}g^{-1}(\\textbf{u})|d\\textbf{u}\\) e \\(\\{\\textbf{x}:g(\\textbf{x})\\in A\\}=\\{\\textbf{u}\\in A\\}\\), o que implica em\n\\[P(\\textbf{Y}\\in A)=\\int_{A}f_\\textbf{X}(g^{-1}(\\textbf{u})|\\mathcal{J}g^{-1}(\\textbf{u})|d\\textbf{u}.\\]\nonde \\(\\mathcal{J}g^{-1}(\\textbf{u})\\) é denominada matriz Jacobiana, cujo o elemento \\((i,j)\\) é dado por \\[\\frac{\\partial^2}{\\partial u_i\\partial u_j}g^{-1}(\\textbf{u}).\\]\nEm particular, teremos que\n\\[F_{\\textbf{Y}}(\\textbf{y})=\\int_{-\\infty}^{y_1}\\cdots \\int_{-\\infty}^{y_n}f_\\textbf{X}(g^{-1}(\\textbf{u}))|\\mathcal{J}g^{-1}(\\textbf{u})|d\\textbf{u}.\\]\nPortanto, concluímos que \\[f_\\textbf{Y}(\\textbf{y})=f_\\textbf{X}(g^{−1}(\\textbf{y}))|\\mathcal{J}g^{-1}(\\textbf{y})|.\\]\n\nExample 3.8 Sejam \\(X_1\\) e \\(X_2\\) variáveis aleatórias independentes com distribuição Normal(0,1). Vamos encontrar a função densidade conjunta de \\(\\textbf{Y}=(X_1+X_2,Y2=X_1−X_2)\\).\nPrimeiro, temos que encontrar a função inversa:\n\\[\\begin{array}{c}\nY_1=X_1+X_2\\\\\nY_2=X_1-X_2\\\\\n\\end{array} \\Leftrightarrow \\begin{array}{c}X_1=0,5(Y_1+Y_2)\\\\ X_2=0,5(Y_1-Y_2)\\end{array}\\]\ne o Jacobiano da transformação é dado por\n\\[\\mathcal{J}g^{-1}(\\textbf{y})=\\left[\\begin{array}{cc} 0,5 & 0,5 \\\\ 0,5 & - 0,5 \\end{array}\\right],\\]\ncujo determinante é igual a 1/2. Logo,\n\\[\\begin{align}f_\\textbf{Y}(\\textbf{y})&=f_{X_1}(0,5(y_1+y_2)f_{X_2}(0,5(y_1−y2_2)\\frac{1}{2}=\\frac{1}{4\\pi}e^{-\\frac{1}{8}[(y_1-y_2)^2+(y_1+y_2)^2]}\\\\&=\\frac{1}{4\\pi}e^{-\\frac{1}{4}(y_1^2+y_2^2)}\\end{align}\\] Podemos notar que a densidade conjunta fatora em duas normais, ou seja \\(Y_1\\) e \\(Y2_\\) são independentes com marginais Normal(0,2).\n\n\nExercise 3.9 Sejam \\(X_1\\) e \\(X_2\\) variáveis aleatórias independentes com distribuição Normal(0,1).\n\nEncontre a função densidade conjunta de \\(Y_1=aX_1+X_2\\) e \\(Y_2=X_1−X_2\\), onde \\(a\\) é uma constante.\nQuais são os valores de \\(a\\) tais que \\(Y_1\\) é independente de \\(Y_2\\)?\n\n\n\nExample 3.9 Sejam \\(X\\) e \\(Y\\) variáveis aleatórias independentes com distribuição Exponencial(1). Vamos determinar a distribuição conjunta de \\(U=X+Y\\) e \\(V=Y/X\\) .\nAntes de prosseguirmos, é importante relembrar alguns resultados sobre funções indicadoras.\nSeja I(x∈A) a função indicadora, onde I(x∈A)={1,0, se x∈A em caso contrário. Em particular, se x∈(a,b) , podemos escrever I(a&lt;x&lt;b) . Então, é verdade que\nI(a1&lt;x&lt;b1)I(a2&lt;x&lt;b2)=I(max{a1,a2}&lt;x&lt;min{b1,b2}).\n&lt;div class=“alert alert-success&gt; ∫RI(a&lt;x&lt;b)h(x)dx=∫bah(x)dx. Considere o agora que g:Rm→Rn , onde m&gt;n . Nesse caso, Y=g(X) ainda é um vetor aleatório, mas podemos aplicar o método discutido nesta seção porque g(.) não tem inversa. Neste caso, adicionamos um vetor W=h(X) de dimensão m−n tal que a função g∗(X)=(g(X),h(X)) tenha inversa. Então, obtemos a densidade conjunta de (Y,W) através do método discutido anteriormente, ou seja\nfY,W(y,w)=fX(g∗−1(y,w))|J(y,w)|. Em seguida, podemos encontrar a densidade conjunta de Y integrando a conjunta acima em W :\nfY(y)=∫fX(g∗−1(y,w))|J(y,w)|dw. Exemplo. Sejam X1 e X2 variáveis aleatórias independentes com distribuição Exponencial(1). Vamos encontrar a densidade de Y=X1+X2 .\nNote que não há inversa (ou seja, não é possível escrever X1 e X2 como função apenas de Y ). Vamos introduzir a variável auxilar W=X2 . Então,\n{Y=X1+X2W=X2⇒{X1=Y−WX2=W\nO jacobiano da transformação será J(y,w)=∣∣∣10−11∣∣∣=1 e\nfY,W(y,w)=fX1,X2(y−w,w)|J(y,w)|=fX1(y−w)fX2(w) Lembremos que a densidade da Exponencial(1) é dada por fX(x)=e−x, para x&gt;0 . Isso é o mesmo que escrever fX(x)=e−xI(x&gt;0). Agora, podemos escrever a densidade conjunta de (Y,W): fY,W(y,w)=e−(y−w)I(y−w&gt;0)e−wI(w&gt;0)=e−yI(y−w&gt;0)I(w&gt;0). Vamos encontrar a marginal de Y integrando o resultado acima em w:\n\\[fY(y)=∫e−yI(y−w&gt;0)I(w&gt;0)dw=∫e−yI(w&lt;y)I(0&lt;w)dw=∫e−yI(−∞&lt;w&lt;y)I(0&lt;w&lt;∞)dw=∫e−yI(max{−∞,0}&lt;w&lt;min{y,∞})dw=∫e−yI(0&lt;w&lt;y)dw=∫y0e−ydw=e−y∫y0dw=ye−y.\\]\nExercício Sejam X1 e X2 variáveis aleatórias independentes com distribuição Uniforme(0,1). Encontre a distribuição de Y=X1+X2 . Solução Considere a variável auxiliar W=X1 . Neste caso, X1X2=W,=Y−W. e o Jacobiano da transformação será ∣∣∣∣∂x1∂y∂x2∂y∂x1∂w∂x2∂w∣∣∣∣=∣∣∣011−1∣∣∣=1\nComo fX1,X2(x1,x2)=fX1(x1)fX2(x2)=1 se 0&lt;x&lt;1 e 0&lt;y&lt;1 e 0 em caso contrário, teremos que\nfY,W(y,w)=fX1,X2(w,y−w)J(y,w)=I(0&lt;w&lt;1)I(0&lt;y−w&lt;1),\nse 0&lt;w&lt;1 e 0&lt;y−w&lt;1 e 0 em caso contrário.\nAgora, vamos encontrar a densidade de Y :\nfY(y)=∫RI(0&lt;w&lt;1)I(0&lt;y−w&lt;1)dw=∫RI(0&lt;w&lt;1)I(y−1&lt;w&lt;y)dw=∫RI(max{0,y−1}&lt;w&lt;min{1,y})dw=∫min{1,y}max{0,y−1}1dw=min{1,y}−max{0,y−1},\nse 0&lt;y&lt;2 e zero em caso contrário.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distribuição de vetores aleatórios contínuos</span>"
    ]
  }
]